{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import utils, imp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use any sentiment training, it might be worth exploring, which words are in any way determining labels. There are more than 70k words, so learning matrices capable of processing vectors that huge is going to take forever. Most of them is going be not so informative - for instance, words like 'I', 'the', 'will', 'be', 'want' are most likely going to occur in every label with roughly the same probability. \n",
    "\n",
    "What I will want to find, will be how distributions of joint probability $P( W, L )$ diverges from independence assumptions $P( W, L ) = P(W)P(L)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What models am I going to build? First one will be simple Naive Bayes. I will test for occurence of given word, its count and Tf-Idf score. I will use CountVectorizer and TfidfVectorizer from sci-kit learn package. Moreover, using vectors given by these models as inputs, I will build simple logistic regression and neural network with one hidden layer. Another model I'm curious to check out would be average over word embeddings in sentence. At last, I will reach recurrent neural networks, which I expect to explore more deeply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to desire to keep this notebook somewhat clean and readable, I'm storing both all of my helper functions and models in separate files. I will try to explain what is going on, but they are easily checkable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = utils.load_data(keywords=['technology', 'design', 'entertainment'])\n",
    "\n",
    "#it loads and shuffles my training data from TED dataset. Here used with default parameters. Under the hood, it also\n",
    "#does some basic preprocessing - turns to lowercase, deletes numbers and diactric signs\n",
    "\n",
    "X, y = list(zip(*dataset))\n",
    "y, labels_readable = utils.transform_labels_usable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = np.unique(y, return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes are highly imbalanced. This is going to be a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to need some plotting device. Matplotlib is indispensable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine most useful words, I will need some metric of difference between two distributions of probability - first one being proportional to labels' frequency in dataset and other one conditioned by word. There are two common ways to do this - first one is called mutual information score, second is Chi-Squared test. \n",
    "\n",
    "$$ MI = \\sum_{w_i \\in W} \\sum_{l_j \\in L} P( w = w_i, l = l_j ) \\log \\frac{P( w = w_i, l = l_j )}{P( w = w_i) P(l = l_j)} $$\n",
    "\n",
    "Those of you familiar with statistics can recognize this as cross entropy - basically we are testing how different our joint distribution is from distributions that holds independence assumption.\n",
    "\n",
    "Chi-Squared test also tests this difference, but with more straightforward way.\n",
    "\n",
    "$$ \\tilde{\\chi}^2 = \\sum_{w_i \\in W} \\sum_{l_j \\in L} \\frac{\\left( N_{ w_i, l_j} - E_{  w_i, l_j } \\right)^2}{E_{ w_i, l_j }}$$\n",
    "\n",
    "where $N_{ w = w_i, l = l_j}$ is number of real occurences of both word and label and $E_{ w = w_i, l = l_j }$ is number of occurence should these two factors were independent. $\\tilde{\\chi}^2$ is probability distribution - if it is in \n",
    "\n",
    "Fortunately, I don't have to write this pretty straightforward functions myself - sci-kit learn package is going to do all tedious processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, I can't really use all the words. Many of them occurs only once, so it would be basically relying on chance. I have to assert that every $P( w = w_i, l = l_j )$ is greater than zero, at the very least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counts = utils.count_words(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proportions_dict = utils.calculate_probs_occurence(word_counts.keys(), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check number of words fulfilling the condition of having at least 20 occurences in every class. Apart from that, I will test for showing up in at least ten percent of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perc_threshold = int(len(X)/10)\n",
    "occ_threshold = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_least_occ = list(filter(lambda x: np.all(proportions_dict[x] > occ_threshold), proportions_dict.keys()))\n",
    "at_least_threshold = list(filter(lambda x: np.sum(proportions_dict[x])>perc_threshold, proportions_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(at_least_occ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that was unexpected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1106"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(at_least_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "at_least_5 = list(filter(lambda x: np.all(proportions_dict[x]>5), proportions_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(at_least_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, everything will be determined be final score of the estimator - maybe someone more skilled in statistics would be able to predict, which approach is going to yield better accuracy of predictions? Before I get around to testing predictors, it's time to check how these sets encapsulate each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(at_least_threshold) - set(at_least_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I do any feature engineering, let's check how simple models are going to perform on last two sets of words. I will use three vectorizers and three different models, respectively. Binary count vectorizer will select features for Bernoulli Naive Bayes ( further NB ), ordinary count vectorizer will produce inputs for Multinomial NB and tf-idf vectorizer will fabricate samples for Gaussian NB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do I mean by text vectorizer? Well, it is simply function that takes some given sequence of words as input and outputs some vector of numbers - be it integers or reals. For instance, for dictionary of words of size $N$, vectorizer will output vector of size $N$. Number on $i$-th position will be representing frequency, occurence (or lack thereof) of $i$-th word. In binary vectorizer, it will be 1 if word was found in given text and zero otherwise. In count vectorizer, it is going be number of times word was found in text. Misterious tf-idf vectorizer will return number produced by equation: $\\frac{\\#w_{ji}}{\\#w_j} \\cdot \\frac{N}{\\log 1 + D_{w_i} }$, where $w_j$ denotes number of words in document, $w_{ji}$ number of times word $w_i$ can be found in $D_j$ and $D_{w_i}$ is number of documents which one can find $w_i$ in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've decided to import accuracy_score only for brevity - displaying confusion matrix, while useful, is going to take up a lot of place in this notebook. It would be reasonable for one classifier, but not for six of them (two vocab sets, three models ). Since this is multiclass problem, I can't really use other metrics such as precision and recall out of the box - I would have to turn this into multiple binary classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BinaryVectorizer = partial(CountVectorizer, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I track metrics for both training and test sets. Therefore I will be capable of measuring overfitting and gain another way to better my models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "imp.reload(utils)\n",
    "\n",
    "overall_scores = []\n",
    "vect_model = list(zip([BinaryVectorizer, CountVectorizer, TfidfVectorizer],[BernoulliNB, MultinomialNB, GaussianNB]))\n",
    "for vocab in [at_least_5, at_least_threshold]:\n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        vectorizer, model = vect_model[i]\n",
    "        params = {\n",
    "            'vectorizer':vectorizer,\n",
    "            'model':model,\n",
    "            'vocabulary':vocab,\n",
    "            'data':data\n",
    "        }\n",
    "        \n",
    "        score, pip = utils.train_test_pipeline(**params)\n",
    "        overall_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAGTCAYAAABnBRvRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhyRJaub/A1P/wWCSQNo/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f59fc8518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xticks = ['{model}, {vocab}'.format(model=model, vocab=vocab) for vocab in ['small', 'large'] for model in ['binary', 'count', 'tf-idf']]\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(range(1,7), [x[0]['accuracy'] for x in overall_scores])\n",
    "plt.xticks(range(1,7), xticks, rotation=45)\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(range(1,7), [x[1]['accuracy'] for x in overall_scores])\n",
    "plt.xticks(range(1,7), xticks, rotation=45)\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "score, pip = utils.train_test_pipeline(vectorizer=BinaryVectorizer, model=MultinomialNB, vocabulary=at_least_threshold, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'accuracy': 0.65329257536600815,\n",
       "   'log loss': 1.8817345211102008,\n",
       "   'precision': 0.68833850156391274,\n",
       "   'recall': 0.74893345470518236},\n",
       "  {'accuracy': 0.52135092178113118,\n",
       "   'log loss': 3.242976684353831,\n",
       "   'precision': 0.31550007626286741,\n",
       "   'recall': 0.32887180956184559}],\n",
       " Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "    ...     validate=True)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unexpected winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one might easily see, these models are clearly overfit. Since NB classifiers do not have any parameteres, there is not very much to tune here. I might, however, try constructing some ensembles. I will take best-performing model and train couple of its versions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will split training set into N folds and train n-th model on every fold except n-th one. Then I will average their predictions on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/utils.py'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, I can't test this approach on more than 18 folds since least populated class has that many samples. It will have to wait until I test multiclass binary approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip = utils._create_vect_pipeline(vectorizer=BinaryVectorizer, \n",
    "                                  model=MultinomialNB, \n",
    "                                  vocabulary=at_least_threshold)\n",
    "\n",
    "pips = utils.train_models_on_folds(pip, x_train, y_train, number=10)\n",
    "train_scores = utils.many_models_score(pips, x_train, y_train)\n",
    "test_scores = utils.many_models_score(pips, x_test, y_test)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.59499246472 2.97582430756\n"
     ]
    }
   ],
   "source": [
    "print(train_scores['log loss'], test_scores['log loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.68458093410108767,\n",
       "  'log loss': 1.5949924647164873,\n",
       "  'precision': 0.73663425932157334,\n",
       "  'recall': 0.79187337664205204},\n",
       " {'accuracy': 0.55938697318007657,\n",
       "  'log loss': 2.9758243075639488,\n",
       "  'precision': 0.34313240167318559,\n",
       "  'recall': 0.34328468127760337})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very impressive - we see that rare classes were rarely ( mostly not at all ) correctly labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transfm = pip.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transfm_test = pip.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(transfm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.77375566,  0.38636364,  0.36585366,  0.        ,  0.46666667,\n",
       "        0.        ,  0.20408163,  1.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.test_score_one_vs_all(y_test, clf.predict(transfm_test), precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec = utils.test_score_one_vs_all(y_test, clf.predict(transfm_test), recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_readable[0] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGrCAYAAAAvhYsOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f62d47be5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rects = plt.bar(range(1,9), rec)\n",
    "for i, rect in enumerate(rects):\n",
    "    h = rect.get_height()\n",
    "    plt.text(rect.get_x() + rect.get_width()/3, .05*(1-h)+1.1*h, counts[i])\n",
    "\n",
    "plt.xticks(range(1,9), labels_readable, rotation=90)\n",
    "plt.ylim(0, .9)\n",
    "plt.ylabel('recall')\n",
    "plt.xlabel('label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Finally, it's time to select best features, so I can be honest while comparing scores of different classifiers. It would not be very wise to give verdict \"Naive Bayes is crap\" while not taking elementary steps to make it a little bit better.\n",
    "\n",
    "I'll start off with MIS. Also, since this is neither production-level analysis nor Kaggle contest, I will use only two best-performing models from previous pipeline - which means Multinomial Naive Bayes on top of Binary Vectorizer and Gaussian NB on top of Tf-idf. It does not mean, of course, that some other model would not outperform this one with less number of irrelevant words, but this ain't Kaggle competition ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1.28485698057 1.30455723194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 1.20892111271 1.25459474154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 1.21288659697 1.27121281776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 1.13483916086 1.22040542245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 1.12009129696 1.21680426683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 1.09353984485 1.20407611543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 1.08722886573 1.22883500209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 1.02058500422 1.17160784256\n",
      "90 1.01281652831 1.18308755583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "imp.reload(utils)\n",
    "\n",
    "overall_scores = []\n",
    "pips = []\n",
    "for k in range(10, 100, 10):\n",
    "    \n",
    "    score, pip = utils.feature_selection_pipeline(BinaryVectorizer, MultinomialNB, data, mutual_info_classif, \n",
    "                                                  vocabulary=at_least_threshold, k=k)\n",
    "    \n",
    "    overall_scores.append(score)\n",
    "    pips.append(pip)\n",
    "    \n",
    "    print(k, score[0]['log loss'], score[1]['log loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1.33887148774 1.35998631375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 1.19148678342 1.23527857185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 1.14047822693 1.20688274698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 1.10454642827 1.19115358102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 1.07989275548 1.18606829222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 1.07411801902 1.19581975428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 1.07629829355 1.21849959883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 1.06309031778 1.22290805163\n",
      "90 1.07067434938 1.24783399058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "alt_scores = []\n",
    "alt_pips = []\n",
    "for k in range(10, 100, 10):\n",
    "    \n",
    "    score, pip = utils.feature_selection_pipeline(BinaryVectorizer, MultinomialNB, data, chi2, \n",
    "                                                  vocabulary=at_least_threshold, k=k)\n",
    "    \n",
    "    alt_scores.append(score)\n",
    "    alt_pips.append(pip)\n",
    "    \n",
    "    print(k, score[0]['log loss'], score[1]['log loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alt_scores = alt_scores[:len(overall_scores)]\n",
    "alt_pips = alt_pips[:len(overall_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f57404080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzjnnYuIJwznnXEz+H91+WH/O34jyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f4a676160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(range(10, 100, 10), [x[0]['log loss'] for x in overall_scores], label='MI', c='red')\n",
    "plt.plot(range(10, 100, 10), [x[0]['log loss'] for x in alt_scores], label='chi2', c='blue')\n",
    "plt.xlabel('k best features - Multinomial')\n",
    "plt.ylabel('log loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['learned',\n",
       " 'looked',\n",
       " 'asking',\n",
       " 'started',\n",
       " 'built',\n",
       " 'central',\n",
       " 'measure',\n",
       " 'havent',\n",
       " 'world',\n",
       " 'grew',\n",
       " 'fine',\n",
       " 'feel',\n",
       " 'makes',\n",
       " 'meant',\n",
       " 'amount',\n",
       " 'so',\n",
       " 'forms',\n",
       " 'begin',\n",
       " 'ask',\n",
       " 'major',\n",
       " 'boy',\n",
       " 'tiny',\n",
       " 'across',\n",
       " 'deal',\n",
       " 'hundred',\n",
       " 'loved',\n",
       " 'falsenumber',\n",
       " 'pick',\n",
       " 'remember',\n",
       " 'theyll',\n",
       " 'involved',\n",
       " 'hard',\n",
       " 'cool',\n",
       " 'sitting',\n",
       " 'particular',\n",
       " 'mostly',\n",
       " 'range',\n",
       " 'brought',\n",
       " 'into',\n",
       " 'movement',\n",
       " 'somehow',\n",
       " 'front',\n",
       " 'human',\n",
       " 'changing',\n",
       " 'seemed',\n",
       " 'therefore',\n",
       " 'maybe',\n",
       " 'enough',\n",
       " 'living',\n",
       " 'doing',\n",
       " 'then',\n",
       " 'state',\n",
       " 'yes',\n",
       " 'act',\n",
       " 'war',\n",
       " 'watching',\n",
       " 'born',\n",
       " 'though',\n",
       " 'she',\n",
       " 'species',\n",
       " 'size',\n",
       " 'serious',\n",
       " 'take',\n",
       " 'systems',\n",
       " 'arent',\n",
       " 'love',\n",
       " 'several',\n",
       " 'starts',\n",
       " 'they',\n",
       " 'youd',\n",
       " 'were',\n",
       " 'yourself',\n",
       " 'plan',\n",
       " 'met',\n",
       " 'became',\n",
       " 'twice',\n",
       " 'humans',\n",
       " 'months',\n",
       " 'explain',\n",
       " 'phone',\n",
       " 'think',\n",
       " 'moved',\n",
       " 'house',\n",
       " 'am',\n",
       " 'internet',\n",
       " 'projects',\n",
       " 'thinking',\n",
       " 'week',\n",
       " 'available',\n",
       " 'pay',\n",
       " 'decided',\n",
       " 'their',\n",
       " 'soon',\n",
       " 'of',\n",
       " 'cities',\n",
       " 'allowed',\n",
       " 'india',\n",
       " 'beyond',\n",
       " 'your',\n",
       " 'space',\n",
       " 'growing',\n",
       " 'complicated',\n",
       " 'side',\n",
       " 'im',\n",
       " 'protect',\n",
       " 'making',\n",
       " 'europe',\n",
       " 'quick',\n",
       " 'find',\n",
       " 'moment',\n",
       " 'grow',\n",
       " 'huge',\n",
       " 'sounds',\n",
       " 'waiting',\n",
       " 'came',\n",
       " 'would',\n",
       " 'set',\n",
       " 'spent',\n",
       " 'understanding',\n",
       " 'sent',\n",
       " 'issues',\n",
       " 'two',\n",
       " 'worse',\n",
       " 'recognize',\n",
       " 'crazy',\n",
       " 'apart',\n",
       " 'up',\n",
       " 'eventually',\n",
       " 'culture',\n",
       " 'spread',\n",
       " 'end',\n",
       " 'growth',\n",
       " 'lost',\n",
       " 'career',\n",
       " 'stopped',\n",
       " 'directly',\n",
       " 'itself',\n",
       " 'project',\n",
       " 'food',\n",
       " 'results',\n",
       " 'kinds',\n",
       " 'general',\n",
       " 'theyve',\n",
       " 'massive',\n",
       " 'passed',\n",
       " 'made',\n",
       " 'come',\n",
       " 'friends',\n",
       " 'had',\n",
       " 'place',\n",
       " 'those',\n",
       " 'have',\n",
       " 'happy',\n",
       " 'himself',\n",
       " 'tools',\n",
       " 'instead',\n",
       " 'among',\n",
       " 'after',\n",
       " 'connected',\n",
       " 'present',\n",
       " 'parts',\n",
       " 'kind',\n",
       " 'hit',\n",
       " 'an',\n",
       " 'force',\n",
       " 'fast',\n",
       " 'system',\n",
       " 'business',\n",
       " 'discovered',\n",
       " 'experience',\n",
       " 'drive',\n",
       " 'ideas',\n",
       " 'eyes',\n",
       " 'off',\n",
       " 'stop',\n",
       " 'enormous',\n",
       " 's',\n",
       " 'care',\n",
       " 'until',\n",
       " 'behavior',\n",
       " 'seem',\n",
       " 'get',\n",
       " 'cars',\n",
       " 'white',\n",
       " 'wed',\n",
       " 'knew',\n",
       " 'states',\n",
       " 'themselves',\n",
       " 'giving',\n",
       " 'earlier',\n",
       " 'schools',\n",
       " 'low',\n",
       " 'word',\n",
       " 'street',\n",
       " 'opportunity',\n",
       " 'animals',\n",
       " 'need',\n",
       " 'ran',\n",
       " 'may',\n",
       " 'type',\n",
       " 'story',\n",
       " 'revolution',\n",
       " 'her',\n",
       " 'true',\n",
       " 'process',\n",
       " 'want',\n",
       " 'as',\n",
       " 'many',\n",
       " 'screen',\n",
       " 'since',\n",
       " 'chance',\n",
       " 'sea',\n",
       " 'control',\n",
       " 'certain',\n",
       " 'trying',\n",
       " 'says',\n",
       " 'very',\n",
       " 'does',\n",
       " 'under',\n",
       " 'walked',\n",
       " 'simple',\n",
       " 'big',\n",
       " 'anybody',\n",
       " 'driving',\n",
       " 'development',\n",
       " 'faster',\n",
       " 'first',\n",
       " 'teach',\n",
       " 'energy',\n",
       " 'went',\n",
       " 'network',\n",
       " 'especially',\n",
       " 'main',\n",
       " 'concept',\n",
       " 'cause',\n",
       " 'wants',\n",
       " 'couldnt',\n",
       " 'sorts',\n",
       " 'number',\n",
       " 'good',\n",
       " 'bigger',\n",
       " 'money',\n",
       " 'exactly',\n",
       " 'within',\n",
       " 'challenges',\n",
       " 'indeed',\n",
       " 'book',\n",
       " 'idea',\n",
       " 'along',\n",
       " 'worry',\n",
       " 'government',\n",
       " 'step',\n",
       " 'questions',\n",
       " 'ways',\n",
       " 'different',\n",
       " 'slow',\n",
       " 'company',\n",
       " 'reading',\n",
       " 'scale',\n",
       " 'oh',\n",
       " 'his',\n",
       " 'body',\n",
       " 'how',\n",
       " 'doesnt',\n",
       " 'terms',\n",
       " 'east',\n",
       " 'works',\n",
       " 'exist',\n",
       " 'guess',\n",
       " 'please',\n",
       " 'sort',\n",
       " 'bottom',\n",
       " 'now',\n",
       " 'yeah',\n",
       " 'recently',\n",
       " 'modern',\n",
       " 'aware',\n",
       " 'water',\n",
       " 'organization',\n",
       " 'little',\n",
       " 'source',\n",
       " 'dark',\n",
       " 'led',\n",
       " 'both',\n",
       " 'night',\n",
       " 'reasons',\n",
       " 'material',\n",
       " 'some',\n",
       " 'theyre',\n",
       " 'looks',\n",
       " 'ive',\n",
       " 'finding',\n",
       " 'becoming',\n",
       " 'mean',\n",
       " 'green',\n",
       " 'surface',\n",
       " 'position',\n",
       " 'nobody',\n",
       " 'theres',\n",
       " 'sure',\n",
       " 'areas',\n",
       " 'be',\n",
       " 'quality',\n",
       " 'worst',\n",
       " 'local',\n",
       " 'heart',\n",
       " 'pieces',\n",
       " 'feeling',\n",
       " 'voice',\n",
       " 'market',\n",
       " 'america',\n",
       " 'youve',\n",
       " 'data',\n",
       " 'economic',\n",
       " 'perspective',\n",
       " 'further',\n",
       " 'blue',\n",
       " 'hundreds',\n",
       " 'fall',\n",
       " 'interesting',\n",
       " 'worth',\n",
       " 'minute',\n",
       " 'said',\n",
       " 'series',\n",
       " 'fundamental',\n",
       " 'everything',\n",
       " 'north',\n",
       " 'ago',\n",
       " 'middle',\n",
       " 'approach',\n",
       " 'american',\n",
       " 'books',\n",
       " 'key',\n",
       " 'normal',\n",
       " 'showed',\n",
       " 'others',\n",
       " 'the',\n",
       " 'found',\n",
       " 'hold',\n",
       " 'natural',\n",
       " 'likely',\n",
       " 'at',\n",
       " 'designed',\n",
       " 'expensive',\n",
       " 'every',\n",
       " 'but',\n",
       " 'god',\n",
       " 'him',\n",
       " 'imagine',\n",
       " 'worlds',\n",
       " 'billion',\n",
       " 'saying',\n",
       " 'tool',\n",
       " 'current',\n",
       " 'least',\n",
       " 'companies',\n",
       " 'told',\n",
       " 'planet',\n",
       " 'quite',\n",
       " 'happen',\n",
       " 'job',\n",
       " 'form',\n",
       " 'men',\n",
       " 'piece',\n",
       " 'million',\n",
       " 'did',\n",
       " 'better',\n",
       " 'create',\n",
       " 'anyway',\n",
       " 'matter',\n",
       " 'simply',\n",
       " 'six',\n",
       " 'years',\n",
       " 'rest',\n",
       " 'else',\n",
       " 'rate',\n",
       " 'realized',\n",
       " 'minutes',\n",
       " 'even',\n",
       " 'no',\n",
       " 'give',\n",
       " 'die',\n",
       " 'when',\n",
       " 'average',\n",
       " 'camera',\n",
       " 'student',\n",
       " 'before',\n",
       " 'telling',\n",
       " 'conditions',\n",
       " 'poor',\n",
       " 'bit',\n",
       " 'someone',\n",
       " 'black',\n",
       " 'hope',\n",
       " 'girl',\n",
       " 'any',\n",
       " 'learning',\n",
       " 'figure',\n",
       " 'music',\n",
       " 'climate',\n",
       " 'vision',\n",
       " 'onto',\n",
       " 'worked',\n",
       " 'examples',\n",
       " 'specific',\n",
       " 'dead',\n",
       " 'expect',\n",
       " 'product',\n",
       " 'wife',\n",
       " 'last',\n",
       " 'feet',\n",
       " 'team',\n",
       " 'ability',\n",
       " 'situation',\n",
       " 'than',\n",
       " 'join',\n",
       " 'forget',\n",
       " 'creative',\n",
       " 'effect',\n",
       " 'sometimes',\n",
       " 'like',\n",
       " 'bring',\n",
       " 'too',\n",
       " 'community',\n",
       " 'all',\n",
       " 'inside',\n",
       " 'month',\n",
       " 'you',\n",
       " 'almost',\n",
       " 'brain',\n",
       " 'air',\n",
       " 'time',\n",
       " 'large',\n",
       " 'science',\n",
       " 'extraordinary',\n",
       " 'without',\n",
       " 'law',\n",
       " 'kids',\n",
       " 'using',\n",
       " 'literally',\n",
       " 'greater',\n",
       " 'produce',\n",
       " 'past',\n",
       " 'break',\n",
       " 'ready',\n",
       " 'images',\n",
       " 'do',\n",
       " 'scientific',\n",
       " 'cant',\n",
       " 'line',\n",
       " 'often',\n",
       " 'playing',\n",
       " 'actually',\n",
       " 'lose',\n",
       " 'happens',\n",
       " 'written',\n",
       " 'dangerous',\n",
       " 'face',\n",
       " 'left',\n",
       " 'beginning',\n",
       " 'beings',\n",
       " 'own',\n",
       " 'health',\n",
       " 'students',\n",
       " 'wait',\n",
       " 'immediately',\n",
       " 'places',\n",
       " 'table',\n",
       " 'computer',\n",
       " 'finally',\n",
       " 'theyd',\n",
       " 'anywhere',\n",
       " 'country',\n",
       " 'here',\n",
       " 'also',\n",
       " 'shape',\n",
       " 'group',\n",
       " 'totally',\n",
       " 'particularly',\n",
       " 'he',\n",
       " 'there',\n",
       " 'message',\n",
       " 'certainly',\n",
       " 'difference',\n",
       " 'ok',\n",
       " 'smart',\n",
       " 'standing',\n",
       " 'hour',\n",
       " 'woman',\n",
       " 'stories',\n",
       " 'nine',\n",
       " 'truth',\n",
       " 'build',\n",
       " 'course',\n",
       " 'alone',\n",
       " 'field',\n",
       " 'for',\n",
       " 'why',\n",
       " 'either',\n",
       " 'go',\n",
       " 'stand',\n",
       " 'older',\n",
       " 'people',\n",
       " 'ended',\n",
       " 'fight',\n",
       " 'today',\n",
       " 'together',\n",
       " 'favorite',\n",
       " 'few',\n",
       " 'werent',\n",
       " 'political',\n",
       " 'structure',\n",
       " 'in',\n",
       " 'although',\n",
       " 'hear',\n",
       " 'about',\n",
       " 'touch',\n",
       " 'our',\n",
       " 'individuals',\n",
       " 'slightly',\n",
       " 'right',\n",
       " 'familiar',\n",
       " 'died',\n",
       " 'yet',\n",
       " 'machine',\n",
       " 'youre',\n",
       " 'complex',\n",
       " 'clearly',\n",
       " 'technologies',\n",
       " 'truly',\n",
       " 'has',\n",
       " 'becomes',\n",
       " 'online',\n",
       " 'safe',\n",
       " 'dream',\n",
       " 'a',\n",
       " 'conversation',\n",
       " 'something',\n",
       " 'larger',\n",
       " 'obvious',\n",
       " 'possible',\n",
       " 'attention',\n",
       " 'evidence',\n",
       " 'seven',\n",
       " 'connect',\n",
       " 'sense',\n",
       " 'action',\n",
       " 'given',\n",
       " 'full',\n",
       " 'must',\n",
       " 'following',\n",
       " 'international',\n",
       " 'means',\n",
       " 'next',\n",
       " 'eight',\n",
       " 'speed',\n",
       " 'box',\n",
       " 'turns',\n",
       " 'important',\n",
       " 'area',\n",
       " 'kid',\n",
       " 'ted',\n",
       " 'uses',\n",
       " 'obviously',\n",
       " 'taking',\n",
       " 'become',\n",
       " 'well',\n",
       " 'family',\n",
       " 'audience',\n",
       " 'upon',\n",
       " 'four',\n",
       " 'thanks',\n",
       " 'pull',\n",
       " 'famous',\n",
       " 'children',\n",
       " 'needed',\n",
       " 'goes',\n",
       " 'looking',\n",
       " 'knowledge',\n",
       " 'minds',\n",
       " 'national',\n",
       " 'seeing',\n",
       " 'was',\n",
       " 'home',\n",
       " 'powerful',\n",
       " 'age',\n",
       " 'these',\n",
       " 'provide',\n",
       " 'heres',\n",
       " 'small',\n",
       " 'old',\n",
       " 'news',\n",
       " 'thing',\n",
       " 'point',\n",
       " 'access',\n",
       " 'order',\n",
       " 'hands',\n",
       " 'youll',\n",
       " 'named',\n",
       " 'myself',\n",
       " 'second',\n",
       " 'much',\n",
       " 'ourselves',\n",
       " 'again',\n",
       " 'fun',\n",
       " 'us',\n",
       " 'watch',\n",
       " 'might',\n",
       " 'one',\n",
       " 'pictures',\n",
       " 'stay',\n",
       " 'my',\n",
       " 'economy',\n",
       " 'understood',\n",
       " 'is',\n",
       " 'biggest',\n",
       " 'consider',\n",
       " 'essentially',\n",
       " 'being',\n",
       " 'easy',\n",
       " 'center',\n",
       " 'digital',\n",
       " 'lived',\n",
       " 'groups',\n",
       " 'id',\n",
       " 'public',\n",
       " 'mine',\n",
       " 'realize',\n",
       " 'less',\n",
       " 'needs',\n",
       " 'search',\n",
       " 'part',\n",
       " 'days',\n",
       " 'keep',\n",
       " 'whatever',\n",
       " 'result',\n",
       " 'who',\n",
       " 'art',\n",
       " 'theory',\n",
       " 'me',\n",
       " 'raise',\n",
       " 'higher',\n",
       " 'actual',\n",
       " 'happening',\n",
       " 'hours',\n",
       " 'began',\n",
       " 'recent',\n",
       " 'while',\n",
       " 'wrong',\n",
       " 'lab',\n",
       " 'hand',\n",
       " 'design',\n",
       " 'back',\n",
       " 'not',\n",
       " 'see',\n",
       " 'research',\n",
       " 'notice',\n",
       " 'africa',\n",
       " 'various',\n",
       " 'work',\n",
       " 'city',\n",
       " 'wonder',\n",
       " 'cold',\n",
       " 'understand',\n",
       " 'cut',\n",
       " 'shown',\n",
       " 'anymore',\n",
       " 'son',\n",
       " 'developed',\n",
       " 'tells',\n",
       " 'going',\n",
       " 'lives',\n",
       " 'continue',\n",
       " 'mass',\n",
       " 'if',\n",
       " 'rich',\n",
       " 'taught',\n",
       " 'taken',\n",
       " 'open',\n",
       " 'change',\n",
       " 'question',\n",
       " 'gives',\n",
       " 'language',\n",
       " 'always',\n",
       " 'just',\n",
       " 'should',\n",
       " 'land',\n",
       " 'view',\n",
       " 'single',\n",
       " 'talking',\n",
       " 'known',\n",
       " 'eye',\n",
       " 'look',\n",
       " 'list',\n",
       " 'impossible',\n",
       " 'quickly',\n",
       " 'called',\n",
       " 'fly',\n",
       " 'map',\n",
       " 'strong',\n",
       " 'changes',\n",
       " 'th',\n",
       " 'somewhere',\n",
       " 'person',\n",
       " 'putting',\n",
       " 'sorry',\n",
       " 'car',\n",
       " 'scientists',\n",
       " 'throughout',\n",
       " 'knows',\n",
       " 'turned',\n",
       " 'complete',\n",
       " 'office',\n",
       " 'early',\n",
       " 'risk',\n",
       " 'social',\n",
       " 'interested',\n",
       " 'colleagues',\n",
       " 'by',\n",
       " 'guy',\n",
       " 'united',\n",
       " 'problem',\n",
       " 'heard',\n",
       " 'reason',\n",
       " 'mind',\n",
       " 'china',\n",
       " 'spend',\n",
       " 'show',\n",
       " 'isnt',\n",
       " 'somebody',\n",
       " 'relationship',\n",
       " 'door',\n",
       " 'make',\n",
       " 'women',\n",
       " 'nice',\n",
       " 'direction',\n",
       " 'will',\n",
       " 'clear',\n",
       " 'reach',\n",
       " 'what',\n",
       " 'incredible',\n",
       " 'took',\n",
       " 'comes',\n",
       " 'role',\n",
       " 'meet',\n",
       " 'speaking',\n",
       " 'half',\n",
       " 'seen',\n",
       " 'including',\n",
       " 'between',\n",
       " 'red',\n",
       " 'answer',\n",
       " 'fantastic',\n",
       " 'man',\n",
       " 'unique',\n",
       " 'traditional',\n",
       " 'shows',\n",
       " 'talk',\n",
       " 'father',\n",
       " 'forward',\n",
       " 'which',\n",
       " 'decide',\n",
       " 'incredibly',\n",
       " 'century',\n",
       " 'real',\n",
       " 'lets',\n",
       " 'couple',\n",
       " 'hot',\n",
       " 'however',\n",
       " 'color',\n",
       " 'from',\n",
       " 'to',\n",
       " 'new',\n",
       " 'rather',\n",
       " 'working',\n",
       " 'over',\n",
       " 'whats',\n",
       " 'top',\n",
       " 'share',\n",
       " 'ever',\n",
       " 'lots',\n",
       " 'personal',\n",
       " 'each',\n",
       " 'probably',\n",
       " 'largest',\n",
       " 'test',\n",
       " 'wanted',\n",
       " 'are',\n",
       " 'develop',\n",
       " 'fact',\n",
       " 'miles',\n",
       " 'we',\n",
       " 'unfortunately',\n",
       " 'power',\n",
       " 'context',\n",
       " 'parents',\n",
       " 'millions',\n",
       " 'version',\n",
       " 'put',\n",
       " 'buy',\n",
       " 'bunch',\n",
       " 'college',\n",
       " 'response',\n",
       " 'possibly',\n",
       " 'fit',\n",
       " 'solution',\n",
       " 'final',\n",
       " 'information',\n",
       " 'lines',\n",
       " 'based',\n",
       " 'such',\n",
       " 'positive',\n",
       " 'young',\n",
       " 'decades',\n",
       " 'environment',\n",
       " 'behind',\n",
       " 'away',\n",
       " 'goal',\n",
       " 'longer',\n",
       " 'game',\n",
       " 'greatest',\n",
       " 'it',\n",
       " 'completely',\n",
       " 'during',\n",
       " 'third',\n",
       " 'developing',\n",
       " 'best',\n",
       " 'can',\n",
       " 'speak',\n",
       " 'wonderful',\n",
       " 'other',\n",
       " 'gave',\n",
       " 'this',\n",
       " 'sat',\n",
       " 'lead',\n",
       " 'critical',\n",
       " 'fear',\n",
       " 'baby',\n",
       " 'points',\n",
       " 'free',\n",
       " 'level',\n",
       " 'physical',\n",
       " 'study',\n",
       " 'write',\n",
       " 'types',\n",
       " 'created',\n",
       " 'challenge',\n",
       " 'know',\n",
       " 'computers',\n",
       " 'terrible',\n",
       " 'let',\n",
       " 'similar',\n",
       " 'things',\n",
       " 'with',\n",
       " 'against',\n",
       " 'difficult',\n",
       " 'case',\n",
       " 'its',\n",
       " 'getting',\n",
       " 'learn',\n",
       " 'three',\n",
       " 'coming',\n",
       " 'excited',\n",
       " 'cannot',\n",
       " 'meaning',\n",
       " 'thousands',\n",
       " 'york',\n",
       " 'countries',\n",
       " 'carry',\n",
       " 'software',\n",
       " 'whose',\n",
       " 'okay',\n",
       " 'eat',\n",
       " 'success',\n",
       " 'close',\n",
       " 'felt',\n",
       " 'stage',\n",
       " 'whole',\n",
       " 'add',\n",
       " 'media',\n",
       " 'easily',\n",
       " 'wont',\n",
       " 'great',\n",
       " 'thats',\n",
       " 'way',\n",
       " 'short',\n",
       " 'friend',\n",
       " 'earth',\n",
       " 'five',\n",
       " 'already',\n",
       " 'perfect',\n",
       " 'numbers',\n",
       " 'individual',\n",
       " 'everyone',\n",
       " 'picture',\n",
       " 'tend',\n",
       " 'weve',\n",
       " 'listen',\n",
       " 'helped',\n",
       " 'where',\n",
       " 'through',\n",
       " 'i',\n",
       " 'usually',\n",
       " 'example',\n",
       " 'focus',\n",
       " 'cases',\n",
       " 'allows',\n",
       " 'industry',\n",
       " 'hes',\n",
       " 'used',\n",
       " 'long',\n",
       " 'interest',\n",
       " 'fire',\n",
       " 'head',\n",
       " 'except',\n",
       " 'thousand',\n",
       " 'perhaps',\n",
       " 'late',\n",
       " 'experiment',\n",
       " 'supposed',\n",
       " 'ill',\n",
       " 'kill',\n",
       " 'program',\n",
       " 'because',\n",
       " 'believe',\n",
       " 'class',\n",
       " 'practice',\n",
       " 'only',\n",
       " 'dont',\n",
       " 'live',\n",
       " 'ground',\n",
       " 'strange',\n",
       " 'dollars',\n",
       " 'that',\n",
       " 'paper',\n",
       " 'smaller',\n",
       " 'history',\n",
       " 'gets',\n",
       " 'percent',\n",
       " 'common',\n",
       " 'society',\n",
       " 'having',\n",
       " 'call',\n",
       " 'none',\n",
       " 'ones',\n",
       " 'light',\n",
       " 'never',\n",
       " 'wrote',\n",
       " 'population',\n",
       " 'cell',\n",
       " 'impact',\n",
       " 'words',\n",
       " 'seems',\n",
       " 'out',\n",
       " 'got',\n",
       " 'image',\n",
       " 'nothing',\n",
       " 'moving',\n",
       " 'wasnt',\n",
       " 'whether',\n",
       " 'start',\n",
       " 'extremely',\n",
       " 'families',\n",
       " 'choice',\n",
       " 'communities',\n",
       " 'everybody',\n",
       " 'school',\n",
       " 'same',\n",
       " 'suddenly',\n",
       " 'still',\n",
       " 'special',\n",
       " 'basically',\n",
       " 'road',\n",
       " 'anyone',\n",
       " 'thank',\n",
       " 'name',\n",
       " 'towards',\n",
       " 'studies',\n",
       " 'sit',\n",
       " 'generation',\n",
       " 'showing',\n",
       " 'cost',\n",
       " 'year',\n",
       " 'send',\n",
       " 'absolutely',\n",
       " 'anything',\n",
       " 'kept',\n",
       " 'successful',\n",
       " 'above',\n",
       " 'value',\n",
       " 'lot',\n",
       " 'reality',\n",
       " 'and',\n",
       " 'google',\n",
       " 'takes',\n",
       " 'allow',\n",
       " 'south',\n",
       " 'model',\n",
       " 'room',\n",
       " 'potential',\n",
       " ...]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pips[-1].named_steps['countvectorizer'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_words = [pips[-1].named_steps['countvectorizer'].get_feature_names()[i] for i in range(len(at_least_threshold)) if pips[-1].named_steps['selectkbest'].get_support()[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'accuracy': 0.62355433738185284,\n",
       "   'log loss': 1.0128165283099013,\n",
       "   'precision': 0.55840283756829656,\n",
       "   'recall': 0.35837939133718832},\n",
       "  {'accuracy': 0.58362623852450746,\n",
       "   'log loss': 1.1830875558336831,\n",
       "   'precision': 0.2896167721056454,\n",
       "   'recall': 0.24046710847673719}],\n",
       " Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "    ...     validate=True)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.train_test_pipeline(BinaryVectorizer, MultinomialNB, data, best_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRiUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f4a59dc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([word_counts[word] for word in best_words])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worst_words = [pips[-1].named_steps['countvectorizer'].get_feature_names()[x] for x in np.argsort(pips[-1].named_steps['selectkbest'].scores_)[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxXbw0RkQZgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f9d972320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([word_counts[word] for word in worst_words])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it does not matter that much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOedcVJ4snHPORfX/QFgMyEQtr2MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f62d47a2e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(range(10, 100, 10), [x['accuracy'] for x in overall_scores], label='MI', c='red')\n",
    "plt.plot(range(10, 100, 10), [x['accuracy'] for x in alt_scores], label='chi2', c='blue')\n",
    "plt.xlabel('k best features - Multinomial')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ae868d26837c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m score, pip = utils.train_test_pipeline(TfidfVectorizer, LogisticRegression, data, at_least_threshold, \n\u001b[0;32m----> 2\u001b[0;31m                                        class_weight='balanced', C=5, penalty='l1')\n\u001b[0m",
      "\u001b[0;32m/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/utils.py\u001b[0m in \u001b[0;36mtrain_test_pipeline\u001b[0;34m(vectorizer, model, data, vocabulary, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/utils.py\u001b[0m in \u001b[0;36mget_score\u001b[0;34m(clf, X, y, cv)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score, pip = utils.train_test_pipeline(TfidfVectorizer, LogisticRegression, data, at_least_threshold, \n",
    "                                       class_weight='balanced', C=5, penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(vocabulary=at_least_threshold)\n",
    "selector = SelectKBest(chi2)\n",
    "lr = LogisticRegression()\n",
    "\n",
    "pip = Pipeline([('vect', vect), ('sel', selector), ('lr', lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searcher = RandomizedSearchCV(pip, \n",
    "                              n_iter=30, \n",
    "                              param_distributions={'sel__k': randint(5, 100), 'lr__C':uniform(1,10), 'lr__penalty': ['l1', 'l2']}, \n",
    "                              verbose=2, n_jobs=10, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "[CV] sel__k=7, lr__penalty=l1, lr__C=8.2733851135 ....................\n",
      "[CV] sel__k=7, lr__penalty=l1, lr__C=8.2733851135 ....................\n",
      "[CV] sel__k=7, lr__penalty=l1, lr__C=8.2733851135 ....................\n",
      "[CV] sel__k=7, lr__penalty=l1, lr__C=8.2733851135 ....................\n",
      "[CV] sel__k=7, lr__penalty=l1, lr__C=8.2733851135 ....................\n",
      "[CV] sel__k=7, lr__penalty=l1, lr__C=8.2733851135 ....................\n",
      "[CV] sel__k=7, lr__penalty=l1, lr__C=8.2733851135 ....................\n",
      "[CV] sel__k=7, lr__penalty=l1, lr__C=8.2733851135 ....................\n",
      "[CV] sel__k=7, lr__penalty=l1, lr__C=8.2733851135 ....................\n",
      "[CV] sel__k=7, lr__penalty=l1, lr__C=8.2733851135 ....................\n",
      "[CV] ..... sel__k=7, lr__penalty=l1, lr__C=8.2733851135, total=  11.5s\n",
      "[CV] sel__k=35, lr__penalty=l1, lr__C=10.2928174126 ..................\n",
      "[CV] ..... sel__k=7, lr__penalty=l1, lr__C=8.2733851135, total=  11.8s\n",
      "[CV] sel__k=35, lr__penalty=l1, lr__C=10.2928174126 ..................\n",
      "[CV] ..... sel__k=7, lr__penalty=l1, lr__C=8.2733851135, total=  12.4s\n",
      "[CV] sel__k=35, lr__penalty=l1, lr__C=10.2928174126 ..................\n",
      "[CV] ..... sel__k=7, lr__penalty=l1, lr__C=8.2733851135, total=  12.4s\n",
      "[CV] sel__k=35, lr__penalty=l1, lr__C=10.2928174126 ..................\n",
      "[CV] ..... sel__k=7, lr__penalty=l1, lr__C=8.2733851135, total=  11.9s\n",
      "[CV] sel__k=35, lr__penalty=l1, lr__C=10.2928174126 ..................\n",
      "[CV] ..... sel__k=7, lr__penalty=l1, lr__C=8.2733851135, total=  12.5s\n",
      "[CV] sel__k=35, lr__penalty=l1, lr__C=10.2928174126 ..................\n",
      "[CV] ..... sel__k=7, lr__penalty=l1, lr__C=8.2733851135, total=  13.0s\n",
      "[CV] ..... sel__k=7, lr__penalty=l1, lr__C=8.2733851135, total=  12.5s\n",
      "[CV] sel__k=35, lr__penalty=l1, lr__C=10.2928174126 ..................\n",
      "[CV] sel__k=35, lr__penalty=l1, lr__C=10.2928174126 ..................\n",
      "[CV] ..... sel__k=7, lr__penalty=l1, lr__C=8.2733851135, total=  13.0s\n",
      "[CV] sel__k=35, lr__penalty=l1, lr__C=10.2928174126 ..................\n",
      "[CV] ..... sel__k=7, lr__penalty=l1, lr__C=8.2733851135, total=  14.0s\n",
      "[CV] sel__k=35, lr__penalty=l1, lr__C=10.2928174126 ..................\n",
      "[CV] ... sel__k=35, lr__penalty=l1, lr__C=10.2928174126, total=  15.1s\n",
      "[CV] sel__k=23, lr__penalty=l2, lr__C=9.50734001605 ..................\n",
      "[CV] ... sel__k=35, lr__penalty=l1, lr__C=10.2928174126, total=  14.3s\n",
      "[CV] sel__k=23, lr__penalty=l2, lr__C=9.50734001605 ..................\n",
      "[CV] ... sel__k=35, lr__penalty=l1, lr__C=10.2928174126, total=  13.6s\n",
      "[CV] sel__k=23, lr__penalty=l2, lr__C=9.50734001605 ..................\n",
      "[CV] ... sel__k=35, lr__penalty=l1, lr__C=10.2928174126, total=  14.0s\n",
      "[CV] sel__k=23, lr__penalty=l2, lr__C=9.50734001605 ..................\n",
      "[CV] ... sel__k=35, lr__penalty=l1, lr__C=10.2928174126, total=  13.6s\n",
      "[CV] ... sel__k=35, lr__penalty=l1, lr__C=10.2928174126, total=  14.2s\n",
      "[CV] sel__k=23, lr__penalty=l2, lr__C=9.50734001605 ..................\n",
      "[CV] sel__k=23, lr__penalty=l2, lr__C=9.50734001605 ..................\n",
      "[CV] ... sel__k=35, lr__penalty=l1, lr__C=10.2928174126, total=  13.9s\n",
      "[CV] sel__k=23, lr__penalty=l2, lr__C=9.50734001605 ..................\n",
      "[CV] ... sel__k=35, lr__penalty=l1, lr__C=10.2928174126, total=  15.0s\n",
      "[CV] sel__k=23, lr__penalty=l2, lr__C=9.50734001605 ..................\n",
      "[CV] ... sel__k=35, lr__penalty=l1, lr__C=10.2928174126, total=  14.1s\n",
      "[CV] sel__k=23, lr__penalty=l2, lr__C=9.50734001605 ..................\n",
      "[CV] ... sel__k=35, lr__penalty=l1, lr__C=10.2928174126, total=  14.7s\n",
      "[CV] sel__k=23, lr__penalty=l2, lr__C=9.50734001605 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l2, lr__C=9.50734001605, total=  14.7s\n",
      "[CV] sel__k=84, lr__penalty=l1, lr__C=7.75902323336 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:  1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... sel__k=23, lr__penalty=l2, lr__C=9.50734001605, total=  14.2s\n",
      "[CV] sel__k=84, lr__penalty=l1, lr__C=7.75902323336 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l2, lr__C=9.50734001605, total=  14.1s\n",
      "[CV] sel__k=84, lr__penalty=l1, lr__C=7.75902323336 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l2, lr__C=9.50734001605, total=  14.9s\n",
      "[CV] sel__k=84, lr__penalty=l1, lr__C=7.75902323336 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l2, lr__C=9.50734001605, total=  15.6s\n",
      "[CV] sel__k=84, lr__penalty=l1, lr__C=7.75902323336 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l2, lr__C=9.50734001605, total=  15.8s\n",
      "[CV] sel__k=84, lr__penalty=l1, lr__C=7.75902323336 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l2, lr__C=9.50734001605, total=  14.8s\n",
      "[CV] sel__k=84, lr__penalty=l1, lr__C=7.75902323336 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l2, lr__C=9.50734001605, total=  15.3s\n",
      "[CV] sel__k=84, lr__penalty=l1, lr__C=7.75902323336 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l2, lr__C=9.50734001605, total=  15.4s\n",
      "[CV] sel__k=84, lr__penalty=l1, lr__C=7.75902323336 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l2, lr__C=9.50734001605, total=  14.2s\n",
      "[CV] sel__k=84, lr__penalty=l1, lr__C=7.75902323336 ..................\n",
      "[CV] ... sel__k=84, lr__penalty=l1, lr__C=7.75902323336, total=  14.8s\n",
      "[CV] sel__k=13, lr__penalty=l2, lr__C=7.19702353598 ..................\n",
      "[CV] ... sel__k=84, lr__penalty=l1, lr__C=7.75902323336, total=  14.4s\n",
      "[CV] sel__k=13, lr__penalty=l2, lr__C=7.19702353598 ..................\n",
      "[CV] ... sel__k=84, lr__penalty=l1, lr__C=7.75902323336, total=  15.4s\n",
      "[CV] sel__k=13, lr__penalty=l2, lr__C=7.19702353598 ..................\n",
      "[CV] ... sel__k=84, lr__penalty=l1, lr__C=7.75902323336, total=  14.7s\n",
      "[CV] ... sel__k=84, lr__penalty=l1, lr__C=7.75902323336, total=  14.8s\n",
      "[CV] sel__k=13, lr__penalty=l2, lr__C=7.19702353598 ..................\n",
      "[CV] ... sel__k=84, lr__penalty=l1, lr__C=7.75902323336, total=  14.3s\n",
      "[CV] sel__k=13, lr__penalty=l2, lr__C=7.19702353598 ..................\n",
      "[CV] sel__k=13, lr__penalty=l2, lr__C=7.19702353598 ..................\n",
      "[CV] ... sel__k=84, lr__penalty=l1, lr__C=7.75902323336, total=  14.3s\n",
      "[CV] sel__k=13, lr__penalty=l2, lr__C=7.19702353598 ..................\n",
      "[CV] ... sel__k=84, lr__penalty=l1, lr__C=7.75902323336, total=  15.6s\n",
      "[CV] sel__k=13, lr__penalty=l2, lr__C=7.19702353598 ..................\n",
      "[CV] ... sel__k=84, lr__penalty=l1, lr__C=7.75902323336, total=  15.6s\n",
      "[CV] sel__k=13, lr__penalty=l2, lr__C=7.19702353598 ..................\n",
      "[CV] ... sel__k=84, lr__penalty=l1, lr__C=7.75902323336, total=  15.5s\n",
      "[CV] sel__k=13, lr__penalty=l2, lr__C=7.19702353598 ..................\n",
      "[CV] ... sel__k=13, lr__penalty=l2, lr__C=7.19702353598, total=  13.6s\n",
      "[CV] sel__k=48, lr__penalty=l2, lr__C=3.75636481974 ..................\n",
      "[CV] ... sel__k=13, lr__penalty=l2, lr__C=7.19702353598, total=  14.8s\n",
      "[CV] sel__k=48, lr__penalty=l2, lr__C=3.75636481974 ..................\n",
      "[CV] ... sel__k=13, lr__penalty=l2, lr__C=7.19702353598, total=  13.7s\n",
      "[CV] ... sel__k=13, lr__penalty=l2, lr__C=7.19702353598, total=  14.6s\n",
      "[CV] sel__k=48, lr__penalty=l2, lr__C=3.75636481974 ..................\n",
      "[CV] sel__k=48, lr__penalty=l2, lr__C=3.75636481974 ..................\n",
      "[CV] ... sel__k=13, lr__penalty=l2, lr__C=7.19702353598, total=  14.8s\n",
      "[CV] sel__k=48, lr__penalty=l2, lr__C=3.75636481974 ..................\n",
      "[CV] ... sel__k=13, lr__penalty=l2, lr__C=7.19702353598, total=  14.3s\n",
      "[CV] sel__k=48, lr__penalty=l2, lr__C=3.75636481974 ..................\n",
      "[CV] ... sel__k=13, lr__penalty=l2, lr__C=7.19702353598, total=  14.8s\n",
      "[CV] sel__k=48, lr__penalty=l2, lr__C=3.75636481974 ..................\n",
      "[CV] ... sel__k=13, lr__penalty=l2, lr__C=7.19702353598, total=  13.9s\n",
      "[CV] sel__k=48, lr__penalty=l2, lr__C=3.75636481974 ..................\n",
      "[CV] ... sel__k=13, lr__penalty=l2, lr__C=7.19702353598, total=  14.7s\n",
      "[CV] sel__k=48, lr__penalty=l2, lr__C=3.75636481974 ..................\n",
      "[CV] ... sel__k=13, lr__penalty=l2, lr__C=7.19702353598, total=  15.1s\n",
      "[CV] sel__k=48, lr__penalty=l2, lr__C=3.75636481974 ..................\n",
      "[CV] ... sel__k=48, lr__penalty=l2, lr__C=3.75636481974, total=  12.4s\n",
      "[CV] ... sel__k=48, lr__penalty=l2, lr__C=3.75636481974, total=  12.8s\n",
      "[CV] sel__k=60, lr__penalty=l2, lr__C=1.3786990543 ...................\n",
      "[CV] sel__k=60, lr__penalty=l2, lr__C=1.3786990543 ...................\n",
      "[CV] ... sel__k=48, lr__penalty=l2, lr__C=3.75636481974, total=  15.0s\n",
      "[CV] sel__k=60, lr__penalty=l2, lr__C=1.3786990543 ...................\n",
      "[CV] ... sel__k=48, lr__penalty=l2, lr__C=3.75636481974, total=  15.4s\n",
      "[CV] sel__k=60, lr__penalty=l2, lr__C=1.3786990543 ...................\n",
      "[CV] ... sel__k=48, lr__penalty=l2, lr__C=3.75636481974, total=  13.5s\n",
      "[CV] sel__k=60, lr__penalty=l2, lr__C=1.3786990543 ...................\n",
      "[CV] ... sel__k=48, lr__penalty=l2, lr__C=3.75636481974, total=  13.2s\n",
      "[CV] sel__k=60, lr__penalty=l2, lr__C=1.3786990543 ...................\n",
      "[CV] ... sel__k=48, lr__penalty=l2, lr__C=3.75636481974, total=  13.8s\n",
      "[CV] sel__k=60, lr__penalty=l2, lr__C=1.3786990543 ...................\n",
      "[CV] ... sel__k=48, lr__penalty=l2, lr__C=3.75636481974, total=  14.0s\n",
      "[CV] sel__k=60, lr__penalty=l2, lr__C=1.3786990543 ...................\n",
      "[CV] ... sel__k=48, lr__penalty=l2, lr__C=3.75636481974, total=  13.3s\n",
      "[CV] sel__k=60, lr__penalty=l2, lr__C=1.3786990543 ...................\n",
      "[CV] ... sel__k=48, lr__penalty=l2, lr__C=3.75636481974, total=  13.2s\n",
      "[CV] sel__k=60, lr__penalty=l2, lr__C=1.3786990543 ...................\n",
      "[CV] .... sel__k=60, lr__penalty=l2, lr__C=1.3786990543, total=  13.1s\n",
      "[CV] sel__k=14, lr__penalty=l1, lr__C=5.22278293793 ..................\n",
      "[CV] .... sel__k=60, lr__penalty=l2, lr__C=1.3786990543, total=  14.8s\n",
      "[CV] sel__k=14, lr__penalty=l1, lr__C=5.22278293793 ..................\n",
      "[CV] .... sel__k=60, lr__penalty=l2, lr__C=1.3786990543, total=  15.3s\n",
      "[CV] sel__k=14, lr__penalty=l1, lr__C=5.22278293793 ..................\n",
      "[CV] .... sel__k=60, lr__penalty=l2, lr__C=1.3786990543, total=  14.1s\n",
      "[CV] sel__k=14, lr__penalty=l1, lr__C=5.22278293793 ..................\n",
      "[CV] .... sel__k=60, lr__penalty=l2, lr__C=1.3786990543, total=  13.2s\n",
      "[CV] .... sel__k=60, lr__penalty=l2, lr__C=1.3786990543, total=  13.6s\n",
      "[CV] sel__k=14, lr__penalty=l1, lr__C=5.22278293793 ..................\n",
      "[CV] sel__k=14, lr__penalty=l1, lr__C=5.22278293793 ..................\n",
      "[CV] .... sel__k=60, lr__penalty=l2, lr__C=1.3786990543, total=  14.4s\n",
      "[CV] sel__k=14, lr__penalty=l1, lr__C=5.22278293793 ..................\n",
      "[CV] .... sel__k=60, lr__penalty=l2, lr__C=1.3786990543, total=  12.9s\n",
      "[CV] sel__k=14, lr__penalty=l1, lr__C=5.22278293793 ..................\n",
      "[CV] .... sel__k=60, lr__penalty=l2, lr__C=1.3786990543, total=  12.6s\n",
      "[CV] .... sel__k=60, lr__penalty=l2, lr__C=1.3786990543, total=  12.8s\n",
      "[CV] sel__k=14, lr__penalty=l1, lr__C=5.22278293793 ..................\n",
      "[CV] sel__k=14, lr__penalty=l1, lr__C=5.22278293793 ..................\n",
      "[CV] ... sel__k=14, lr__penalty=l1, lr__C=5.22278293793, total=  13.4s\n",
      "[CV] sel__k=57, lr__penalty=l2, lr__C=6.08195434381 ..................\n",
      "[CV] ... sel__k=14, lr__penalty=l1, lr__C=5.22278293793, total=  12.2s\n",
      "[CV] sel__k=57, lr__penalty=l2, lr__C=6.08195434381 ..................\n",
      "[CV] ... sel__k=14, lr__penalty=l1, lr__C=5.22278293793, total=  12.3s\n",
      "[CV] sel__k=57, lr__penalty=l2, lr__C=6.08195434381 ..................\n",
      "[CV] ... sel__k=14, lr__penalty=l1, lr__C=5.22278293793, total=  12.1s\n",
      "[CV] sel__k=57, lr__penalty=l2, lr__C=6.08195434381 ..................\n",
      "[CV] ... sel__k=14, lr__penalty=l1, lr__C=5.22278293793, total=  12.3s\n",
      "[CV] sel__k=57, lr__penalty=l2, lr__C=6.08195434381 ..................\n",
      "[CV] ... sel__k=14, lr__penalty=l1, lr__C=5.22278293793, total=  11.9s\n",
      "[CV] ... sel__k=14, lr__penalty=l1, lr__C=5.22278293793, total=  12.1s\n",
      "[CV] sel__k=57, lr__penalty=l2, lr__C=6.08195434381 ..................\n",
      "[CV] sel__k=57, lr__penalty=l2, lr__C=6.08195434381 ..................\n",
      "[CV] ... sel__k=14, lr__penalty=l1, lr__C=5.22278293793, total=  11.6s\n",
      "[CV] sel__k=57, lr__penalty=l2, lr__C=6.08195434381 ..................\n",
      "[CV] ... sel__k=14, lr__penalty=l1, lr__C=5.22278293793, total=  11.6s\n",
      "[CV] sel__k=57, lr__penalty=l2, lr__C=6.08195434381 ..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... sel__k=14, lr__penalty=l1, lr__C=5.22278293793, total=  12.5s\n",
      "[CV] sel__k=57, lr__penalty=l2, lr__C=6.08195434381 ..................\n",
      "[CV] ... sel__k=57, lr__penalty=l2, lr__C=6.08195434381, total=  13.0s\n",
      "[CV] sel__k=90, lr__penalty=l1, lr__C=3.76673712307 ..................\n",
      "[CV] ... sel__k=57, lr__penalty=l2, lr__C=6.08195434381, total=  13.4s\n",
      "[CV] sel__k=90, lr__penalty=l1, lr__C=3.76673712307 ..................\n",
      "[CV] ... sel__k=57, lr__penalty=l2, lr__C=6.08195434381, total=  12.8s\n",
      "[CV] sel__k=90, lr__penalty=l1, lr__C=3.76673712307 ..................\n",
      "[CV] ... sel__k=57, lr__penalty=l2, lr__C=6.08195434381, total=  13.1s\n",
      "[CV] sel__k=90, lr__penalty=l1, lr__C=3.76673712307 ..................\n",
      "[CV] ... sel__k=57, lr__penalty=l2, lr__C=6.08195434381, total=  13.6s\n",
      "[CV] sel__k=90, lr__penalty=l1, lr__C=3.76673712307 ..................\n",
      "[CV] ... sel__k=57, lr__penalty=l2, lr__C=6.08195434381, total=  13.8s\n",
      "[CV] sel__k=90, lr__penalty=l1, lr__C=3.76673712307 ..................\n",
      "[CV] ... sel__k=57, lr__penalty=l2, lr__C=6.08195434381, total=  14.2s\n",
      "[CV] sel__k=90, lr__penalty=l1, lr__C=3.76673712307 ..................\n",
      "[CV] ... sel__k=57, lr__penalty=l2, lr__C=6.08195434381, total=  14.2s\n",
      "[CV] sel__k=90, lr__penalty=l1, lr__C=3.76673712307 ..................\n",
      "[CV] ... sel__k=57, lr__penalty=l2, lr__C=6.08195434381, total=  14.0s\n",
      "[CV] sel__k=90, lr__penalty=l1, lr__C=3.76673712307 ..................\n",
      "[CV] ... sel__k=57, lr__penalty=l2, lr__C=6.08195434381, total=  13.1s\n",
      "[CV] sel__k=90, lr__penalty=l1, lr__C=3.76673712307 ..................\n",
      "[CV] ... sel__k=90, lr__penalty=l1, lr__C=3.76673712307, total=  14.1s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=4.73567649066 ..................\n",
      "[CV] ... sel__k=90, lr__penalty=l1, lr__C=3.76673712307, total=  13.7s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=4.73567649066 ..................\n",
      "[CV] ... sel__k=90, lr__penalty=l1, lr__C=3.76673712307, total=  14.2s\n",
      "[CV] ... sel__k=90, lr__penalty=l1, lr__C=3.76673712307, total=  13.2s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=4.73567649066 ..................\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=4.73567649066 ..................\n",
      "[CV] ... sel__k=90, lr__penalty=l1, lr__C=3.76673712307, total=  13.3s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=4.73567649066 ..................\n",
      "[CV] ... sel__k=90, lr__penalty=l1, lr__C=3.76673712307, total=  14.9s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=4.73567649066 ..................\n",
      "[CV] ... sel__k=90, lr__penalty=l1, lr__C=3.76673712307, total=  14.2s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=4.73567649066 ..................\n",
      "[CV] ... sel__k=90, lr__penalty=l1, lr__C=3.76673712307, total=  14.4s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=4.73567649066 ..................\n",
      "[CV] ... sel__k=90, lr__penalty=l1, lr__C=3.76673712307, total=  15.2s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=4.73567649066 ..................\n",
      "[CV] ... sel__k=90, lr__penalty=l1, lr__C=3.76673712307, total=  15.0s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=4.73567649066 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=4.73567649066, total=  13.9s\n",
      "[CV] sel__k=73, lr__penalty=l2, lr__C=4.27994225715 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=4.73567649066, total=  14.2s\n",
      "[CV] sel__k=73, lr__penalty=l2, lr__C=4.27994225715 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=4.73567649066, total=  13.1s\n",
      "[CV] sel__k=73, lr__penalty=l2, lr__C=4.27994225715 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=4.73567649066, total=  14.6s\n",
      "[CV] sel__k=73, lr__penalty=l2, lr__C=4.27994225715 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=4.73567649066, total=  13.6s\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=4.73567649066, total=  14.2s\n",
      "[CV] sel__k=73, lr__penalty=l2, lr__C=4.27994225715 ..................\n",
      "[CV] sel__k=73, lr__penalty=l2, lr__C=4.27994225715 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=4.73567649066, total=  11.1s\n",
      "[CV] sel__k=73, lr__penalty=l2, lr__C=4.27994225715 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=4.73567649066, total=  14.6s\n",
      "[CV] sel__k=73, lr__penalty=l2, lr__C=4.27994225715 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=4.73567649066, total=  13.5s\n",
      "[CV] sel__k=73, lr__penalty=l2, lr__C=4.27994225715 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=4.73567649066, total=  12.9s\n",
      "[CV] sel__k=73, lr__penalty=l2, lr__C=4.27994225715 ..................\n",
      "[CV] ... sel__k=73, lr__penalty=l2, lr__C=4.27994225715, total=  11.6s\n",
      "[CV] sel__k=82, lr__penalty=l2, lr__C=8.80751273104 ..................\n",
      "[CV] ... sel__k=73, lr__penalty=l2, lr__C=4.27994225715, total=  13.0s\n",
      "[CV] ... sel__k=73, lr__penalty=l2, lr__C=4.27994225715, total=  12.9s\n",
      "[CV] sel__k=82, lr__penalty=l2, lr__C=8.80751273104 ..................\n",
      "[CV] sel__k=82, lr__penalty=l2, lr__C=8.80751273104 ..................\n",
      "[CV] ... sel__k=73, lr__penalty=l2, lr__C=4.27994225715, total=  12.8s\n",
      "[CV] ... sel__k=73, lr__penalty=l2, lr__C=4.27994225715, total=  12.5s\n",
      "[CV] sel__k=82, lr__penalty=l2, lr__C=8.80751273104 ..................\n",
      "[CV] sel__k=82, lr__penalty=l2, lr__C=8.80751273104 ..................\n",
      "[CV] ... sel__k=73, lr__penalty=l2, lr__C=4.27994225715, total=  12.6s\n",
      "[CV] sel__k=82, lr__penalty=l2, lr__C=8.80751273104 ..................\n",
      "[CV] ... sel__k=73, lr__penalty=l2, lr__C=4.27994225715, total=  12.7s\n",
      "[CV] ... sel__k=73, lr__penalty=l2, lr__C=4.27994225715, total=  13.6s\n",
      "[CV] sel__k=82, lr__penalty=l2, lr__C=8.80751273104 ..................\n",
      "[CV] sel__k=82, lr__penalty=l2, lr__C=8.80751273104 ..................\n",
      "[CV] ... sel__k=73, lr__penalty=l2, lr__C=4.27994225715, total=  14.5s\n",
      "[CV] sel__k=82, lr__penalty=l2, lr__C=8.80751273104 ..................\n",
      "[CV] ... sel__k=73, lr__penalty=l2, lr__C=4.27994225715, total=  14.1s\n",
      "[CV] sel__k=82, lr__penalty=l2, lr__C=8.80751273104 ..................\n",
      "[CV] ... sel__k=82, lr__penalty=l2, lr__C=8.80751273104, total=  12.6s\n",
      "[CV] ... sel__k=82, lr__penalty=l2, lr__C=8.80751273104, total=  13.1s\n",
      "[CV] sel__k=10, lr__penalty=l1, lr__C=10.5242228049 ..................\n",
      "[CV] sel__k=10, lr__penalty=l1, lr__C=10.5242228049 ..................\n",
      "[CV] ... sel__k=82, lr__penalty=l2, lr__C=8.80751273104, total=  13.6s\n",
      "[CV] sel__k=10, lr__penalty=l1, lr__C=10.5242228049 ..................\n",
      "[CV] ... sel__k=82, lr__penalty=l2, lr__C=8.80751273104, total=  14.1s\n",
      "[CV] sel__k=10, lr__penalty=l1, lr__C=10.5242228049 ..................\n",
      "[CV] ... sel__k=82, lr__penalty=l2, lr__C=8.80751273104, total=  13.4s\n",
      "[CV] sel__k=10, lr__penalty=l1, lr__C=10.5242228049 ..................\n",
      "[CV] ... sel__k=82, lr__penalty=l2, lr__C=8.80751273104, total=  13.1s\n",
      "[CV] sel__k=10, lr__penalty=l1, lr__C=10.5242228049 ..................\n",
      "[CV] ... sel__k=82, lr__penalty=l2, lr__C=8.80751273104, total=  14.9s\n",
      "[CV] ... sel__k=82, lr__penalty=l2, lr__C=8.80751273104, total=  13.3s\n",
      "[CV] sel__k=10, lr__penalty=l1, lr__C=10.5242228049 ..................\n",
      "[CV] sel__k=10, lr__penalty=l1, lr__C=10.5242228049 ..................\n",
      "[CV] ... sel__k=82, lr__penalty=l2, lr__C=8.80751273104, total=  13.6s\n",
      "[CV] sel__k=10, lr__penalty=l1, lr__C=10.5242228049 ..................\n",
      "[CV] ... sel__k=82, lr__penalty=l2, lr__C=8.80751273104, total=  14.5s\n",
      "[CV] sel__k=10, lr__penalty=l1, lr__C=10.5242228049 ..................\n",
      "[CV] ... sel__k=10, lr__penalty=l1, lr__C=10.5242228049, total=  13.6s\n",
      "[CV] sel__k=86, lr__penalty=l1, lr__C=10.7139282322 ..................\n",
      "[CV] ... sel__k=10, lr__penalty=l1, lr__C=10.5242228049, total=  14.5s\n",
      "[CV] sel__k=86, lr__penalty=l1, lr__C=10.7139282322 ..................\n",
      "[CV] ... sel__k=10, lr__penalty=l1, lr__C=10.5242228049, total=  15.0s\n",
      "[CV] sel__k=86, lr__penalty=l1, lr__C=10.7139282322 ..................\n",
      "[CV] ... sel__k=10, lr__penalty=l1, lr__C=10.5242228049, total=  15.2s\n",
      "[CV] sel__k=86, lr__penalty=l1, lr__C=10.7139282322 ..................\n",
      "[CV] ... sel__k=10, lr__penalty=l1, lr__C=10.5242228049, total=  14.0s\n",
      "[CV] sel__k=86, lr__penalty=l1, lr__C=10.7139282322 ..................\n",
      "[CV] ... sel__k=10, lr__penalty=l1, lr__C=10.5242228049, total=  13.7s\n",
      "[CV] sel__k=86, lr__penalty=l1, lr__C=10.7139282322 ..................\n",
      "[CV] ... sel__k=10, lr__penalty=l1, lr__C=10.5242228049, total=  15.3s\n",
      "[CV] sel__k=86, lr__penalty=l1, lr__C=10.7139282322 ..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... sel__k=10, lr__penalty=l1, lr__C=10.5242228049, total=  14.2s\n",
      "[CV] sel__k=86, lr__penalty=l1, lr__C=10.7139282322 ..................\n",
      "[CV] ... sel__k=10, lr__penalty=l1, lr__C=10.5242228049, total=  15.7s\n",
      "[CV] sel__k=86, lr__penalty=l1, lr__C=10.7139282322 ..................\n",
      "[CV] ... sel__k=10, lr__penalty=l1, lr__C=10.5242228049, total=  14.4s\n",
      "[CV] sel__k=86, lr__penalty=l1, lr__C=10.7139282322 ..................\n",
      "[CV] ... sel__k=86, lr__penalty=l1, lr__C=10.7139282322, total=  13.6s\n",
      "[CV] sel__k=26, lr__penalty=l2, lr__C=3.23995917628 ..................\n",
      "[CV] ... sel__k=86, lr__penalty=l1, lr__C=10.7139282322, total=  14.6s\n",
      "[CV] ... sel__k=86, lr__penalty=l1, lr__C=10.7139282322, total=  15.1s\n",
      "[CV] sel__k=26, lr__penalty=l2, lr__C=3.23995917628 ..................\n",
      "[CV] sel__k=26, lr__penalty=l2, lr__C=3.23995917628 ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done 142 tasks      | elapsed:  6.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... sel__k=86, lr__penalty=l1, lr__C=10.7139282322, total=  14.4s\n",
      "[CV] ... sel__k=86, lr__penalty=l1, lr__C=10.7139282322, total=  13.7s\n",
      "[CV] ... sel__k=86, lr__penalty=l1, lr__C=10.7139282322, total=  13.7s\n",
      "[CV] sel__k=26, lr__penalty=l2, lr__C=3.23995917628 ..................\n",
      "[CV] sel__k=26, lr__penalty=l2, lr__C=3.23995917628 ..................\n",
      "[CV] sel__k=26, lr__penalty=l2, lr__C=3.23995917628 ..................\n",
      "[CV] ... sel__k=86, lr__penalty=l1, lr__C=10.7139282322, total=  14.8s\n",
      "[CV] sel__k=26, lr__penalty=l2, lr__C=3.23995917628 ..................\n",
      "[CV] ... sel__k=86, lr__penalty=l1, lr__C=10.7139282322, total=  14.0s\n",
      "[CV] ... sel__k=86, lr__penalty=l1, lr__C=10.7139282322, total=  14.3s\n",
      "[CV] sel__k=26, lr__penalty=l2, lr__C=3.23995917628 ..................\n",
      "[CV] sel__k=26, lr__penalty=l2, lr__C=3.23995917628 ..................\n",
      "[CV] ... sel__k=86, lr__penalty=l1, lr__C=10.7139282322, total=  14.1s\n",
      "[CV] sel__k=26, lr__penalty=l2, lr__C=3.23995917628 ..................\n",
      "[CV] ... sel__k=26, lr__penalty=l2, lr__C=3.23995917628, total=  11.8s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=9.31753339738 ..................\n",
      "[CV] ... sel__k=26, lr__penalty=l2, lr__C=3.23995917628, total=  11.2s\n",
      "[CV] ... sel__k=26, lr__penalty=l2, lr__C=3.23995917628, total=  11.6s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=9.31753339738 ..................\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=9.31753339738 ..................\n",
      "[CV] ... sel__k=26, lr__penalty=l2, lr__C=3.23995917628, total=  10.6s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=9.31753339738 ..................\n",
      "[CV] ... sel__k=26, lr__penalty=l2, lr__C=3.23995917628, total=  11.6s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=9.31753339738 ..................\n",
      "[CV] ... sel__k=26, lr__penalty=l2, lr__C=3.23995917628, total=  11.4s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=9.31753339738 ..................\n",
      "[CV] ... sel__k=26, lr__penalty=l2, lr__C=3.23995917628, total=  11.0s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=9.31753339738 ..................\n",
      "[CV] ... sel__k=26, lr__penalty=l2, lr__C=3.23995917628, total=  12.0s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=9.31753339738 ..................\n",
      "[CV] ... sel__k=26, lr__penalty=l2, lr__C=3.23995917628, total=  12.5s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=9.31753339738 ..................\n",
      "[CV] ... sel__k=26, lr__penalty=l2, lr__C=3.23995917628, total=  11.4s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=9.31753339738 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=9.31753339738, total=  13.3s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=4.16907772216 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=9.31753339738, total=  13.4s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=4.16907772216 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=9.31753339738, total=  13.8s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=4.16907772216 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=9.31753339738, total=  13.9s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=4.16907772216 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=9.31753339738, total=  13.3s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=4.16907772216 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=9.31753339738, total=  13.2s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=4.16907772216 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=9.31753339738, total=  13.2s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=4.16907772216 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=9.31753339738, total=  12.8s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=4.16907772216 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=9.31753339738, total=  13.7s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=4.16907772216 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=9.31753339738, total=  13.8s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=4.16907772216 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=4.16907772216, total=  12.0s\n",
      "[CV] sel__k=58, lr__penalty=l2, lr__C=2.37304636839 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=4.16907772216, total=  11.6s\n",
      "[CV] sel__k=58, lr__penalty=l2, lr__C=2.37304636839 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=4.16907772216, total=  11.6s\n",
      "[CV] sel__k=58, lr__penalty=l2, lr__C=2.37304636839 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=4.16907772216, total=  12.4s\n",
      "[CV] sel__k=58, lr__penalty=l2, lr__C=2.37304636839 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=4.16907772216, total=  12.0s\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=4.16907772216, total=  12.1s\n",
      "[CV] sel__k=58, lr__penalty=l2, lr__C=2.37304636839 ..................\n",
      "[CV] sel__k=58, lr__penalty=l2, lr__C=2.37304636839 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=4.16907772216, total=  11.9s\n",
      "[CV] sel__k=58, lr__penalty=l2, lr__C=2.37304636839 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=4.16907772216, total=  12.6s\n",
      "[CV] sel__k=58, lr__penalty=l2, lr__C=2.37304636839 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=4.16907772216, total=  11.5s\n",
      "[CV] sel__k=58, lr__penalty=l2, lr__C=2.37304636839 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=4.16907772216, total=  11.1s\n",
      "[CV] sel__k=58, lr__penalty=l2, lr__C=2.37304636839 ..................\n",
      "[CV] ... sel__k=58, lr__penalty=l2, lr__C=2.37304636839, total=  13.4s\n",
      "[CV] sel__k=96, lr__penalty=l2, lr__C=4.78533773825 ..................\n",
      "[CV] ... sel__k=58, lr__penalty=l2, lr__C=2.37304636839, total=  12.7s\n",
      "[CV] sel__k=96, lr__penalty=l2, lr__C=4.78533773825 ..................\n",
      "[CV] ... sel__k=58, lr__penalty=l2, lr__C=2.37304636839, total=  13.1s\n",
      "[CV] sel__k=96, lr__penalty=l2, lr__C=4.78533773825 ..................\n",
      "[CV] ... sel__k=58, lr__penalty=l2, lr__C=2.37304636839, total=  13.5s\n",
      "[CV] sel__k=96, lr__penalty=l2, lr__C=4.78533773825 ..................\n",
      "[CV] ... sel__k=58, lr__penalty=l2, lr__C=2.37304636839, total=  13.5s\n",
      "[CV] sel__k=96, lr__penalty=l2, lr__C=4.78533773825 ..................\n",
      "[CV] ... sel__k=58, lr__penalty=l2, lr__C=2.37304636839, total=  13.8s\n",
      "[CV] sel__k=96, lr__penalty=l2, lr__C=4.78533773825 ..................\n",
      "[CV] ... sel__k=58, lr__penalty=l2, lr__C=2.37304636839, total=  14.1s\n",
      "[CV] sel__k=96, lr__penalty=l2, lr__C=4.78533773825 ..................\n",
      "[CV] ... sel__k=58, lr__penalty=l2, lr__C=2.37304636839, total=  13.9s\n",
      "[CV] sel__k=96, lr__penalty=l2, lr__C=4.78533773825 ..................\n",
      "[CV] ... sel__k=58, lr__penalty=l2, lr__C=2.37304636839, total=  13.4s\n",
      "[CV] sel__k=96, lr__penalty=l2, lr__C=4.78533773825 ..................\n",
      "[CV] ... sel__k=58, lr__penalty=l2, lr__C=2.37304636839, total=  13.3s\n",
      "[CV] sel__k=96, lr__penalty=l2, lr__C=4.78533773825 ..................\n",
      "[CV] ... sel__k=96, lr__penalty=l2, lr__C=4.78533773825, total=  12.3s\n",
      "[CV] sel__k=92, lr__penalty=l1, lr__C=9.72464547452 ..................\n",
      "[CV] ... sel__k=96, lr__penalty=l2, lr__C=4.78533773825, total=  12.5s\n",
      "[CV] sel__k=92, lr__penalty=l1, lr__C=9.72464547452 ..................\n",
      "[CV] ... sel__k=96, lr__penalty=l2, lr__C=4.78533773825, total=  12.5s\n",
      "[CV] sel__k=92, lr__penalty=l1, lr__C=9.72464547452 ..................\n",
      "[CV] ... sel__k=96, lr__penalty=l2, lr__C=4.78533773825, total=  11.8s\n",
      "[CV] sel__k=92, lr__penalty=l1, lr__C=9.72464547452 ..................\n",
      "[CV] ... sel__k=96, lr__penalty=l2, lr__C=4.78533773825, total=  12.4s\n",
      "[CV] sel__k=92, lr__penalty=l1, lr__C=9.72464547452 ..................\n",
      "[CV] ... sel__k=96, lr__penalty=l2, lr__C=4.78533773825, total=  12.6s\n",
      "[CV] sel__k=92, lr__penalty=l1, lr__C=9.72464547452 ..................\n",
      "[CV] ... sel__k=96, lr__penalty=l2, lr__C=4.78533773825, total=  12.3s\n",
      "[CV] sel__k=92, lr__penalty=l1, lr__C=9.72464547452 ..................\n",
      "[CV] ... sel__k=96, lr__penalty=l2, lr__C=4.78533773825, total=  12.7s\n",
      "[CV] sel__k=92, lr__penalty=l1, lr__C=9.72464547452 ..................\n",
      "[CV] ... sel__k=96, lr__penalty=l2, lr__C=4.78533773825, total=  12.5s\n",
      "[CV] sel__k=92, lr__penalty=l1, lr__C=9.72464547452 ..................\n",
      "[CV] ... sel__k=96, lr__penalty=l2, lr__C=4.78533773825, total=  12.1s\n",
      "[CV] sel__k=92, lr__penalty=l1, lr__C=9.72464547452 ..................\n",
      "[CV] ... sel__k=92, lr__penalty=l1, lr__C=9.72464547452, total=  15.7s\n",
      "[CV] sel__k=95, lr__penalty=l1, lr__C=7.92821838704 ..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... sel__k=92, lr__penalty=l1, lr__C=9.72464547452, total=  15.4s\n",
      "[CV] sel__k=95, lr__penalty=l1, lr__C=7.92821838704 ..................\n",
      "[CV] ... sel__k=92, lr__penalty=l1, lr__C=9.72464547452, total=  15.8s\n",
      "[CV] sel__k=95, lr__penalty=l1, lr__C=7.92821838704 ..................\n",
      "[CV] ... sel__k=92, lr__penalty=l1, lr__C=9.72464547452, total=  16.0s\n",
      "[CV] sel__k=95, lr__penalty=l1, lr__C=7.92821838704 ..................\n",
      "[CV] ... sel__k=92, lr__penalty=l1, lr__C=9.72464547452, total=  16.1s\n",
      "[CV] sel__k=95, lr__penalty=l1, lr__C=7.92821838704 ..................\n",
      "[CV] ... sel__k=92, lr__penalty=l1, lr__C=9.72464547452, total=  16.8s\n",
      "[CV] sel__k=95, lr__penalty=l1, lr__C=7.92821838704 ..................\n",
      "[CV] ... sel__k=92, lr__penalty=l1, lr__C=9.72464547452, total=  16.5s\n",
      "[CV] sel__k=95, lr__penalty=l1, lr__C=7.92821838704 ..................\n",
      "[CV] ... sel__k=92, lr__penalty=l1, lr__C=9.72464547452, total=  16.6s\n",
      "[CV] sel__k=95, lr__penalty=l1, lr__C=7.92821838704 ..................\n",
      "[CV] ... sel__k=92, lr__penalty=l1, lr__C=9.72464547452, total=  17.7s\n",
      "[CV] sel__k=95, lr__penalty=l1, lr__C=7.92821838704 ..................\n",
      "[CV] ... sel__k=92, lr__penalty=l1, lr__C=9.72464547452, total=  17.0s\n",
      "[CV] sel__k=95, lr__penalty=l1, lr__C=7.92821838704 ..................\n",
      "[CV] ... sel__k=95, lr__penalty=l1, lr__C=7.92821838704, total=  14.1s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=2.03260785103 ..................\n",
      "[CV] ... sel__k=95, lr__penalty=l1, lr__C=7.92821838704, total=  14.4s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=2.03260785103 ..................\n",
      "[CV] ... sel__k=95, lr__penalty=l1, lr__C=7.92821838704, total=  14.6s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=2.03260785103 ..................\n",
      "[CV] ... sel__k=95, lr__penalty=l1, lr__C=7.92821838704, total=  15.0s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=2.03260785103 ..................\n",
      "[CV] ... sel__k=95, lr__penalty=l1, lr__C=7.92821838704, total=  13.7s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=2.03260785103 ..................\n",
      "[CV] ... sel__k=95, lr__penalty=l1, lr__C=7.92821838704, total=  14.4s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=2.03260785103 ..................\n",
      "[CV] ... sel__k=95, lr__penalty=l1, lr__C=7.92821838704, total=  15.7s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=2.03260785103 ..................\n",
      "[CV] ... sel__k=95, lr__penalty=l1, lr__C=7.92821838704, total=  15.9s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=2.03260785103 ..................\n",
      "[CV] ... sel__k=95, lr__penalty=l1, lr__C=7.92821838704, total=  15.0s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=2.03260785103 ..................\n",
      "[CV] ... sel__k=95, lr__penalty=l1, lr__C=7.92821838704, total=  15.1s\n",
      "[CV] sel__k=94, lr__penalty=l2, lr__C=2.03260785103 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=2.03260785103, total=  13.7s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=5.72424738769 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=2.03260785103, total=  13.3s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=5.72424738769 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=2.03260785103, total=  14.1s\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=2.03260785103, total=  14.2s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=5.72424738769 ..................\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=5.72424738769 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=2.03260785103, total=  14.6s\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=2.03260785103, total=  13.0s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=5.72424738769 ..................\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=5.72424738769 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=2.03260785103, total=  15.5s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=5.72424738769 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=2.03260785103, total=  13.8s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=5.72424738769 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=2.03260785103, total=  14.4s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=5.72424738769 ..................\n",
      "[CV] ... sel__k=94, lr__penalty=l2, lr__C=2.03260785103, total=  15.7s\n",
      "[CV] sel__k=23, lr__penalty=l1, lr__C=5.72424738769 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=5.72424738769, total=  12.9s\n",
      "[CV] sel__k=95, lr__penalty=l2, lr__C=1.24807181818 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=5.72424738769, total=  12.7s\n",
      "[CV] sel__k=95, lr__penalty=l2, lr__C=1.24807181818 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=5.72424738769, total=  12.4s\n",
      "[CV] sel__k=95, lr__penalty=l2, lr__C=1.24807181818 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=5.72424738769, total=  12.8s\n",
      "[CV] sel__k=95, lr__penalty=l2, lr__C=1.24807181818 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=5.72424738769, total=  12.1s\n",
      "[CV] sel__k=95, lr__penalty=l2, lr__C=1.24807181818 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=5.72424738769, total=  12.2s\n",
      "[CV] sel__k=95, lr__penalty=l2, lr__C=1.24807181818 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=5.72424738769, total=  12.9s\n",
      "[CV] sel__k=95, lr__penalty=l2, lr__C=1.24807181818 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=5.72424738769, total=  11.9s\n",
      "[CV] sel__k=95, lr__penalty=l2, lr__C=1.24807181818 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=5.72424738769, total=  11.8s\n",
      "[CV] sel__k=95, lr__penalty=l2, lr__C=1.24807181818 ..................\n",
      "[CV] ... sel__k=23, lr__penalty=l1, lr__C=5.72424738769, total=  11.9s\n",
      "[CV] sel__k=95, lr__penalty=l2, lr__C=1.24807181818 ..................\n",
      "[CV] ... sel__k=95, lr__penalty=l2, lr__C=1.24807181818, total=  18.5s\n",
      "[CV] sel__k=56, lr__penalty=l2, lr__C=7.2265832397 ...................\n",
      "[CV] ... sel__k=95, lr__penalty=l2, lr__C=1.24807181818, total=  15.0s\n",
      "[CV] ... sel__k=95, lr__penalty=l2, lr__C=1.24807181818, total=  16.4s\n",
      "[CV] sel__k=56, lr__penalty=l2, lr__C=7.2265832397 ...................\n",
      "[CV] sel__k=56, lr__penalty=l2, lr__C=7.2265832397 ...................\n",
      "[CV] ... sel__k=95, lr__penalty=l2, lr__C=1.24807181818, total=  16.0s\n",
      "[CV] sel__k=56, lr__penalty=l2, lr__C=7.2265832397 ...................\n",
      "[CV] ... sel__k=95, lr__penalty=l2, lr__C=1.24807181818, total=  15.5s\n",
      "[CV] sel__k=56, lr__penalty=l2, lr__C=7.2265832397 ...................\n",
      "[CV] ... sel__k=95, lr__penalty=l2, lr__C=1.24807181818, total=  14.5s\n",
      "[CV] sel__k=56, lr__penalty=l2, lr__C=7.2265832397 ...................\n",
      "[CV] ... sel__k=95, lr__penalty=l2, lr__C=1.24807181818, total=  16.5s\n",
      "[CV] sel__k=56, lr__penalty=l2, lr__C=7.2265832397 ...................\n",
      "[CV] ... sel__k=95, lr__penalty=l2, lr__C=1.24807181818, total=  15.4s\n",
      "[CV] sel__k=56, lr__penalty=l2, lr__C=7.2265832397 ...................\n",
      "[CV] ... sel__k=95, lr__penalty=l2, lr__C=1.24807181818, total=  16.1s\n",
      "[CV] sel__k=56, lr__penalty=l2, lr__C=7.2265832397 ...................\n",
      "[CV] ... sel__k=95, lr__penalty=l2, lr__C=1.24807181818, total=  15.8s\n",
      "[CV] sel__k=56, lr__penalty=l2, lr__C=7.2265832397 ...................\n",
      "[CV] .... sel__k=56, lr__penalty=l2, lr__C=7.2265832397, total=  13.0s\n",
      "[CV] sel__k=12, lr__penalty=l1, lr__C=4.87270784864 ..................\n",
      "[CV] .... sel__k=56, lr__penalty=l2, lr__C=7.2265832397, total=  12.8s\n",
      "[CV] sel__k=12, lr__penalty=l1, lr__C=4.87270784864 ..................\n",
      "[CV] .... sel__k=56, lr__penalty=l2, lr__C=7.2265832397, total=  12.9s\n",
      "[CV] sel__k=12, lr__penalty=l1, lr__C=4.87270784864 ..................\n",
      "[CV] .... sel__k=56, lr__penalty=l2, lr__C=7.2265832397, total=  12.5s\n",
      "[CV] sel__k=12, lr__penalty=l1, lr__C=4.87270784864 ..................\n",
      "[CV] .... sel__k=56, lr__penalty=l2, lr__C=7.2265832397, total=  12.9s\n",
      "[CV] sel__k=12, lr__penalty=l1, lr__C=4.87270784864 ..................\n",
      "[CV] .... sel__k=56, lr__penalty=l2, lr__C=7.2265832397, total=  13.4s\n",
      "[CV] sel__k=12, lr__penalty=l1, lr__C=4.87270784864 ..................\n",
      "[CV] .... sel__k=56, lr__penalty=l2, lr__C=7.2265832397, total=  12.5s\n",
      "[CV] sel__k=12, lr__penalty=l1, lr__C=4.87270784864 ..................\n",
      "[CV] .... sel__k=56, lr__penalty=l2, lr__C=7.2265832397, total=  12.8s\n",
      "[CV] sel__k=12, lr__penalty=l1, lr__C=4.87270784864 ..................\n",
      "[CV] .... sel__k=56, lr__penalty=l2, lr__C=7.2265832397, total=  12.7s\n",
      "[CV] sel__k=12, lr__penalty=l1, lr__C=4.87270784864 ..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... sel__k=56, lr__penalty=l2, lr__C=7.2265832397, total=  12.5s\n",
      "[CV] sel__k=12, lr__penalty=l1, lr__C=4.87270784864 ..................\n",
      "[CV] ... sel__k=12, lr__penalty=l1, lr__C=4.87270784864, total=  14.9s\n",
      "[CV] ... sel__k=12, lr__penalty=l1, lr__C=4.87270784864, total=  14.6s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=4.58178134603 ..................\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=4.58178134603 ..................\n",
      "[CV] ... sel__k=12, lr__penalty=l1, lr__C=4.87270784864, total=  16.9s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=4.58178134603 ..................\n",
      "[CV] ... sel__k=12, lr__penalty=l1, lr__C=4.87270784864, total=  15.2s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=4.58178134603 ..................\n",
      "[CV] ... sel__k=12, lr__penalty=l1, lr__C=4.87270784864, total=  15.8s\n",
      "[CV] ... sel__k=12, lr__penalty=l1, lr__C=4.87270784864, total=  16.6s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=4.58178134603 ..................\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=4.58178134603 ..................\n",
      "[CV] ... sel__k=12, lr__penalty=l1, lr__C=4.87270784864, total=  16.8s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=4.58178134603 ..................\n",
      "[CV] ... sel__k=12, lr__penalty=l1, lr__C=4.87270784864, total=  16.3s\n",
      "[CV] ... sel__k=12, lr__penalty=l1, lr__C=4.87270784864, total=  15.7s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=4.58178134603 ..................\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=4.58178134603 ..................\n",
      "[CV] ... sel__k=12, lr__penalty=l1, lr__C=4.87270784864, total=  16.2s\n",
      "[CV] sel__k=27, lr__penalty=l1, lr__C=4.58178134603 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=4.58178134603, total=  13.1s\n",
      "[CV] sel__k=33, lr__penalty=l1, lr__C=10.8960560404 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=4.58178134603, total=  14.0s\n",
      "[CV] sel__k=33, lr__penalty=l1, lr__C=10.8960560404 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=4.58178134603, total=  13.1s\n",
      "[CV] sel__k=33, lr__penalty=l1, lr__C=10.8960560404 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=4.58178134603, total=  13.6s\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=4.58178134603, total=  12.9s\n",
      "[CV] sel__k=33, lr__penalty=l1, lr__C=10.8960560404 ..................\n",
      "[CV] sel__k=33, lr__penalty=l1, lr__C=10.8960560404 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=4.58178134603, total=  13.0s\n",
      "[CV] sel__k=33, lr__penalty=l1, lr__C=10.8960560404 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=4.58178134603, total=  11.8s\n",
      "[CV] sel__k=33, lr__penalty=l1, lr__C=10.8960560404 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=4.58178134603, total=  12.9s\n",
      "[CV] sel__k=33, lr__penalty=l1, lr__C=10.8960560404 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=4.58178134603, total=  13.0s\n",
      "[CV] sel__k=33, lr__penalty=l1, lr__C=10.8960560404 ..................\n",
      "[CV] ... sel__k=27, lr__penalty=l1, lr__C=4.58178134603, total=  12.5s\n",
      "[CV] sel__k=33, lr__penalty=l1, lr__C=10.8960560404 ..................\n",
      "[CV] ... sel__k=33, lr__penalty=l1, lr__C=10.8960560404, total=  13.8s\n",
      "[CV] sel__k=77, lr__penalty=l2, lr__C=5.4187034997 ...................\n",
      "[CV] ... sel__k=33, lr__penalty=l1, lr__C=10.8960560404, total=  13.4s\n",
      "[CV] sel__k=77, lr__penalty=l2, lr__C=5.4187034997 ...................\n",
      "[CV] ... sel__k=33, lr__penalty=l1, lr__C=10.8960560404, total=  13.9s\n",
      "[CV] sel__k=77, lr__penalty=l2, lr__C=5.4187034997 ...................\n",
      "[CV] ... sel__k=33, lr__penalty=l1, lr__C=10.8960560404, total=  14.7s\n",
      "[CV] sel__k=77, lr__penalty=l2, lr__C=5.4187034997 ...................\n",
      "[CV] ... sel__k=33, lr__penalty=l1, lr__C=10.8960560404, total=  15.2s\n",
      "[CV] sel__k=77, lr__penalty=l2, lr__C=5.4187034997 ...................\n",
      "[CV] ... sel__k=33, lr__penalty=l1, lr__C=10.8960560404, total=  15.1s\n",
      "[CV] sel__k=77, lr__penalty=l2, lr__C=5.4187034997 ...................\n",
      "[CV] ... sel__k=33, lr__penalty=l1, lr__C=10.8960560404, total=  14.8s\n",
      "[CV] sel__k=77, lr__penalty=l2, lr__C=5.4187034997 ...................\n",
      "[CV] ... sel__k=33, lr__penalty=l1, lr__C=10.8960560404, total=  15.6s\n",
      "[CV] sel__k=77, lr__penalty=l2, lr__C=5.4187034997 ...................\n",
      "[CV] ... sel__k=33, lr__penalty=l1, lr__C=10.8960560404, total=  14.9s\n",
      "[CV] sel__k=77, lr__penalty=l2, lr__C=5.4187034997 ...................\n",
      "[CV] ... sel__k=33, lr__penalty=l1, lr__C=10.8960560404, total=  15.2s\n",
      "[CV] sel__k=77, lr__penalty=l2, lr__C=5.4187034997 ...................\n",
      "[CV] .... sel__k=77, lr__penalty=l2, lr__C=5.4187034997, total=  11.5s\n",
      "[CV] .... sel__k=77, lr__penalty=l2, lr__C=5.4187034997, total=  12.6s\n",
      "[CV] .... sel__k=77, lr__penalty=l2, lr__C=5.4187034997, total=  12.1s\n",
      "[CV] .... sel__k=77, lr__penalty=l2, lr__C=5.4187034997, total=  11.7s\n",
      "[CV] .... sel__k=77, lr__penalty=l2, lr__C=5.4187034997, total=  12.6s\n",
      "[CV] .... sel__k=77, lr__penalty=l2, lr__C=5.4187034997, total=  12.9s\n",
      "[CV] .... sel__k=77, lr__penalty=l2, lr__C=5.4187034997, total=  12.3s\n",
      "[CV] .... sel__k=77, lr__penalty=l2, lr__C=5.4187034997, total=  12.0s\n",
      "[CV] .... sel__k=77, lr__penalty=l2, lr__C=5.4187034997, total=  13.4s\n",
      "[CV] .... sel__k=77, lr__penalty=l2, lr__C=5.4187034997, total=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done 300 out of 300 | elapsed: 12.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "          fit_params={}, iid=True, n_iter=30, n_jobs=10,\n",
       "          param_distributions={'lr__penalty': ['l1', 'l2'], 'sel__k': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f62d1bda940>, 'lr__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f62d1bdada0>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__C': 9.7246454745155901, 'lr__penalty': 'l1', 'sel__k': 92}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...ty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip.set_params(lr__C=9.7246454745155901, lr__penalty='l1', sel__k= 92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68458093410108767"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56896551724137934"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.67162012345909827,\n",
       "  'log loss': 0.91051132060427487,\n",
       "  'precision': 0.68832502012240115,\n",
       "  'recall': 0.35845692800579576},\n",
       " {'accuracy': 0.61487566873781119,\n",
       "  'log loss': 1.1268338061300502,\n",
       "  'precision': 0.30549725096196501,\n",
       "  'recall': 0.25073505151541109}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_score(pip, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pips = utils.train_models_on_folds(pip, x_train, y_train, number=10)\n",
    "train_scores = utils.many_models_score(pips, x_train, y_train)\n",
    "test_scores = utils.many_models_score(pips, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.67178502879078694,\n",
       " 'log loss': 0.91371700148648782,\n",
       " 'precision': 0.74770644871658587,\n",
       " 'recall': 0.35658250875986219}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.64559386973180077,\n",
       " 'log loss': 1.0081681507658879,\n",
       " 'precision': 0.4296029661445443,\n",
       " 'recall': 0.27293231498868509}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('../embeddings/vecs_300.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/utils.py'>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pip = make_pipeline(utils.DocVectorizer(model, word_counts), LogisticRegression(C=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "docv = utils.DocVectorizer(model, word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=5, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.20063936, -1.22725852, -1.24465305])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, dx, dy, scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_vect = TfidfVectorizer(vocabulary=at_least_threshold)\n",
    "\n",
    "bin_vect.fit(x_train)\n",
    "\n",
    "selector = SelectKBest(chi2, k = 100)\n",
    "\n",
    "selector.fit(bin_vect.transform(x_train), y_train)\n",
    "\n",
    "np.argsort( selector.pvalues_ )\n",
    "\n",
    "best_words = [bin_vect.get_feature_names()[x] for x in np.argsort( selector.pvalues_ )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_docv = utils.DocVectorizer(model, {word:word_counts[word] for word in best_words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seldx, seldy = selected_docv.fit_transform(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.30440817, -1.33896912, -1.31460577])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, seldx, seldy, scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searcher = RandomizedSearchCV(LogisticRegression(), scoring='neg_log_loss', verbose=1, n_jobs=-1, n_iter=20, cv=10, param_distributions={'C': uniform(1,15), 'penalty':['l1', 'l2']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=20, n_jobs=-1,\n",
       "          param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f3f4fdbd710>, 'penalty': ['l1', 'l2']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring='neg_log_loss', verbose=1)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.fit(dx, dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0460811894184285"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = utils.train_models_on_folds(searcher.best_estimator_, dx, dy, number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dxtest, dytest = docv.transform(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "ensemble_scores = utils.many_models_score(models, dxtest, dytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.66218809980806137,\n",
       " 'log loss': 0.98649955103880727,\n",
       " 'precision': 0.33791303716608595,\n",
       " 'recall': 0.27579610070932298}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cands = [searcher.cv_results_['params'][x] for x in np.argsort(searcher.cv_results_['rank_test_score'])][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(**cand) for cand in cands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = utils.train_models_on_folds(models, dx, dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "ensemble_scores = utils.many_models_score(models, dxtest, dytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.66218809980806137,\n",
       " 'log loss': 0.98819026412080579,\n",
       " 'precision': 0.33397331565459976,\n",
       " 'recall': 0.27579610070932298}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = utils.train_many_models(models, dx, dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.66794625719769674,\n",
       " 'log loss': 0.98946741660850335,\n",
       " 'precision': 0.34033376118417102,\n",
       " 'recall': 0.28041098784443258}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.many_models_score(models, dxtest, dytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(500), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.72086175\n",
      "Iteration 2, loss = 1.44829777\n",
      "Iteration 3, loss = 1.38576722\n",
      "Iteration 4, loss = 1.35751718\n",
      "Iteration 5, loss = 1.33480084\n",
      "Iteration 6, loss = 1.30506453\n",
      "Iteration 7, loss = 1.27890205\n",
      "Iteration 8, loss = 1.25284499\n",
      "Iteration 9, loss = 1.22995741\n",
      "Iteration 10, loss = 1.20513485\n",
      "Iteration 11, loss = 1.18497562\n",
      "Iteration 12, loss = 1.16424031\n",
      "Iteration 13, loss = 1.14557184\n",
      "Iteration 14, loss = 1.12704396\n",
      "Iteration 15, loss = 1.10977782\n",
      "Iteration 16, loss = 1.09554599\n",
      "Iteration 17, loss = 1.08230994\n",
      "Iteration 18, loss = 1.06838353\n",
      "Iteration 19, loss = 1.05767938\n",
      "Iteration 20, loss = 1.04998671\n",
      "Iteration 21, loss = 1.03595619\n",
      "Iteration 22, loss = 1.02838789\n",
      "Iteration 23, loss = 1.02712686\n",
      "Iteration 24, loss = 1.01272081\n",
      "Iteration 25, loss = 1.00259279\n",
      "Iteration 26, loss = 0.99840891\n",
      "Iteration 27, loss = 0.99073569\n",
      "Iteration 28, loss = 0.98683816\n",
      "Iteration 29, loss = 0.98063744\n",
      "Iteration 30, loss = 0.97021806\n",
      "Iteration 31, loss = 0.96644066\n",
      "Iteration 32, loss = 0.95864405\n",
      "Iteration 33, loss = 0.95575823\n",
      "Iteration 34, loss = 0.94508841\n",
      "Iteration 35, loss = 0.94641301\n",
      "Iteration 36, loss = 0.94025552\n",
      "Iteration 37, loss = 0.93034812\n",
      "Iteration 38, loss = 0.92470174\n",
      "Iteration 39, loss = 0.92038653\n",
      "Iteration 40, loss = 0.91615873\n",
      "Iteration 41, loss = 0.91301649\n",
      "Iteration 42, loss = 0.91093129\n",
      "Iteration 43, loss = 0.90418124\n",
      "Iteration 44, loss = 0.90125535\n",
      "Iteration 45, loss = 0.90059568\n",
      "Iteration 46, loss = 0.89438149\n",
      "Iteration 47, loss = 0.88927920\n",
      "Iteration 48, loss = 0.88378559\n",
      "Iteration 49, loss = 0.89088216\n",
      "Iteration 50, loss = 0.88502261\n",
      "Iteration 51, loss = 0.88128719\n",
      "Iteration 52, loss = 0.87089118\n",
      "Iteration 53, loss = 0.87041156\n",
      "Iteration 54, loss = 0.87186604\n",
      "Iteration 55, loss = 0.86281428\n",
      "Iteration 56, loss = 0.85590477\n",
      "Iteration 57, loss = 0.85650362\n",
      "Iteration 58, loss = 0.84937618\n",
      "Iteration 59, loss = 0.85491600\n",
      "Iteration 60, loss = 0.84926620\n",
      "Iteration 61, loss = 0.84002964\n",
      "Iteration 62, loss = 0.84022333\n",
      "Iteration 63, loss = 0.83831099\n",
      "Iteration 64, loss = 0.83358607\n",
      "Iteration 65, loss = 0.83164318\n",
      "Iteration 66, loss = 0.83118360\n",
      "Iteration 67, loss = 0.82332054\n",
      "Iteration 68, loss = 0.82712838\n",
      "Iteration 69, loss = 0.82223383\n",
      "Iteration 70, loss = 0.82148394\n",
      "Iteration 71, loss = 0.81868568\n",
      "Iteration 72, loss = 0.81589901\n",
      "Iteration 73, loss = 0.81130403\n",
      "Iteration 74, loss = 0.80513627\n",
      "Iteration 75, loss = 0.80323564\n",
      "Iteration 76, loss = 0.80498990\n",
      "Iteration 77, loss = 0.80852529\n",
      "Iteration 78, loss = 0.81362136\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.69841989\n",
      "Iteration 2, loss = 1.42767871\n",
      "Iteration 3, loss = 1.38507179\n",
      "Iteration 4, loss = 1.35244833\n",
      "Iteration 5, loss = 1.31818150\n",
      "Iteration 6, loss = 1.28735619\n",
      "Iteration 7, loss = 1.25667259\n",
      "Iteration 8, loss = 1.23067135\n",
      "Iteration 9, loss = 1.20467094\n",
      "Iteration 10, loss = 1.18172922\n",
      "Iteration 11, loss = 1.15933052\n",
      "Iteration 12, loss = 1.14159986\n",
      "Iteration 13, loss = 1.12569394\n",
      "Iteration 14, loss = 1.11216453\n",
      "Iteration 15, loss = 1.09606399\n",
      "Iteration 16, loss = 1.08201080\n",
      "Iteration 17, loss = 1.07291236\n",
      "Iteration 18, loss = 1.06070004\n",
      "Iteration 19, loss = 1.04919108\n",
      "Iteration 20, loss = 1.04068161\n",
      "Iteration 21, loss = 1.03639462\n",
      "Iteration 22, loss = 1.02150337\n",
      "Iteration 23, loss = 1.01279758\n",
      "Iteration 24, loss = 1.00560070\n",
      "Iteration 25, loss = 0.99595759\n",
      "Iteration 26, loss = 0.98998271\n",
      "Iteration 27, loss = 0.98124686\n",
      "Iteration 28, loss = 0.97671318\n",
      "Iteration 29, loss = 0.96999617\n",
      "Iteration 30, loss = 0.96647798\n",
      "Iteration 31, loss = 0.95619190\n",
      "Iteration 32, loss = 0.94930965\n",
      "Iteration 33, loss = 0.94500165\n",
      "Iteration 34, loss = 0.94905691\n",
      "Iteration 35, loss = 0.93991864\n",
      "Iteration 36, loss = 0.93162137\n",
      "Iteration 37, loss = 0.92506881\n",
      "Iteration 38, loss = 0.92100150\n",
      "Iteration 39, loss = 0.91478165\n",
      "Iteration 40, loss = 0.91095785\n",
      "Iteration 41, loss = 0.90300600\n",
      "Iteration 42, loss = 0.89944288\n",
      "Iteration 43, loss = 0.90031260\n",
      "Iteration 44, loss = 0.89164262\n",
      "Iteration 45, loss = 0.88921019\n",
      "Iteration 46, loss = 0.88945359\n",
      "Iteration 47, loss = 0.88014969\n",
      "Iteration 48, loss = 0.88103071\n",
      "Iteration 49, loss = 0.88236129\n",
      "Iteration 50, loss = 0.87033156\n",
      "Iteration 51, loss = 0.87390949\n",
      "Iteration 52, loss = 0.87208250\n",
      "Iteration 53, loss = 0.85477096\n",
      "Iteration 54, loss = 0.85679129\n",
      "Iteration 55, loss = 0.85324067\n",
      "Iteration 56, loss = 0.85551368\n",
      "Iteration 57, loss = 0.85048001\n",
      "Iteration 58, loss = 0.84851610\n",
      "Iteration 59, loss = 0.83821653\n",
      "Iteration 60, loss = 0.83506525\n",
      "Iteration 61, loss = 0.83166533\n",
      "Iteration 62, loss = 0.82721031\n",
      "Iteration 63, loss = 0.82489157\n",
      "Iteration 64, loss = 0.82070612\n",
      "Iteration 65, loss = 0.82414378\n",
      "Iteration 66, loss = 0.81787601\n",
      "Iteration 67, loss = 0.81734863\n",
      "Iteration 68, loss = 0.81238187\n",
      "Iteration 69, loss = 0.81364384\n",
      "Iteration 70, loss = 0.81327691\n",
      "Iteration 71, loss = 0.81156809\n",
      "Iteration 72, loss = 0.80637542\n",
      "Iteration 73, loss = 0.79979327\n",
      "Iteration 74, loss = 0.79976815\n",
      "Iteration 75, loss = 0.80093797\n",
      "Iteration 76, loss = 0.79376568\n",
      "Iteration 77, loss = 0.78907206\n",
      "Iteration 78, loss = 0.78115469\n",
      "Iteration 79, loss = 0.77879662\n",
      "Iteration 80, loss = 0.77849769\n",
      "Iteration 81, loss = 0.78036121\n",
      "Iteration 82, loss = 0.77687694\n",
      "Iteration 83, loss = 0.77463118\n",
      "Iteration 84, loss = 0.76963372\n",
      "Iteration 85, loss = 0.76740066\n",
      "Iteration 86, loss = 0.76719594\n",
      "Iteration 87, loss = 0.77035447\n",
      "Iteration 88, loss = 0.75996337\n",
      "Iteration 89, loss = 0.76909028\n",
      "Iteration 90, loss = 0.77325995\n",
      "Iteration 91, loss = 0.76227230\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.66845187\n",
      "Iteration 2, loss = 1.43455180\n",
      "Iteration 3, loss = 1.38439067\n",
      "Iteration 4, loss = 1.36770989\n",
      "Iteration 5, loss = 1.34013014\n",
      "Iteration 6, loss = 1.31432004\n",
      "Iteration 7, loss = 1.28687905\n",
      "Iteration 8, loss = 1.26353351\n",
      "Iteration 9, loss = 1.23971156\n",
      "Iteration 10, loss = 1.22139485\n",
      "Iteration 11, loss = 1.20225487\n",
      "Iteration 12, loss = 1.18222159\n",
      "Iteration 13, loss = 1.16580820\n",
      "Iteration 14, loss = 1.15161160\n",
      "Iteration 15, loss = 1.13811773\n",
      "Iteration 16, loss = 1.12518437\n",
      "Iteration 17, loss = 1.11288192\n",
      "Iteration 18, loss = 1.10262956\n",
      "Iteration 19, loss = 1.09687980\n",
      "Iteration 20, loss = 1.08202862\n",
      "Iteration 21, loss = 1.07392405\n",
      "Iteration 22, loss = 1.06669114\n",
      "Iteration 23, loss = 1.05656658\n",
      "Iteration 24, loss = 1.05573905\n",
      "Iteration 25, loss = 1.04457189\n",
      "Iteration 26, loss = 1.03950048\n",
      "Iteration 27, loss = 1.03231901\n",
      "Iteration 28, loss = 1.02333852\n",
      "Iteration 29, loss = 1.01566167\n",
      "Iteration 30, loss = 1.01000940\n",
      "Iteration 31, loss = 1.00600789\n",
      "Iteration 32, loss = 0.99926928\n",
      "Iteration 33, loss = 0.99329770\n",
      "Iteration 34, loss = 0.98800230\n",
      "Iteration 35, loss = 0.98288587\n",
      "Iteration 36, loss = 0.97669128\n",
      "Iteration 37, loss = 0.97253511\n",
      "Iteration 38, loss = 0.97025465\n",
      "Iteration 39, loss = 0.96838863\n",
      "Iteration 40, loss = 0.96228899\n",
      "Iteration 41, loss = 0.95362476\n",
      "Iteration 42, loss = 0.94904998\n",
      "Iteration 43, loss = 0.94251911\n",
      "Iteration 44, loss = 0.93983339\n",
      "Iteration 45, loss = 0.94009419\n",
      "Iteration 46, loss = 0.93890034\n",
      "Iteration 47, loss = 0.94103390\n",
      "Iteration 48, loss = 0.92753204\n",
      "Iteration 49, loss = 0.91868693\n",
      "Iteration 50, loss = 0.92005865\n",
      "Iteration 51, loss = 0.91521272\n",
      "Iteration 52, loss = 0.90585672\n",
      "Iteration 53, loss = 0.90660361\n",
      "Iteration 54, loss = 0.90978928\n",
      "Iteration 55, loss = 0.90758683\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.6028777 ,  0.62302158,  0.64202899])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp, dx, dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dx, dy, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.85712305734319894, 'output_size': 8, 'architecture': 535, 'input_size': 300}\n",
      "{'dropout': 0.85712305734319894, 'output_size': 8, 'architecture': 535, 'input_size': 300}\n",
      "{'dropout': 0.85712305734319894, 'output_size': 8, 'architecture': 535, 'input_size': 300}\n",
      "{'dropout': 0.96786017589883555, 'output_size': 8, 'architecture': 464, 'input_size': 300}\n",
      "{'dropout': 0.96786017589883555, 'output_size': 8, 'architecture': 464, 'input_size': 300}\n",
      "{'dropout': 0.96786017589883555, 'output_size': 8, 'architecture': 464, 'input_size': 300}\n",
      "{'dropout': 0.67220344437713764, 'output_size': 8, 'architecture': 537, 'input_size': 300}\n",
      "{'dropout': 0.67220344437713764, 'output_size': 8, 'architecture': 537, 'input_size': 300}\n",
      "{'dropout': 0.67220344437713764, 'output_size': 8, 'architecture': 537, 'input_size': 300}\n",
      "{'dropout': 0.98126900293821895, 'output_size': 8, 'architecture': 658, 'input_size': 300}\n",
      "{'dropout': 0.98126900293821895, 'output_size': 8, 'architecture': 658, 'input_size': 300}\n",
      "{'dropout': 0.98126900293821895, 'output_size': 8, 'architecture': 658, 'input_size': 300}\n",
      "{'dropout': 0.81167128112179276, 'output_size': 8, 'architecture': 464, 'input_size': 300}\n",
      "{'dropout': 0.81167128112179276, 'output_size': 8, 'architecture': 464, 'input_size': 300}\n",
      "{'dropout': 0.81167128112179276, 'output_size': 8, 'architecture': 464, 'input_size': 300}\n",
      "{'dropout': 0.67077699304464522, 'output_size': 8, 'architecture': 408, 'input_size': 300}\n",
      "{'dropout': 0.67077699304464522, 'output_size': 8, 'architecture': 408, 'input_size': 300}\n",
      "{'dropout': 0.67077699304464522, 'output_size': 8, 'architecture': 408, 'input_size': 300}\n",
      "{'dropout': 0.66539063489282113, 'output_size': 8, 'architecture': 315, 'input_size': 300}\n",
      "{'dropout': 0.66539063489282113, 'output_size': 8, 'architecture': 315, 'input_size': 300}\n",
      "{'dropout': 0.66539063489282113, 'output_size': 8, 'architecture': 315, 'input_size': 300}\n",
      "{'dropout': 0.70627322834960005, 'output_size': 8, 'architecture': 596, 'input_size': 300}\n",
      "{'dropout': 0.70627322834960005, 'output_size': 8, 'architecture': 596, 'input_size': 300}\n",
      "{'dropout': 0.70627322834960005, 'output_size': 8, 'architecture': 596, 'input_size': 300}\n",
      "{'dropout': 0.91082661802555398, 'output_size': 8, 'architecture': 590, 'input_size': 300}\n",
      "{'dropout': 0.91082661802555398, 'output_size': 8, 'architecture': 590, 'input_size': 300}\n",
      "{'dropout': 0.91082661802555398, 'output_size': 8, 'architecture': 590, 'input_size': 300}\n",
      "{'dropout': 0.87023934604093012, 'output_size': 8, 'architecture': 551, 'input_size': 300}\n",
      "{'dropout': 0.87023934604093012, 'output_size': 8, 'architecture': 551, 'input_size': 300}\n",
      "{'dropout': 0.87023934604093012, 'output_size': 8, 'architecture': 551, 'input_size': 300}\n",
      "{'dropout': 0.92720412816328368, 'output_size': 8, 'architecture': 490, 'input_size': 300}\n",
      "{'dropout': 0.92720412816328368, 'output_size': 8, 'architecture': 490, 'input_size': 300}\n",
      "{'dropout': 0.92720412816328368, 'output_size': 8, 'architecture': 490, 'input_size': 300}\n",
      "{'dropout': 0.6163926044881094, 'output_size': 8, 'architecture': 662, 'input_size': 300}\n",
      "{'dropout': 0.6163926044881094, 'output_size': 8, 'architecture': 662, 'input_size': 300}\n",
      "{'dropout': 0.6163926044881094, 'output_size': 8, 'architecture': 662, 'input_size': 300}\n",
      "{'dropout': 0.76484355354691513, 'output_size': 8, 'architecture': 798, 'input_size': 300}\n",
      "{'dropout': 0.76484355354691513, 'output_size': 8, 'architecture': 798, 'input_size': 300}\n",
      "{'dropout': 0.76484355354691513, 'output_size': 8, 'architecture': 798, 'input_size': 300}\n",
      "{'dropout': 0.51574813497857142, 'output_size': 8, 'architecture': 567, 'input_size': 300}\n",
      "{'dropout': 0.51574813497857142, 'output_size': 8, 'architecture': 567, 'input_size': 300}\n",
      "{'dropout': 0.51574813497857142, 'output_size': 8, 'architecture': 567, 'input_size': 300}\n",
      "{'dropout': 0.73114303702998695, 'output_size': 8, 'architecture': 543, 'input_size': 300}\n",
      "{'dropout': 0.73114303702998695, 'output_size': 8, 'architecture': 543, 'input_size': 300}\n",
      "{'dropout': 0.73114303702998695, 'output_size': 8, 'architecture': 543, 'input_size': 300}\n",
      "{'dropout': 0.93814526397745102, 'output_size': 8, 'architecture': 768, 'input_size': 300}\n",
      "{'dropout': 0.93814526397745102, 'output_size': 8, 'architecture': 768, 'input_size': 300}\n",
      "{'dropout': 0.93814526397745102, 'output_size': 8, 'architecture': 768, 'input_size': 300}\n",
      "{'dropout': 0.9095921191604065, 'output_size': 8, 'architecture': 553, 'input_size': 300}\n",
      "{'dropout': 0.9095921191604065, 'output_size': 8, 'architecture': 553, 'input_size': 300}\n",
      "{'dropout': 0.9095921191604065, 'output_size': 8, 'architecture': 553, 'input_size': 300}\n",
      "{'dropout': 0.68220547662965347, 'output_size': 8, 'architecture': 650, 'input_size': 300}\n",
      "{'dropout': 0.68220547662965347, 'output_size': 8, 'architecture': 650, 'input_size': 300}\n",
      "{'dropout': 0.68220547662965347, 'output_size': 8, 'architecture': 650, 'input_size': 300}\n",
      "{'dropout': 0.55941402491146142, 'output_size': 8, 'architecture': 446, 'input_size': 300}\n",
      "{'dropout': 0.55941402491146142, 'output_size': 8, 'architecture': 446, 'input_size': 300}\n",
      "{'dropout': 0.55941402491146142, 'output_size': 8, 'architecture': 446, 'input_size': 300}\n",
      "{'dropout': 0.71071771029929931, 'output_size': 8, 'architecture': 674, 'input_size': 300}\n",
      "{'dropout': 0.71071771029929931, 'output_size': 8, 'architecture': 674, 'input_size': 300}\n",
      "{'dropout': 0.71071771029929931, 'output_size': 8, 'architecture': 674, 'input_size': 300}\n",
      "{'dropout': 0.63384001327728234, 'output_size': 8, 'architecture': 601, 'input_size': 300}\n",
      "{'dropout': 0.63384001327728234, 'output_size': 8, 'architecture': 601, 'input_size': 300}\n",
      "{'dropout': 0.63384001327728234, 'output_size': 8, 'architecture': 601, 'input_size': 300}\n",
      "{'dropout': 0.61078429613885432, 'output_size': 8, 'architecture': 606, 'input_size': 300}\n",
      "{'dropout': 0.61078429613885432, 'output_size': 8, 'architecture': 606, 'input_size': 300}\n",
      "{'dropout': 0.61078429613885432, 'output_size': 8, 'architecture': 606, 'input_size': 300}\n",
      "{'dropout': 0.60884511050123735, 'output_size': 8, 'architecture': 389, 'input_size': 300}\n",
      "{'dropout': 0.60884511050123735, 'output_size': 8, 'architecture': 389, 'input_size': 300}\n",
      "{'dropout': 0.60884511050123735, 'output_size': 8, 'architecture': 389, 'input_size': 300}\n",
      "{'dropout': 0.67658043355151576, 'output_size': 8, 'architecture': 492, 'input_size': 300}\n",
      "{'dropout': 0.67658043355151576, 'output_size': 8, 'architecture': 492, 'input_size': 300}\n",
      "{'dropout': 0.67658043355151576, 'output_size': 8, 'architecture': 492, 'input_size': 300}\n",
      "{'dropout': 0.77369081951742102, 'output_size': 8, 'architecture': 492, 'input_size': 300}\n",
      "{'dropout': 0.77369081951742102, 'output_size': 8, 'architecture': 492, 'input_size': 300}\n",
      "{'dropout': 0.77369081951742102, 'output_size': 8, 'architecture': 492, 'input_size': 300}\n",
      "{'dropout': 0.9112246963989783, 'output_size': 8, 'architecture': 345, 'input_size': 300}\n",
      "{'dropout': 0.9112246963989783, 'output_size': 8, 'architecture': 345, 'input_size': 300}\n",
      "{'dropout': 0.9112246963989783, 'output_size': 8, 'architecture': 345, 'input_size': 300}\n",
      "{'dropout': 0.75896836168560577, 'output_size': 8, 'architecture': 734, 'input_size': 300}\n",
      "{'dropout': 0.75896836168560577, 'output_size': 8, 'architecture': 734, 'input_size': 300}\n",
      "{'dropout': 0.75896836168560577, 'output_size': 8, 'architecture': 734, 'input_size': 300}\n",
      "{'dropout': 0.70644535187480528, 'output_size': 8, 'architecture': 480, 'input_size': 300}\n",
      "{'dropout': 0.70644535187480528, 'output_size': 8, 'architecture': 480, 'input_size': 300}\n",
      "{'dropout': 0.70644535187480528, 'output_size': 8, 'architecture': 480, 'input_size': 300}\n",
      "{'dropout': 0.92070942434669145, 'output_size': 8, 'architecture': 628, 'input_size': 300}\n",
      "{'dropout': 0.92070942434669145, 'output_size': 8, 'architecture': 628, 'input_size': 300}\n",
      "{'dropout': 0.92070942434669145, 'output_size': 8, 'architecture': 628, 'input_size': 300}\n",
      "{'dropout': 0.72018757249726673, 'output_size': 8, 'architecture': 378, 'input_size': 300}\n",
      "{'dropout': 0.72018757249726673, 'output_size': 8, 'architecture': 378, 'input_size': 300}\n",
      "{'dropout': 0.72018757249726673, 'output_size': 8, 'architecture': 378, 'input_size': 300}\n",
      "{'dropout': 0.65043824595266719, 'output_size': 8, 'architecture': 704, 'input_size': 300}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.65043824595266719, 'output_size': 8, 'architecture': 704, 'input_size': 300}\n",
      "{'dropout': 0.65043824595266719, 'output_size': 8, 'architecture': 704, 'input_size': 300}\n",
      "{'dropout': 0.53103273940932039, 'output_size': 8, 'architecture': 746, 'input_size': 300}\n",
      "{'dropout': 0.53103273940932039, 'output_size': 8, 'architecture': 746, 'input_size': 300}\n",
      "{'dropout': 0.53103273940932039, 'output_size': 8, 'architecture': 746, 'input_size': 300}\n",
      "{'dropout': 0.8946583862503048, 'output_size': 8, 'architecture': 604, 'input_size': 300}\n",
      "{'dropout': 0.8946583862503048, 'output_size': 8, 'architecture': 604, 'input_size': 300}\n",
      "{'dropout': 0.8946583862503048, 'output_size': 8, 'architecture': 604, 'input_size': 300}\n",
      "{'dropout': 0.57775814189672947, 'output_size': 8, 'architecture': 617, 'input_size': 300}\n",
      "{'dropout': 0.57775814189672947, 'output_size': 8, 'architecture': 617, 'input_size': 300}\n",
      "{'dropout': 0.57775814189672947, 'output_size': 8, 'architecture': 617, 'input_size': 300}\n",
      "{'dropout': 0.56278026150184435, 'output_size': 8, 'architecture': 530, 'input_size': 300}\n",
      "{'dropout': 0.56278026150184435, 'output_size': 8, 'architecture': 530, 'input_size': 300}\n",
      "{'dropout': 0.56278026150184435, 'output_size': 8, 'architecture': 530, 'input_size': 300}\n",
      "{'dropout': 0.7616438272152326, 'output_size': 8, 'architecture': 425, 'input_size': 300}\n",
      "{'dropout': 0.7616438272152326, 'output_size': 8, 'architecture': 425, 'input_size': 300}\n",
      "{'dropout': 0.7616438272152326, 'output_size': 8, 'architecture': 425, 'input_size': 300}\n",
      "{'dropout': 0.90409081766711064, 'output_size': 8, 'architecture': 303, 'input_size': 300}\n",
      "{'dropout': 0.90409081766711064, 'output_size': 8, 'architecture': 303, 'input_size': 300}\n",
      "{'dropout': 0.90409081766711064, 'output_size': 8, 'architecture': 303, 'input_size': 300}\n",
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n",
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n",
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n",
      "{'dropout': 0.53231748113453559, 'output_size': 8, 'architecture': 674, 'input_size': 300}\n",
      "{'dropout': 0.53231748113453559, 'output_size': 8, 'architecture': 674, 'input_size': 300}\n",
      "{'dropout': 0.53231748113453559, 'output_size': 8, 'architecture': 674, 'input_size': 300}\n",
      "{'dropout': 0.52398540615841149, 'output_size': 8, 'architecture': 672, 'input_size': 300}\n",
      "{'dropout': 0.52398540615841149, 'output_size': 8, 'architecture': 672, 'input_size': 300}\n",
      "{'dropout': 0.52398540615841149, 'output_size': 8, 'architecture': 672, 'input_size': 300}\n",
      "{'dropout': 0.66735440968573012, 'output_size': 8, 'architecture': 654, 'input_size': 300}\n",
      "{'dropout': 0.66735440968573012, 'output_size': 8, 'architecture': 654, 'input_size': 300}\n",
      "{'dropout': 0.66735440968573012, 'output_size': 8, 'architecture': 654, 'input_size': 300}\n",
      "{'dropout': 0.7148295475176154, 'output_size': 8, 'architecture': 339, 'input_size': 300}\n",
      "{'dropout': 0.7148295475176154, 'output_size': 8, 'architecture': 339, 'input_size': 300}\n",
      "{'dropout': 0.7148295475176154, 'output_size': 8, 'architecture': 339, 'input_size': 300}\n",
      "{'dropout': 0.78328279014661017, 'output_size': 8, 'architecture': 646, 'input_size': 300}\n",
      "{'dropout': 0.78328279014661017, 'output_size': 8, 'architecture': 646, 'input_size': 300}\n",
      "{'dropout': 0.78328279014661017, 'output_size': 8, 'architecture': 646, 'input_size': 300}\n",
      "{'dropout': 0.69869038986597642, 'output_size': 8, 'architecture': 386, 'input_size': 300}\n",
      "{'dropout': 0.69869038986597642, 'output_size': 8, 'architecture': 386, 'input_size': 300}\n",
      "{'dropout': 0.69869038986597642, 'output_size': 8, 'architecture': 386, 'input_size': 300}\n",
      "{'dropout': 0.83607869436113336, 'output_size': 8, 'architecture': 656, 'input_size': 300}\n",
      "{'dropout': 0.83607869436113336, 'output_size': 8, 'architecture': 656, 'input_size': 300}\n",
      "{'dropout': 0.83607869436113336, 'output_size': 8, 'architecture': 656, 'input_size': 300}\n",
      "{'dropout': 0.763055020690941, 'output_size': 8, 'architecture': 773, 'input_size': 300}\n",
      "{'dropout': 0.763055020690941, 'output_size': 8, 'architecture': 773, 'input_size': 300}\n",
      "{'dropout': 0.763055020690941, 'output_size': 8, 'architecture': 773, 'input_size': 300}\n",
      "{'dropout': 0.87690179349173958, 'output_size': 8, 'architecture': 554, 'input_size': 300}\n",
      "{'dropout': 0.87690179349173958, 'output_size': 8, 'architecture': 554, 'input_size': 300}\n",
      "{'dropout': 0.87690179349173958, 'output_size': 8, 'architecture': 554, 'input_size': 300}\n",
      "{'dropout': 0.76306606765380258, 'output_size': 8, 'architecture': 337, 'input_size': 300}\n",
      "{'dropout': 0.76306606765380258, 'output_size': 8, 'architecture': 337, 'input_size': 300}\n",
      "{'dropout': 0.76306606765380258, 'output_size': 8, 'architecture': 337, 'input_size': 300}\n",
      "{'dropout': 0.95212901546828199, 'output_size': 8, 'architecture': 423, 'input_size': 300}\n",
      "{'dropout': 0.95212901546828199, 'output_size': 8, 'architecture': 423, 'input_size': 300}\n",
      "{'dropout': 0.95212901546828199, 'output_size': 8, 'architecture': 423, 'input_size': 300}\n",
      "{'dropout': 0.83581420599868339, 'output_size': 8, 'architecture': 300, 'input_size': 300}\n",
      "{'dropout': 0.83581420599868339, 'output_size': 8, 'architecture': 300, 'input_size': 300}\n",
      "{'dropout': 0.83581420599868339, 'output_size': 8, 'architecture': 300, 'input_size': 300}\n",
      "{'dropout': 0.94464877823264093, 'output_size': 8, 'architecture': 347, 'input_size': 300}\n",
      "{'dropout': 0.94464877823264093, 'output_size': 8, 'architecture': 347, 'input_size': 300}\n",
      "{'dropout': 0.94464877823264093, 'output_size': 8, 'architecture': 347, 'input_size': 300}\n",
      "{'dropout': 0.57871454159533398, 'output_size': 8, 'architecture': 562, 'input_size': 300}\n",
      "{'dropout': 0.57871454159533398, 'output_size': 8, 'architecture': 562, 'input_size': 300}\n",
      "{'dropout': 0.57871454159533398, 'output_size': 8, 'architecture': 562, 'input_size': 300}\n",
      "{'dropout': 0.90478017009069811, 'output_size': 8, 'architecture': 783, 'input_size': 300}\n",
      "{'dropout': 0.90478017009069811, 'output_size': 8, 'architecture': 783, 'input_size': 300}\n",
      "{'dropout': 0.90478017009069811, 'output_size': 8, 'architecture': 783, 'input_size': 300}\n",
      "{'dropout': 0.56883941765925883, 'output_size': 8, 'architecture': 743, 'input_size': 300}\n",
      "{'dropout': 0.56883941765925883, 'output_size': 8, 'architecture': 743, 'input_size': 300}\n",
      "{'dropout': 0.56883941765925883, 'output_size': 8, 'architecture': 743, 'input_size': 300}\n",
      "{'dropout': 0.59787503728786251, 'output_size': 8, 'architecture': 695, 'input_size': 300}\n",
      "{'dropout': 0.59787503728786251, 'output_size': 8, 'architecture': 695, 'input_size': 300}\n",
      "{'dropout': 0.59787503728786251, 'output_size': 8, 'architecture': 695, 'input_size': 300}\n",
      "{'dropout': 0.77986081322176037, 'output_size': 8, 'architecture': 380, 'input_size': 300}\n",
      "{'dropout': 0.77986081322176037, 'output_size': 8, 'architecture': 380, 'input_size': 300}\n",
      "{'dropout': 0.77986081322176037, 'output_size': 8, 'architecture': 380, 'input_size': 300}\n",
      "{'dropout': 0.59550564323706801, 'output_size': 8, 'architecture': 345, 'input_size': 300}\n",
      "{'dropout': 0.59550564323706801, 'output_size': 8, 'architecture': 345, 'input_size': 300}\n",
      "{'dropout': 0.59550564323706801, 'output_size': 8, 'architecture': 345, 'input_size': 300}\n",
      "{'dropout': 0.89271362081126604, 'output_size': 8, 'architecture': 436, 'input_size': 300}\n",
      "{'dropout': 0.89271362081126604, 'output_size': 8, 'architecture': 436, 'input_size': 300}\n",
      "{'dropout': 0.89271362081126604, 'output_size': 8, 'architecture': 436, 'input_size': 300}\n",
      "{'dropout': 0.96358070482225622, 'output_size': 8, 'architecture': 412, 'input_size': 300}\n",
      "{'dropout': 0.96358070482225622, 'output_size': 8, 'architecture': 412, 'input_size': 300}\n",
      "{'dropout': 0.96358070482225622, 'output_size': 8, 'architecture': 412, 'input_size': 300}\n",
      "{'dropout': 0.8800977280001181, 'output_size': 8, 'architecture': 324, 'input_size': 300}\n",
      "{'dropout': 0.8800977280001181, 'output_size': 8, 'architecture': 324, 'input_size': 300}\n",
      "{'dropout': 0.8800977280001181, 'output_size': 8, 'architecture': 324, 'input_size': 300}\n",
      "{'dropout': 0.83057751141401437, 'output_size': 8, 'architecture': 353, 'input_size': 300}\n",
      "{'dropout': 0.83057751141401437, 'output_size': 8, 'architecture': 353, 'input_size': 300}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.83057751141401437, 'output_size': 8, 'architecture': 353, 'input_size': 300}\n",
      "{'dropout': 0.7977982455684548, 'output_size': 8, 'architecture': 459, 'input_size': 300}\n",
      "{'dropout': 0.7977982455684548, 'output_size': 8, 'architecture': 459, 'input_size': 300}\n",
      "{'dropout': 0.7977982455684548, 'output_size': 8, 'architecture': 459, 'input_size': 300}\n",
      "{'dropout': 0.54417798139092, 'output_size': 8, 'architecture': 643, 'input_size': 300}\n",
      "{'dropout': 0.54417798139092, 'output_size': 8, 'architecture': 643, 'input_size': 300}\n",
      "{'dropout': 0.54417798139092, 'output_size': 8, 'architecture': 643, 'input_size': 300}\n",
      "{'dropout': 0.66106689828870668, 'output_size': 8, 'architecture': 377, 'input_size': 300}\n",
      "{'dropout': 0.66106689828870668, 'output_size': 8, 'architecture': 377, 'input_size': 300}\n",
      "{'dropout': 0.66106689828870668, 'output_size': 8, 'architecture': 377, 'input_size': 300}\n",
      "{'dropout': 0.89146021970095735, 'output_size': 8, 'architecture': 382, 'input_size': 300}\n",
      "{'dropout': 0.89146021970095735, 'output_size': 8, 'architecture': 382, 'input_size': 300}\n",
      "{'dropout': 0.89146021970095735, 'output_size': 8, 'architecture': 382, 'input_size': 300}\n",
      "{'dropout': 0.99897641886658795, 'output_size': 8, 'architecture': 370, 'input_size': 300}\n",
      "{'dropout': 0.99897641886658795, 'output_size': 8, 'architecture': 370, 'input_size': 300}\n",
      "{'dropout': 0.99897641886658795, 'output_size': 8, 'architecture': 370, 'input_size': 300}\n",
      "{'dropout': 0.74792767293459073, 'output_size': 8, 'architecture': 680, 'input_size': 300}\n",
      "{'dropout': 0.74792767293459073, 'output_size': 8, 'architecture': 680, 'input_size': 300}\n",
      "{'dropout': 0.74792767293459073, 'output_size': 8, 'architecture': 680, 'input_size': 300}\n",
      "{'dropout': 0.7586246461637588, 'output_size': 8, 'architecture': 537, 'input_size': 300}\n",
      "{'dropout': 0.7586246461637588, 'output_size': 8, 'architecture': 537, 'input_size': 300}\n",
      "{'dropout': 0.7586246461637588, 'output_size': 8, 'architecture': 537, 'input_size': 300}\n",
      "{'dropout': 0.93039232443569486, 'output_size': 8, 'architecture': 741, 'input_size': 300}\n",
      "{'dropout': 0.93039232443569486, 'output_size': 8, 'architecture': 741, 'input_size': 300}\n",
      "{'dropout': 0.93039232443569486, 'output_size': 8, 'architecture': 741, 'input_size': 300}\n",
      "{'dropout': 0.9815407354532304, 'output_size': 8, 'architecture': 491, 'input_size': 300}\n",
      "{'dropout': 0.9815407354532304, 'output_size': 8, 'architecture': 491, 'input_size': 300}\n",
      "{'dropout': 0.9815407354532304, 'output_size': 8, 'architecture': 491, 'input_size': 300}\n",
      "{'dropout': 0.78340130891970783, 'output_size': 8, 'architecture': 511, 'input_size': 300}\n",
      "{'dropout': 0.78340130891970783, 'output_size': 8, 'architecture': 511, 'input_size': 300}\n",
      "{'dropout': 0.78340130891970783, 'output_size': 8, 'architecture': 511, 'input_size': 300}\n",
      "{'dropout': 0.62272936804598245, 'output_size': 8, 'architecture': 391, 'input_size': 300}\n",
      "{'dropout': 0.62272936804598245, 'output_size': 8, 'architecture': 391, 'input_size': 300}\n",
      "{'dropout': 0.62272936804598245, 'output_size': 8, 'architecture': 391, 'input_size': 300}\n",
      "{'dropout': 0.56405364621874665, 'output_size': 8, 'architecture': 642, 'input_size': 300}\n",
      "{'dropout': 0.56405364621874665, 'output_size': 8, 'architecture': 642, 'input_size': 300}\n",
      "{'dropout': 0.56405364621874665, 'output_size': 8, 'architecture': 642, 'input_size': 300}\n",
      "{'dropout': 0.7940437584278548, 'output_size': 8, 'architecture': 340, 'input_size': 300}\n",
      "{'dropout': 0.7940437584278548, 'output_size': 8, 'architecture': 340, 'input_size': 300}\n",
      "{'dropout': 0.7940437584278548, 'output_size': 8, 'architecture': 340, 'input_size': 300}\n",
      "{'dropout': 0.57351912045833031, 'output_size': 8, 'architecture': 507, 'input_size': 300}\n",
      "{'dropout': 0.57351912045833031, 'output_size': 8, 'architecture': 507, 'input_size': 300}\n",
      "{'dropout': 0.57351912045833031, 'output_size': 8, 'architecture': 507, 'input_size': 300}\n",
      "{'dropout': 0.84622045340283636, 'output_size': 8, 'architecture': 632, 'input_size': 300}\n",
      "{'dropout': 0.84622045340283636, 'output_size': 8, 'architecture': 632, 'input_size': 300}\n",
      "{'dropout': 0.84622045340283636, 'output_size': 8, 'architecture': 632, 'input_size': 300}\n",
      "{'dropout': 0.87962168477970337, 'output_size': 8, 'architecture': 595, 'input_size': 300}\n",
      "{'dropout': 0.87962168477970337, 'output_size': 8, 'architecture': 595, 'input_size': 300}\n",
      "{'dropout': 0.87962168477970337, 'output_size': 8, 'architecture': 595, 'input_size': 300}\n",
      "{'dropout': 0.8655727713520458, 'output_size': 8, 'architecture': 329, 'input_size': 300}\n",
      "{'dropout': 0.8655727713520458, 'output_size': 8, 'architecture': 329, 'input_size': 300}\n",
      "{'dropout': 0.8655727713520458, 'output_size': 8, 'architecture': 329, 'input_size': 300}\n",
      "{'dropout': 0.66677819417978901, 'output_size': 8, 'architecture': 332, 'input_size': 300}\n",
      "{'dropout': 0.66677819417978901, 'output_size': 8, 'architecture': 332, 'input_size': 300}\n",
      "{'dropout': 0.66677819417978901, 'output_size': 8, 'architecture': 332, 'input_size': 300}\n",
      "{'dropout': 0.50951130221146257, 'output_size': 8, 'architecture': 518, 'input_size': 300}\n",
      "{'dropout': 0.50951130221146257, 'output_size': 8, 'architecture': 518, 'input_size': 300}\n",
      "{'dropout': 0.50951130221146257, 'output_size': 8, 'architecture': 518, 'input_size': 300}\n",
      "{'dropout': 0.82295299101891117, 'output_size': 8, 'architecture': 462, 'input_size': 300}\n",
      "{'dropout': 0.82295299101891117, 'output_size': 8, 'architecture': 462, 'input_size': 300}\n",
      "{'dropout': 0.82295299101891117, 'output_size': 8, 'architecture': 462, 'input_size': 300}\n",
      "{'dropout': 0.62419955512883485, 'output_size': 8, 'architecture': 370, 'input_size': 300}\n",
      "{'dropout': 0.62419955512883485, 'output_size': 8, 'architecture': 370, 'input_size': 300}\n",
      "{'dropout': 0.62419955512883485, 'output_size': 8, 'architecture': 370, 'input_size': 300}\n",
      "{'dropout': 0.8688510232148281, 'output_size': 8, 'architecture': 678, 'input_size': 300}\n",
      "{'dropout': 0.8688510232148281, 'output_size': 8, 'architecture': 678, 'input_size': 300}\n",
      "{'dropout': 0.8688510232148281, 'output_size': 8, 'architecture': 678, 'input_size': 300}\n",
      "{'dropout': 0.60834732708788641, 'output_size': 8, 'architecture': 470, 'input_size': 300}\n",
      "{'dropout': 0.60834732708788641, 'output_size': 8, 'architecture': 470, 'input_size': 300}\n",
      "{'dropout': 0.60834732708788641, 'output_size': 8, 'architecture': 470, 'input_size': 300}\n",
      "{'dropout': 0.76548273461616279, 'output_size': 8, 'architecture': 340, 'input_size': 300}\n",
      "{'dropout': 0.76548273461616279, 'output_size': 8, 'architecture': 340, 'input_size': 300}\n",
      "{'dropout': 0.76548273461616279, 'output_size': 8, 'architecture': 340, 'input_size': 300}\n",
      "{'dropout': 0.71401517053851427, 'output_size': 8, 'architecture': 638, 'input_size': 300}\n",
      "{'dropout': 0.71401517053851427, 'output_size': 8, 'architecture': 638, 'input_size': 300}\n",
      "{'dropout': 0.71401517053851427, 'output_size': 8, 'architecture': 638, 'input_size': 300}\n",
      "{'dropout': 0.80230247083454764, 'output_size': 8, 'architecture': 338, 'input_size': 300}\n",
      "{'dropout': 0.80230247083454764, 'output_size': 8, 'architecture': 338, 'input_size': 300}\n",
      "{'dropout': 0.80230247083454764, 'output_size': 8, 'architecture': 338, 'input_size': 300}\n",
      "{'dropout': 0.98969619986386625, 'output_size': 8, 'architecture': 634, 'input_size': 300}\n",
      "{'dropout': 0.98969619986386625, 'output_size': 8, 'architecture': 634, 'input_size': 300}\n",
      "{'dropout': 0.98969619986386625, 'output_size': 8, 'architecture': 634, 'input_size': 300}\n",
      "{'dropout': 0.54241800411705221, 'output_size': 8, 'architecture': 760, 'input_size': 300}\n",
      "{'dropout': 0.54241800411705221, 'output_size': 8, 'architecture': 760, 'input_size': 300}\n",
      "{'dropout': 0.54241800411705221, 'output_size': 8, 'architecture': 760, 'input_size': 300}\n",
      "{'dropout': 0.53891097742929084, 'output_size': 8, 'architecture': 573, 'input_size': 300}\n",
      "{'dropout': 0.53891097742929084, 'output_size': 8, 'architecture': 573, 'input_size': 300}\n",
      "{'dropout': 0.53891097742929084, 'output_size': 8, 'architecture': 573, 'input_size': 300}\n",
      "{'dropout': 0.52203297129493487, 'output_size': 8, 'architecture': 560, 'input_size': 300}\n",
      "{'dropout': 0.52203297129493487, 'output_size': 8, 'architecture': 560, 'input_size': 300}\n",
      "{'dropout': 0.52203297129493487, 'output_size': 8, 'architecture': 560, 'input_size': 300}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.93765489386669099, 'output_size': 8, 'architecture': 785, 'input_size': 300}\n",
      "{'dropout': 0.93765489386669099, 'output_size': 8, 'architecture': 785, 'input_size': 300}\n",
      "{'dropout': 0.93765489386669099, 'output_size': 8, 'architecture': 785, 'input_size': 300}\n",
      "{'dropout': 0.81965099159253785, 'output_size': 8, 'architecture': 325, 'input_size': 300}\n",
      "{'dropout': 0.81965099159253785, 'output_size': 8, 'architecture': 325, 'input_size': 300}\n",
      "{'dropout': 0.81965099159253785, 'output_size': 8, 'architecture': 325, 'input_size': 300}\n",
      "{'dropout': 0.78804989603380238, 'output_size': 8, 'architecture': 614, 'input_size': 300}\n",
      "{'dropout': 0.78804989603380238, 'output_size': 8, 'architecture': 614, 'input_size': 300}\n",
      "{'dropout': 0.78804989603380238, 'output_size': 8, 'architecture': 614, 'input_size': 300}\n",
      "{'dropout': 0.71136355795859796, 'output_size': 8, 'architecture': 672, 'input_size': 300}\n",
      "{'dropout': 0.71136355795859796, 'output_size': 8, 'architecture': 672, 'input_size': 300}\n",
      "{'dropout': 0.71136355795859796, 'output_size': 8, 'architecture': 672, 'input_size': 300}\n",
      "{'dropout': 0.97026076784395432, 'output_size': 8, 'architecture': 389, 'input_size': 300}\n",
      "{'dropout': 0.97026076784395432, 'output_size': 8, 'architecture': 389, 'input_size': 300}\n",
      "{'dropout': 0.97026076784395432, 'output_size': 8, 'architecture': 389, 'input_size': 300}\n",
      "{'dropout': 0.5978433895971238, 'output_size': 8, 'architecture': 348, 'input_size': 300}\n",
      "{'dropout': 0.5978433895971238, 'output_size': 8, 'architecture': 348, 'input_size': 300}\n",
      "{'dropout': 0.5978433895971238, 'output_size': 8, 'architecture': 348, 'input_size': 300}\n",
      "{'dropout': 0.76340251412485582, 'output_size': 8, 'architecture': 759, 'input_size': 300}\n",
      "{'dropout': 0.76340251412485582, 'output_size': 8, 'architecture': 759, 'input_size': 300}\n",
      "{'dropout': 0.76340251412485582, 'output_size': 8, 'architecture': 759, 'input_size': 300}\n",
      "{'dropout': 0.51641750739076508, 'output_size': 8, 'architecture': 472, 'input_size': 300}\n",
      "{'dropout': 0.51641750739076508, 'output_size': 8, 'architecture': 472, 'input_size': 300}\n",
      "{'dropout': 0.51641750739076508, 'output_size': 8, 'architecture': 472, 'input_size': 300}\n",
      "{'dropout': 0.99812881412238241, 'output_size': 8, 'architecture': 322, 'input_size': 300}\n",
      "{'dropout': 0.99812881412238241, 'output_size': 8, 'architecture': 322, 'input_size': 300}\n",
      "{'dropout': 0.99812881412238241, 'output_size': 8, 'architecture': 322, 'input_size': 300}\n",
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=<models.Model object at 0x7f62506a2eb8>, fit_params={},\n",
       "          iid=True, n_iter=100, n_jobs=1,\n",
       "          param_distributions={'batch': [128, 256, 512], 'dropout': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f62506b8630>, 'iters': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f62506b89b0>, 'lr': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f6255e31ac8>, 'architecture': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f62506b8b00>, 'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f62506b8940>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(models)\n",
    "\n",
    "nn = models.Model('mlp', lr=1e-3, class_balance=False, batch=256, iters=300, alpha=1e-3, \n",
    "                  architecture=[500], dropout=1)\n",
    "\n",
    "\n",
    "searcher = RandomizedSearchCV(nn, n_iter=100, param_distributions={'lr':uniform(1e-5, 1e-1), 'dropout':uniform(loc=.5, scale=.5),\n",
    "                                             'alpha':uniform(1e-4, 1e-2), 'batch':[128, 256, 512], \n",
    "                                               'architecture':randint(300, 800), 'iters': randint(50, 300)\n",
    "                                                                })\n",
    "\n",
    "searcher.fit(dx, dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.00023090522206274048,\n",
       " 'architecture': 396,\n",
       " 'batch': 512,\n",
       " 'dropout': 0.89291615635753208,\n",
       " 'iters': 210,\n",
       " 'lr': 0.059455630570591084}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n",
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n",
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.99858381, -1.04501146, -1.00619676])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(models)\n",
    "\n",
    "nn = models.Model('mlp', class_balance=False, **searcher.best_params_)\n",
    "\n",
    "cross_val_score(nn, dx, dy, scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n",
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n",
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n",
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n",
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n",
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n",
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n",
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n",
      "{'dropout': 0.89291615635753208, 'output_size': 8, 'architecture': 396, 'input_size': 300}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.62538461538461543,\n",
       " 'log loss': 1.0423807775330407,\n",
       " 'precision': 0.33077524081808873,\n",
       " 'recall': 0.28746744907595628}"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_score(nn, dx, dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BinaryVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b12715c4eda8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbin_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mat_least_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbin_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BinaryVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "bin_vect = BinaryVectorizer(vocabulary=at_least_threshold)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.5)\n",
    "\n",
    "bin_vect.fit(x_train)\n",
    "\n",
    "selector = SelectKBest(chi2, k = 100)\n",
    "\n",
    "selector.fit(bin_vect.transform(x_train), y_train)\n",
    "\n",
    "np.argsort( selector.pvalues_ )\n",
    "\n",
    "best_words = [bin_vect.get_feature_names()[x] for x in np.argsort( selector.pvalues_ )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1624\n",
      "2\n",
      "1486\n",
      "3\n",
      "1057\n",
      "4\n",
      "987\n",
      "5\n",
      "890\n",
      "6\n",
      "867\n",
      "7\n",
      "834\n",
      "8\n",
      "697\n",
      "9\n",
      "630\n",
      "10\n",
      "559\n",
      "11\n",
      "517\n",
      "12\n",
      "508\n",
      "13\n",
      "468\n",
      "14\n",
      "447\n",
      "15\n",
      "429\n",
      "16\n",
      "387\n",
      "17\n",
      "339\n",
      "18\n",
      "317\n",
      "19\n",
      "267\n",
      "20\n",
      "220\n",
      "21\n",
      "170\n",
      "22\n",
      "155\n",
      "23\n",
      "150\n",
      "24\n",
      "137\n",
      "25\n",
      "127\n",
      "26\n",
      "125\n",
      "27\n",
      "115\n",
      "28\n",
      "110\n",
      "29\n",
      "107\n",
      "30\n",
      "102\n",
      "31\n",
      "92\n",
      "32\n",
      "90\n",
      "33\n",
      "77\n",
      "34\n",
      "75\n",
      "35\n",
      "63\n",
      "36\n",
      "59\n",
      "37\n",
      "58\n",
      "38\n",
      "52\n",
      "39\n",
      "42\n",
      "40\n",
      "42\n",
      "41\n",
      "42\n",
      "42\n",
      "42\n",
      "43\n",
      "38\n",
      "44\n",
      "36\n",
      "45\n",
      "36\n",
      "46\n",
      "33\n",
      "47\n",
      "31\n",
      "48\n",
      "31\n",
      "49\n",
      "29\n",
      "50\n",
      "26\n",
      "51\n",
      "26\n",
      "52\n",
      "25\n",
      "53\n",
      "25\n",
      "54\n",
      "23\n",
      "55\n",
      "22\n",
      "56\n",
      "20\n",
      "57\n",
      "20\n",
      "58\n",
      "20\n",
      "59\n",
      "20\n",
      "60\n",
      "19\n",
      "61\n",
      "19\n",
      "62\n",
      "18\n",
      "63\n",
      "18\n",
      "64\n",
      "17\n",
      "65\n",
      "17\n",
      "66\n",
      "17\n",
      "67\n",
      "17\n",
      "68\n",
      "17\n",
      "69\n",
      "17\n",
      "70\n",
      "17\n",
      "71\n",
      "17\n",
      "72\n",
      "16\n",
      "73\n",
      "16\n",
      "74\n",
      "16\n",
      "75\n",
      "16\n",
      "76\n",
      "16\n",
      "77\n",
      "15\n",
      "78\n",
      "15\n",
      "79\n",
      "15\n",
      "80\n",
      "15\n",
      "81\n",
      "15\n",
      "82\n",
      "15\n",
      "83\n",
      "15\n",
      "84\n",
      "15\n",
      "85\n",
      "14\n",
      "86\n",
      "14\n",
      "87\n",
      "14\n",
      "88\n",
      "14\n",
      "89\n",
      "14\n",
      "90\n",
      "14\n",
      "91\n",
      "14\n",
      "92\n",
      "14\n",
      "93\n",
      "14\n",
      "94\n",
      "14\n",
      "95\n",
      "14\n",
      "96\n",
      "14\n",
      "97\n",
      "14\n",
      "98\n",
      "14\n",
      "99\n",
      "13\n",
      "100\n",
      "13\n",
      "101\n",
      "13\n",
      "102\n",
      "13\n",
      "103\n",
      "13\n",
      "104\n",
      "13\n",
      "105\n",
      "13\n",
      "106\n",
      "12\n",
      "107\n",
      "12\n",
      "108\n",
      "12\n",
      "109\n",
      "12\n",
      "110\n",
      "12\n",
      "111\n",
      "12\n",
      "112\n",
      "12\n",
      "113\n",
      "12\n",
      "114\n",
      "12\n",
      "115\n",
      "12\n",
      "116\n",
      "11\n",
      "117\n",
      "11\n",
      "118\n",
      "11\n",
      "119\n",
      "11\n",
      "120\n",
      "11\n",
      "121\n",
      "11\n",
      "122\n",
      "10\n",
      "123\n",
      "10\n",
      "124\n",
      "10\n",
      "125\n",
      "10\n",
      "126\n",
      "10\n",
      "127\n",
      "10\n",
      "128\n",
      "10\n",
      "129\n",
      "10\n",
      "130\n",
      "10\n",
      "131\n",
      "10\n",
      "132\n",
      "10\n",
      "133\n",
      "10\n",
      "134\n",
      "10\n",
      "135\n",
      "10\n",
      "136\n",
      "10\n",
      "137\n",
      "9\n",
      "138\n",
      "9\n",
      "139\n",
      "9\n",
      "140\n",
      "9\n",
      "141\n",
      "9\n",
      "142\n",
      "9\n",
      "143\n",
      "9\n",
      "144\n",
      "9\n",
      "145\n",
      "9\n",
      "146\n",
      "9\n",
      "147\n",
      "9\n",
      "148\n",
      "9\n",
      "149\n",
      "9\n",
      "150\n",
      "9\n",
      "151\n",
      "9\n",
      "152\n",
      "9\n",
      "153\n",
      "9\n",
      "154\n",
      "9\n",
      "155\n",
      "9\n",
      "156\n",
      "9\n",
      "157\n",
      "9\n",
      "158\n",
      "9\n",
      "159\n",
      "9\n",
      "160\n",
      "9\n",
      "161\n",
      "9\n",
      "162\n",
      "9\n",
      "163\n",
      "9\n",
      "164\n",
      "9\n",
      "165\n",
      "9\n",
      "166\n",
      "9\n",
      "167\n",
      "9\n",
      "168\n",
      "9\n",
      "169\n",
      "9\n",
      "170\n",
      "9\n",
      "171\n",
      "9\n",
      "172\n",
      "9\n",
      "173\n",
      "9\n",
      "174\n",
      "9\n",
      "175\n",
      "8\n",
      "176\n",
      "8\n",
      "177\n",
      "8\n",
      "178\n",
      "8\n",
      "179\n",
      "8\n",
      "180\n",
      "8\n",
      "181\n",
      "8\n",
      "182\n",
      "8\n",
      "183\n",
      "8\n",
      "184\n",
      "8\n",
      "185\n",
      "8\n",
      "186\n",
      "8\n",
      "187\n",
      "8\n",
      "188\n",
      "8\n",
      "189\n",
      "8\n",
      "190\n",
      "8\n",
      "191\n",
      "8\n",
      "192\n",
      "8\n",
      "193\n",
      "8\n",
      "194\n",
      "8\n",
      "195\n",
      "8\n",
      "196\n",
      "8\n",
      "197\n",
      "8\n",
      "198\n",
      "8\n",
      "199\n",
      "8\n",
      "200\n",
      "8\n",
      "201\n",
      "8\n",
      "202\n",
      "8\n",
      "203\n",
      "8\n",
      "204\n",
      "8\n",
      "205\n",
      "8\n",
      "206\n",
      "8\n",
      "207\n",
      "8\n",
      "208\n",
      "8\n",
      "209\n",
      "8\n",
      "210\n",
      "8\n",
      "211\n",
      "8\n",
      "212\n",
      "8\n",
      "213\n",
      "8\n",
      "214\n",
      "8\n",
      "215\n",
      "8\n",
      "216\n",
      "8\n",
      "217\n",
      "8\n",
      "218\n",
      "8\n",
      "219\n",
      "8\n",
      "220\n",
      "8\n",
      "221\n",
      "8\n",
      "222\n",
      "8\n",
      "223\n",
      "8\n",
      "224\n",
      "8\n",
      "225\n",
      "8\n",
      "226\n",
      "8\n",
      "227\n",
      "8\n",
      "228\n",
      "8\n",
      "229\n",
      "8\n",
      "230\n",
      "8\n",
      "231\n",
      "8\n",
      "232\n",
      "8\n",
      "233\n",
      "8\n",
      "234\n",
      "8\n",
      "235\n",
      "8\n",
      "236\n",
      "8\n",
      "237\n",
      "8\n",
      "238\n",
      "8\n",
      "239\n",
      "8\n",
      "240\n",
      "8\n",
      "241\n",
      "8\n",
      "242\n",
      "8\n",
      "243\n",
      "8\n",
      "244\n",
      "8\n",
      "245\n",
      "8\n",
      "246\n",
      "8\n",
      "247\n",
      "8\n",
      "248\n",
      "8\n",
      "249\n",
      "8\n",
      "250\n",
      "8\n",
      "251\n",
      "8\n",
      "252\n",
      "8\n",
      "253\n",
      "8\n",
      "254\n",
      "8\n",
      "255\n",
      "8\n",
      "256\n",
      "8\n",
      "257\n",
      "8\n",
      "258\n",
      "8\n",
      "259\n",
      "8\n",
      "260\n",
      "8\n",
      "261\n",
      "8\n",
      "262\n",
      "8\n",
      "263\n",
      "8\n",
      "264\n",
      "8\n",
      "265\n",
      "8\n",
      "266\n",
      "8\n",
      "267\n",
      "8\n",
      "268\n",
      "8\n",
      "269\n",
      "8\n",
      "270\n",
      "8\n",
      "271\n",
      "8\n",
      "272\n",
      "8\n",
      "273\n",
      "8\n",
      "274\n",
      "8\n",
      "275\n",
      "8\n",
      "276\n",
      "8\n",
      "277\n",
      "8\n",
      "278\n",
      "8\n",
      "279\n",
      "8\n",
      "280\n",
      "8\n",
      "281\n",
      "8\n",
      "282\n",
      "8\n",
      "283\n",
      "8\n",
      "284\n",
      "8\n",
      "285\n",
      "8\n",
      "286\n",
      "8\n",
      "287\n",
      "8\n",
      "288\n",
      "8\n",
      "289\n",
      "8\n",
      "290\n",
      "8\n",
      "291\n",
      "8\n",
      "292\n",
      "8\n",
      "293\n",
      "8\n",
      "294\n",
      "8\n",
      "295\n",
      "8\n",
      "296\n",
      "8\n",
      "297\n",
      "8\n",
      "298\n",
      "8\n",
      "299\n",
      "8\n",
      "300\n",
      "8\n",
      "301\n",
      "8\n",
      "302\n",
      "8\n",
      "303\n",
      "8\n",
      "304\n",
      "8\n",
      "305\n",
      "8\n",
      "306\n",
      "8\n",
      "307\n",
      "8\n",
      "308\n",
      "8\n",
      "309\n",
      "8\n",
      "310\n",
      "8\n",
      "311\n",
      "8\n",
      "312\n",
      "8\n",
      "313\n",
      "8\n",
      "314\n",
      "8\n",
      "315\n",
      "8\n",
      "316\n",
      "8\n",
      "317\n",
      "8\n",
      "318\n",
      "8\n",
      "319\n",
      "8\n",
      "320\n",
      "8\n",
      "321\n",
      "8\n",
      "322\n",
      "8\n",
      "323\n",
      "8\n",
      "324\n",
      "8\n",
      "325\n",
      "8\n",
      "326\n",
      "8\n",
      "327\n",
      "8\n",
      "328\n",
      "8\n",
      "329\n",
      "8\n",
      "330\n",
      "8\n",
      "331\n",
      "8\n",
      "332\n",
      "8\n",
      "333\n",
      "8\n",
      "334\n",
      "8\n",
      "335\n",
      "8\n",
      "336\n",
      "8\n",
      "337\n",
      "8\n",
      "338\n",
      "8\n",
      "339\n",
      "8\n",
      "340\n",
      "8\n",
      "341\n",
      "8\n",
      "342\n",
      "8\n",
      "343\n",
      "8\n",
      "344\n",
      "8\n",
      "345\n",
      "8\n",
      "346\n",
      "8\n",
      "347\n",
      "8\n",
      "348\n",
      "8\n",
      "349\n",
      "8\n",
      "350\n",
      "8\n",
      "351\n",
      "8\n",
      "352\n",
      "8\n",
      "353\n",
      "8\n",
      "354\n",
      "8\n",
      "355\n",
      "8\n",
      "356\n",
      "8\n",
      "357\n",
      "8\n",
      "358\n",
      "8\n",
      "359\n",
      "8\n",
      "360\n",
      "8\n",
      "361\n",
      "8\n",
      "362\n",
      "8\n",
      "363\n",
      "8\n",
      "364\n",
      "8\n",
      "365\n",
      "8\n",
      "366\n",
      "8\n",
      "367\n",
      "8\n",
      "368\n",
      "8\n",
      "369\n",
      "8\n",
      "370\n",
      "8\n",
      "371\n",
      "8\n",
      "372\n",
      "8\n",
      "373\n",
      "8\n",
      "374\n",
      "8\n",
      "375\n",
      "8\n",
      "376\n",
      "8\n",
      "377\n",
      "8\n",
      "378\n",
      "8\n",
      "379\n",
      "8\n",
      "380\n",
      "8\n",
      "381\n",
      "8\n",
      "382\n",
      "8\n",
      "383\n",
      "8\n",
      "384\n",
      "8\n",
      "385\n",
      "8\n",
      "386\n",
      "8\n",
      "387\n",
      "8\n",
      "388\n",
      "8\n",
      "389\n",
      "8\n",
      "390\n",
      "8\n",
      "391\n",
      "8\n",
      "392\n",
      "8\n",
      "393\n",
      "8\n",
      "394\n",
      "8\n",
      "395\n",
      "8\n",
      "396\n",
      "8\n",
      "397\n",
      "8\n",
      "398\n",
      "8\n",
      "399\n",
      "8\n",
      "400\n",
      "8\n",
      "401\n",
      "8\n",
      "402\n",
      "8\n",
      "403\n",
      "8\n",
      "404\n",
      "8\n",
      "405\n",
      "8\n",
      "406\n",
      "8\n",
      "407\n",
      "8\n",
      "408\n",
      "8\n",
      "409\n",
      "8\n",
      "410\n",
      "8\n",
      "411\n",
      "8\n",
      "412\n",
      "8\n",
      "413\n",
      "8\n",
      "414\n",
      "8\n",
      "415\n",
      "8\n",
      "416\n",
      "8\n",
      "417\n",
      "8\n",
      "418\n",
      "8\n",
      "419\n",
      "8\n",
      "420\n",
      "8\n",
      "421\n",
      "8\n",
      "422\n",
      "8\n",
      "423\n",
      "8\n",
      "424\n",
      "8\n",
      "425\n",
      "8\n",
      "426\n",
      "8\n",
      "427\n",
      "8\n",
      "428\n",
      "8\n",
      "429\n",
      "8\n",
      "430\n",
      "8\n",
      "431\n",
      "8\n",
      "432\n",
      "8\n",
      "433\n",
      "8\n",
      "434\n",
      "8\n",
      "435\n",
      "8\n",
      "436\n",
      "8\n",
      "437\n",
      "8\n",
      "438\n",
      "8\n",
      "439\n",
      "8\n",
      "440\n",
      "8\n",
      "441\n",
      "8\n",
      "442\n",
      "8\n",
      "443\n",
      "8\n",
      "444\n",
      "8\n",
      "445\n",
      "8\n",
      "446\n",
      "8\n",
      "447\n",
      "8\n",
      "448\n",
      "8\n",
      "449\n",
      "8\n",
      "450\n",
      "8\n",
      "451\n",
      "8\n",
      "452\n",
      "8\n",
      "453\n",
      "8\n",
      "454\n",
      "8\n",
      "455\n",
      "8\n",
      "456\n",
      "8\n",
      "457\n",
      "8\n",
      "458\n",
      "8\n",
      "459\n",
      "8\n",
      "460\n",
      "8\n",
      "461\n",
      "8\n",
      "462\n",
      "8\n",
      "463\n",
      "8\n",
      "464\n",
      "8\n",
      "465\n",
      "8\n",
      "466\n",
      "8\n",
      "467\n",
      "8\n",
      "468\n",
      "8\n",
      "469\n",
      "8\n",
      "470\n",
      "8\n",
      "471\n",
      "8\n",
      "472\n",
      "8\n",
      "473\n",
      "8\n",
      "474\n",
      "8\n",
      "475\n",
      "8\n",
      "476\n",
      "8\n",
      "477\n",
      "8\n",
      "478\n",
      "8\n",
      "479\n",
      "8\n",
      "480\n",
      "8\n",
      "481\n",
      "8\n",
      "482\n",
      "8\n",
      "483\n",
      "8\n",
      "484\n",
      "8\n",
      "485\n",
      "8\n",
      "486\n",
      "8\n",
      "487\n",
      "8\n",
      "488\n",
      "8\n",
      "489\n",
      "8\n",
      "490\n",
      "8\n",
      "491\n",
      "8\n",
      "492\n",
      "8\n",
      "493\n",
      "8\n",
      "494\n",
      "8\n",
      "495\n",
      "8\n",
      "496\n",
      "8\n",
      "497\n",
      "8\n",
      "498\n",
      "8\n",
      "499\n",
      "8\n",
      "500\n",
      "8\n",
      "501\n",
      "8\n",
      "502\n",
      "8\n",
      "503\n",
      "8\n",
      "504\n",
      "8\n",
      "505\n",
      "8\n",
      "506\n",
      "8\n",
      "507\n",
      "8\n",
      "508\n",
      "8\n",
      "509\n",
      "8\n",
      "510\n",
      "8\n",
      "511\n",
      "8\n",
      "512\n",
      "8\n",
      "513\n",
      "8\n",
      "514\n",
      "8\n",
      "515\n",
      "8\n",
      "516\n",
      "8\n",
      "517\n",
      "8\n",
      "518\n",
      "8\n",
      "519\n",
      "8\n",
      "520\n",
      "8\n",
      "521\n",
      "8\n",
      "522\n",
      "8\n",
      "523\n",
      "8\n",
      "524\n",
      "8\n",
      "525\n",
      "8\n",
      "526\n",
      "8\n",
      "527\n",
      "8\n",
      "528\n",
      "8\n",
      "529\n",
      "8\n",
      "530\n",
      "8\n",
      "531\n",
      "8\n",
      "532\n",
      "8\n",
      "533\n",
      "8\n",
      "534\n",
      "8\n",
      "535\n",
      "8\n",
      "536\n",
      "8\n",
      "537\n",
      "8\n",
      "538\n",
      "8\n",
      "539\n",
      "8\n",
      "540\n",
      "8\n",
      "541\n",
      "8\n",
      "542\n",
      "8\n",
      "543\n",
      "8\n",
      "544\n",
      "8\n",
      "545\n",
      "8\n",
      "546\n",
      "8\n",
      "547\n",
      "8\n",
      "548\n",
      "8\n",
      "549\n",
      "7\n",
      "550\n",
      "7\n",
      "551\n",
      "7\n",
      "552\n",
      "7\n",
      "553\n",
      "7\n",
      "554\n",
      "7\n",
      "555\n",
      "7\n",
      "556\n",
      "7\n",
      "557\n",
      "7\n",
      "558\n",
      "7\n",
      "559\n",
      "7\n",
      "560\n",
      "7\n",
      "561\n",
      "7\n",
      "562\n",
      "7\n",
      "563\n",
      "7\n",
      "564\n",
      "7\n",
      "565\n",
      "7\n",
      "566\n",
      "7\n",
      "567\n",
      "7\n",
      "568\n",
      "7\n",
      "569\n",
      "7\n",
      "570\n",
      "7\n",
      "571\n",
      "7\n",
      "572\n",
      "7\n",
      "573\n",
      "7\n",
      "574\n",
      "7\n",
      "575\n",
      "7\n",
      "576\n",
      "7\n",
      "577\n",
      "7\n",
      "578\n",
      "6\n",
      "579\n",
      "6\n",
      "580\n",
      "6\n",
      "581\n",
      "6\n",
      "582\n",
      "6\n",
      "583\n",
      "6\n",
      "584\n",
      "6\n",
      "585\n",
      "6\n",
      "586\n",
      "6\n",
      "587\n",
      "6\n",
      "588\n",
      "6\n",
      "589\n",
      "6\n",
      "590\n",
      "6\n",
      "591\n",
      "6\n",
      "592\n",
      "6\n",
      "593\n",
      "6\n",
      "594\n",
      "6\n",
      "595\n",
      "6\n",
      "596\n",
      "6\n",
      "597\n",
      "6\n",
      "598\n",
      "6\n",
      "599\n",
      "6\n",
      "600\n",
      "6\n",
      "601\n",
      "6\n",
      "602\n",
      "6\n",
      "603\n",
      "6\n",
      "604\n",
      "6\n",
      "605\n",
      "6\n",
      "606\n",
      "6\n",
      "607\n",
      "6\n",
      "608\n",
      "6\n",
      "609\n",
      "6\n",
      "610\n",
      "6\n",
      "611\n",
      "6\n",
      "612\n",
      "6\n",
      "613\n",
      "6\n",
      "614\n",
      "6\n",
      "615\n",
      "6\n",
      "616\n",
      "6\n",
      "617\n",
      "6\n",
      "618\n",
      "6\n",
      "619\n",
      "6\n",
      "620\n",
      "6\n",
      "621\n",
      "6\n",
      "622\n",
      "6\n",
      "623\n",
      "6\n",
      "624\n",
      "6\n",
      "625\n",
      "6\n",
      "626\n",
      "6\n",
      "627\n",
      "6\n",
      "628\n",
      "6\n",
      "629\n",
      "6\n",
      "630\n",
      "6\n",
      "631\n",
      "6\n",
      "632\n",
      "6\n",
      "633\n",
      "6\n",
      "634\n",
      "6\n",
      "635\n",
      "6\n",
      "636\n",
      "6\n",
      "637\n",
      "6\n",
      "638\n",
      "6\n",
      "639\n",
      "6\n",
      "640\n",
      "6\n",
      "641\n",
      "6\n",
      "642\n",
      "6\n",
      "643\n",
      "6\n",
      "644\n",
      "6\n",
      "645\n",
      "6\n",
      "646\n",
      "6\n",
      "647\n",
      "6\n",
      "648\n",
      "6\n",
      "649\n",
      "6\n",
      "650\n",
      "6\n",
      "651\n",
      "6\n",
      "652\n",
      "6\n",
      "653\n",
      "6\n",
      "654\n",
      "6\n",
      "655\n",
      "6\n",
      "656\n",
      "6\n",
      "657\n",
      "6\n",
      "658\n",
      "6\n",
      "659\n",
      "6\n",
      "660\n",
      "6\n",
      "661\n",
      "6\n",
      "662\n",
      "6\n",
      "663\n",
      "6\n",
      "664\n",
      "6\n",
      "665\n",
      "6\n",
      "666\n",
      "6\n",
      "667\n",
      "6\n",
      "668\n",
      "6\n",
      "669\n",
      "6\n",
      "670\n",
      "6\n",
      "671\n",
      "6\n",
      "672\n",
      "6\n",
      "673\n",
      "6\n",
      "674\n",
      "6\n",
      "675\n",
      "6\n",
      "676\n",
      "6\n",
      "677\n",
      "6\n",
      "678\n",
      "6\n",
      "679\n",
      "6\n",
      "680\n",
      "6\n",
      "681\n",
      "6\n",
      "682\n",
      "6\n",
      "683\n",
      "6\n",
      "684\n",
      "6\n",
      "685\n",
      "6\n",
      "686\n",
      "6\n",
      "687\n",
      "6\n",
      "688\n",
      "6\n",
      "689\n",
      "6\n",
      "690\n",
      "6\n",
      "691\n",
      "6\n",
      "692\n",
      "6\n",
      "693\n",
      "6\n",
      "694\n",
      "6\n",
      "695\n",
      "6\n",
      "696\n",
      "6\n",
      "697\n",
      "6\n",
      "698\n",
      "6\n",
      "699\n",
      "6\n",
      "700\n",
      "6\n",
      "701\n",
      "6\n",
      "702\n",
      "6\n",
      "703\n",
      "6\n",
      "704\n",
      "6\n",
      "705\n",
      "6\n",
      "706\n",
      "6\n",
      "707\n",
      "6\n",
      "708\n",
      "6\n",
      "709\n",
      "6\n",
      "710\n",
      "6\n",
      "711\n",
      "6\n",
      "712\n",
      "6\n",
      "713\n",
      "6\n",
      "714\n",
      "6\n",
      "715\n",
      "6\n",
      "716\n",
      "6\n",
      "717\n",
      "6\n",
      "718\n",
      "6\n",
      "719\n",
      "6\n",
      "720\n",
      "6\n",
      "721\n",
      "6\n",
      "722\n",
      "6\n",
      "723\n",
      "6\n",
      "724\n",
      "6\n",
      "725\n",
      "6\n",
      "726\n",
      "6\n",
      "727\n",
      "6\n",
      "728\n",
      "6\n",
      "729\n",
      "6\n",
      "730\n",
      "6\n",
      "731\n",
      "6\n",
      "732\n",
      "6\n",
      "733\n",
      "6\n",
      "734\n",
      "6\n",
      "735\n",
      "6\n",
      "736\n",
      "6\n",
      "737\n",
      "6\n",
      "738\n",
      "6\n",
      "739\n",
      "6\n",
      "740\n",
      "6\n",
      "741\n",
      "6\n",
      "742\n",
      "6\n",
      "743\n",
      "6\n",
      "744\n",
      "6\n",
      "745\n",
      "6\n",
      "746\n",
      "6\n",
      "747\n",
      "6\n",
      "748\n",
      "6\n",
      "749\n",
      "6\n",
      "750\n",
      "6\n",
      "751\n",
      "6\n",
      "752\n",
      "6\n",
      "753\n",
      "6\n",
      "754\n",
      "6\n",
      "755\n",
      "6\n",
      "756\n",
      "6\n",
      "757\n",
      "6\n",
      "758\n",
      "6\n",
      "759\n",
      "6\n",
      "760\n",
      "6\n",
      "761\n",
      "6\n",
      "762\n",
      "6\n",
      "763\n",
      "6\n",
      "764\n",
      "6\n",
      "765\n",
      "6\n",
      "766\n",
      "6\n",
      "767\n",
      "6\n",
      "768\n",
      "6\n",
      "769\n",
      "6\n",
      "770\n",
      "6\n",
      "771\n",
      "6\n",
      "772\n",
      "6\n",
      "773\n",
      "6\n",
      "774\n",
      "6\n",
      "775\n",
      "6\n",
      "776\n",
      "6\n",
      "777\n",
      "6\n",
      "778\n",
      "6\n",
      "779\n",
      "6\n",
      "780\n",
      "6\n",
      "781\n",
      "6\n",
      "782\n",
      "6\n",
      "783\n",
      "6\n",
      "784\n",
      "6\n",
      "785\n",
      "6\n",
      "786\n",
      "6\n",
      "787\n",
      "6\n",
      "788\n",
      "6\n",
      "789\n",
      "6\n",
      "790\n",
      "6\n",
      "791\n",
      "6\n",
      "792\n",
      "6\n",
      "793\n",
      "6\n",
      "794\n",
      "6\n",
      "795\n",
      "6\n",
      "796\n",
      "6\n",
      "797\n",
      "6\n",
      "798\n",
      "6\n",
      "799\n",
      "6\n",
      "800\n",
      "6\n",
      "801\n",
      "6\n",
      "802\n",
      "6\n",
      "803\n",
      "6\n",
      "804\n",
      "6\n",
      "805\n",
      "6\n",
      "806\n",
      "6\n",
      "807\n",
      "6\n",
      "808\n",
      "6\n",
      "809\n",
      "6\n",
      "810\n",
      "6\n",
      "811\n",
      "6\n",
      "812\n",
      "6\n",
      "813\n",
      "6\n",
      "814\n",
      "6\n",
      "815\n",
      "6\n",
      "816\n",
      "6\n",
      "817\n",
      "6\n",
      "818\n",
      "6\n",
      "819\n",
      "6\n",
      "820\n",
      "6\n",
      "821\n",
      "6\n",
      "822\n",
      "6\n",
      "823\n",
      "6\n",
      "824\n",
      "6\n",
      "825\n",
      "6\n",
      "826\n",
      "6\n",
      "827\n",
      "6\n",
      "828\n",
      "6\n",
      "829\n",
      "6\n",
      "830\n",
      "6\n",
      "831\n",
      "6\n",
      "832\n",
      "6\n",
      "833\n",
      "6\n",
      "834\n",
      "6\n",
      "835\n",
      "6\n",
      "836\n",
      "6\n",
      "837\n",
      "6\n",
      "838\n",
      "6\n",
      "839\n",
      "6\n",
      "840\n",
      "6\n",
      "841\n",
      "6\n",
      "842\n",
      "6\n",
      "843\n",
      "6\n",
      "844\n",
      "6\n",
      "845\n",
      "6\n",
      "846\n",
      "6\n",
      "847\n",
      "6\n",
      "848\n",
      "6\n",
      "849\n",
      "6\n",
      "850\n",
      "6\n",
      "851\n",
      "6\n",
      "852\n",
      "6\n",
      "853\n",
      "6\n",
      "854\n",
      "6\n",
      "855\n",
      "6\n",
      "856\n",
      "6\n",
      "857\n",
      "6\n",
      "858\n",
      "6\n",
      "859\n",
      "6\n",
      "860\n",
      "6\n",
      "861\n",
      "6\n",
      "862\n",
      "6\n",
      "863\n",
      "6\n",
      "864\n",
      "6\n",
      "865\n",
      "6\n",
      "866\n",
      "6\n",
      "867\n",
      "6\n",
      "868\n",
      "6\n",
      "869\n",
      "6\n",
      "870\n",
      "6\n",
      "871\n",
      "6\n",
      "872\n",
      "6\n",
      "873\n",
      "6\n",
      "874\n",
      "6\n",
      "875\n",
      "6\n",
      "876\n",
      "6\n",
      "877\n",
      "6\n",
      "878\n",
      "6\n",
      "879\n",
      "6\n",
      "880\n",
      "6\n",
      "881\n",
      "6\n",
      "882\n",
      "6\n",
      "883\n",
      "6\n",
      "884\n",
      "6\n",
      "885\n",
      "6\n",
      "886\n",
      "6\n",
      "887\n",
      "6\n",
      "888\n",
      "6\n",
      "889\n",
      "6\n",
      "890\n",
      "6\n",
      "891\n",
      "6\n",
      "892\n",
      "6\n",
      "893\n",
      "6\n",
      "894\n",
      "6\n",
      "895\n",
      "6\n",
      "896\n",
      "6\n",
      "897\n",
      "6\n",
      "898\n",
      "6\n",
      "899\n",
      "6\n",
      "900\n",
      "6\n",
      "901\n",
      "6\n",
      "902\n",
      "6\n",
      "903\n",
      "6\n",
      "904\n",
      "6\n",
      "905\n",
      "6\n",
      "906\n",
      "6\n",
      "907\n",
      "6\n",
      "908\n",
      "6\n",
      "909\n",
      "6\n",
      "910\n",
      "6\n",
      "911\n",
      "6\n",
      "912\n",
      "6\n",
      "913\n",
      "6\n",
      "914\n",
      "6\n",
      "915\n",
      "6\n",
      "916\n",
      "6\n",
      "917\n",
      "6\n",
      "918\n",
      "6\n",
      "919\n",
      "6\n",
      "920\n",
      "6\n",
      "921\n",
      "6\n",
      "922\n",
      "6\n",
      "923\n",
      "6\n",
      "924\n",
      "6\n",
      "925\n",
      "6\n",
      "926\n",
      "6\n",
      "927\n",
      "6\n",
      "928\n",
      "6\n",
      "929\n",
      "6\n",
      "930\n",
      "6\n",
      "931\n",
      "6\n",
      "932\n",
      "6\n",
      "933\n",
      "6\n",
      "934\n",
      "6\n",
      "935\n",
      "6\n",
      "936\n",
      "6\n",
      "937\n",
      "6\n",
      "938\n",
      "6\n",
      "939\n",
      "6\n",
      "940\n",
      "6\n",
      "941\n",
      "6\n",
      "942\n",
      "6\n",
      "943\n",
      "6\n",
      "944\n",
      "6\n",
      "945\n",
      "6\n",
      "946\n",
      "6\n",
      "947\n",
      "6\n",
      "948\n",
      "6\n",
      "949\n",
      "6\n",
      "950\n",
      "6\n",
      "951\n",
      "6\n",
      "952\n",
      "6\n",
      "953\n",
      "6\n",
      "954\n",
      "6\n",
      "955\n",
      "6\n",
      "956\n",
      "6\n",
      "957\n",
      "6\n",
      "958\n",
      "6\n",
      "959\n",
      "6\n",
      "960\n",
      "6\n",
      "961\n",
      "6\n",
      "962\n",
      "6\n",
      "963\n",
      "6\n",
      "964\n",
      "6\n",
      "965\n",
      "6\n",
      "966\n",
      "6\n",
      "967\n",
      "6\n",
      "968\n",
      "6\n",
      "969\n",
      "6\n",
      "970\n",
      "6\n",
      "971\n",
      "6\n",
      "972\n",
      "6\n",
      "973\n",
      "6\n",
      "974\n",
      "6\n",
      "975\n",
      "6\n",
      "976\n",
      "6\n",
      "977\n",
      "6\n",
      "978\n",
      "6\n",
      "979\n",
      "6\n",
      "980\n",
      "6\n",
      "981\n",
      "6\n",
      "982\n",
      "6\n",
      "983\n",
      "6\n",
      "984\n",
      "6\n",
      "985\n",
      "6\n",
      "986\n",
      "6\n",
      "987\n",
      "6\n",
      "988\n",
      "6\n",
      "989\n",
      "6\n",
      "990\n",
      "6\n",
      "991\n",
      "6\n",
      "992\n",
      "6\n",
      "993\n",
      "6\n",
      "994\n",
      "6\n",
      "995\n",
      "6\n",
      "996\n",
      "6\n",
      "997\n",
      "6\n",
      "998\n",
      "6\n",
      "999\n",
      "6\n",
      "1000\n",
      "6\n",
      "1001\n",
      "6\n",
      "1002\n",
      "6\n",
      "1003\n",
      "6\n",
      "1004\n",
      "6\n",
      "1005\n",
      "6\n",
      "1006\n",
      "6\n",
      "1007\n",
      "6\n",
      "1008\n",
      "6\n",
      "1009\n",
      "6\n",
      "1010\n",
      "6\n",
      "1011\n",
      "6\n",
      "1012\n",
      "6\n",
      "1013\n",
      "6\n",
      "1014\n",
      "6\n",
      "1015\n",
      "6\n",
      "1016\n",
      "6\n",
      "1017\n",
      "6\n",
      "1018\n",
      "6\n",
      "1019\n",
      "6\n",
      "1020\n",
      "6\n",
      "1021\n",
      "6\n",
      "1022\n",
      "6\n",
      "1023\n",
      "6\n",
      "1024\n",
      "6\n",
      "1025\n",
      "6\n",
      "1026\n",
      "6\n",
      "1027\n",
      "6\n",
      "1028\n",
      "6\n",
      "1029\n",
      "6\n",
      "1030\n",
      "6\n",
      "1031\n",
      "6\n",
      "1032\n",
      "6\n",
      "1033\n",
      "6\n",
      "1034\n",
      "6\n",
      "1035\n",
      "6\n",
      "1036\n",
      "6\n",
      "1037\n",
      "6\n",
      "1038\n",
      "6\n",
      "1039\n",
      "6\n",
      "1040\n",
      "6\n",
      "1041\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-b71d40e5a999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mnr_missed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nr_missed = []\n",
    "\n",
    "for k in range(1,len(best_words)+1):\n",
    "    print(k)\n",
    "    \n",
    "    nr_missed.append(0)\n",
    "    for doc in X:\n",
    "        \n",
    "        words = doc.split()\n",
    "        if len(set(words) & set(best_words[:k])) == 0:\n",
    "            nr_missed[-1] += 1\n",
    "            \n",
    "        \n",
    "#     print('over',k)\n",
    "    print(nr_missed[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-eafabb19d0a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_words_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_words' is not defined"
     ]
    }
   ],
   "source": [
    "best_words_counts = {k:word_counts[k] for k in best_words[:100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_words_counts = {k:v/sum(word_counts.values()) for k, v in best_words_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/utils.py'>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_words_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-9148fdc4588a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDocVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_words_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_words_counts' is not defined"
     ]
    }
   ],
   "source": [
    "docvectorizer = utils.DocVectorizer(model, word_counts=best_words_counts, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = docvectorizer.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_size': 8, 'dropout': 0.87853270724439758, 'architecture': 365, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87853270724439758, 'architecture': 365, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87853270724439758, 'architecture': 365, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.80632328797834929, 'architecture': 310, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.80632328797834929, 'architecture': 310, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.80632328797834929, 'architecture': 310, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53157265342878413, 'architecture': 575, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53157265342878413, 'architecture': 575, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53157265342878413, 'architecture': 575, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.63532757329161627, 'architecture': 787, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.63532757329161627, 'architecture': 787, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.63532757329161627, 'architecture': 787, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.98787739425520127, 'architecture': 583, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.98787739425520127, 'architecture': 583, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.98787739425520127, 'architecture': 583, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.74081921713474763, 'architecture': 599, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.74081921713474763, 'architecture': 599, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.74081921713474763, 'architecture': 599, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.88090310575821351, 'architecture': 465, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.88090310575821351, 'architecture': 465, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.88090310575821351, 'architecture': 465, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.66587630666977859, 'architecture': 701, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.66587630666977859, 'architecture': 701, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.66587630666977859, 'architecture': 701, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.88916259201759718, 'architecture': 792, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.88916259201759718, 'architecture': 792, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.88916259201759718, 'architecture': 792, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67533099558555987, 'architecture': 498, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67533099558555987, 'architecture': 498, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67533099558555987, 'architecture': 498, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.91266274367102573, 'architecture': 641, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.91266274367102573, 'architecture': 641, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.91266274367102573, 'architecture': 641, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.95624515165137902, 'architecture': 580, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.95624515165137902, 'architecture': 580, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.95624515165137902, 'architecture': 580, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.5928704562432936, 'architecture': 449, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.5928704562432936, 'architecture': 449, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.5928704562432936, 'architecture': 449, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.74374573525345666, 'architecture': 515, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.74374573525345666, 'architecture': 515, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.74374573525345666, 'architecture': 515, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.96095569069089737, 'architecture': 658, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.96095569069089737, 'architecture': 658, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.96095569069089737, 'architecture': 658, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.79730709534645028, 'architecture': 477, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.79730709534645028, 'architecture': 477, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.79730709534645028, 'architecture': 477, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.60009165309167678, 'architecture': 514, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.60009165309167678, 'architecture': 514, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.60009165309167678, 'architecture': 514, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.57068754753357331, 'architecture': 661, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.57068754753357331, 'architecture': 661, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.57068754753357331, 'architecture': 661, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.66093239504761381, 'architecture': 352, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.66093239504761381, 'architecture': 352, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.66093239504761381, 'architecture': 352, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.7962462987892458, 'architecture': 512, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.7962462987892458, 'architecture': 512, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.7962462987892458, 'architecture': 512, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.76187060055437006, 'architecture': 371, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.76187060055437006, 'architecture': 371, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.76187060055437006, 'architecture': 371, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.61047410550890768, 'architecture': 326, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.61047410550890768, 'architecture': 326, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.61047410550890768, 'architecture': 326, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.81819236358194991, 'architecture': 350, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.81819236358194991, 'architecture': 350, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.81819236358194991, 'architecture': 350, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87458127338004044, 'architecture': 644, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87458127338004044, 'architecture': 644, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87458127338004044, 'architecture': 644, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.71795475699064015, 'architecture': 468, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.71795475699064015, 'architecture': 468, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.71795475699064015, 'architecture': 468, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.69236379130923087, 'architecture': 549, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.69236379130923087, 'architecture': 549, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.69236379130923087, 'architecture': 549, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.60687903188444103, 'architecture': 726, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.60687903188444103, 'architecture': 726, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.60687903188444103, 'architecture': 726, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.76265850919247113, 'architecture': 385, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.76265850919247113, 'architecture': 385, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.76265850919247113, 'architecture': 385, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.68413259847669905, 'architecture': 775, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.68413259847669905, 'architecture': 775, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.68413259847669905, 'architecture': 775, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.83230583531684599, 'architecture': 452, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.83230583531684599, 'architecture': 452, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.83230583531684599, 'architecture': 452, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.73538739614455828, 'architecture': 753, 'input_size': 300}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_size': 8, 'dropout': 0.73538739614455828, 'architecture': 753, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.73538739614455828, 'architecture': 753, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.85081546871180869, 'architecture': 757, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.85081546871180869, 'architecture': 757, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.85081546871180869, 'architecture': 757, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.84749896641875844, 'architecture': 753, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.84749896641875844, 'architecture': 753, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.84749896641875844, 'architecture': 753, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.71759772521514376, 'architecture': 506, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.71759772521514376, 'architecture': 506, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.71759772521514376, 'architecture': 506, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.77428860428437507, 'architecture': 474, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.77428860428437507, 'architecture': 474, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.77428860428437507, 'architecture': 474, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.83938848468300598, 'architecture': 786, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.83938848468300598, 'architecture': 786, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.83938848468300598, 'architecture': 786, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.73314523126027065, 'architecture': 343, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.73314523126027065, 'architecture': 343, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.73314523126027065, 'architecture': 343, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.92421859560373898, 'architecture': 506, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.92421859560373898, 'architecture': 506, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.92421859560373898, 'architecture': 506, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.81652804025919734, 'architecture': 422, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.81652804025919734, 'architecture': 422, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.81652804025919734, 'architecture': 422, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.6961122997959861, 'architecture': 623, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.6961122997959861, 'architecture': 623, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.6961122997959861, 'architecture': 623, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.86589291141428948, 'architecture': 450, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.86589291141428948, 'architecture': 450, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.86589291141428948, 'architecture': 450, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.70710738125153061, 'architecture': 529, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.70710738125153061, 'architecture': 529, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.70710738125153061, 'architecture': 529, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.73124554299396904, 'architecture': 478, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.73124554299396904, 'architecture': 478, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.73124554299396904, 'architecture': 478, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.68629546368269789, 'architecture': 457, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.68629546368269789, 'architecture': 457, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.68629546368269789, 'architecture': 457, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.50093946648777998, 'architecture': 683, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.50093946648777998, 'architecture': 683, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.50093946648777998, 'architecture': 683, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.68629443479432095, 'architecture': 327, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.68629443479432095, 'architecture': 327, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.68629443479432095, 'architecture': 327, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.65978332423102082, 'architecture': 489, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.65978332423102082, 'architecture': 489, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.65978332423102082, 'architecture': 489, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.78707937549398554, 'architecture': 683, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.78707937549398554, 'architecture': 683, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.78707937549398554, 'architecture': 683, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.81692078642605703, 'architecture': 311, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.81692078642605703, 'architecture': 311, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.81692078642605703, 'architecture': 311, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.69546575984552905, 'architecture': 387, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.69546575984552905, 'architecture': 387, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.69546575984552905, 'architecture': 387, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.79112694940413941, 'architecture': 360, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.79112694940413941, 'architecture': 360, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.79112694940413941, 'architecture': 360, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.83244423214581076, 'architecture': 492, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.83244423214581076, 'architecture': 492, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.83244423214581076, 'architecture': 492, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.89525141801297703, 'architecture': 753, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.89525141801297703, 'architecture': 753, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.89525141801297703, 'architecture': 753, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53654918564818499, 'architecture': 622, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53654918564818499, 'architecture': 622, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53654918564818499, 'architecture': 622, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.76732336625285447, 'architecture': 560, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.76732336625285447, 'architecture': 560, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.76732336625285447, 'architecture': 560, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.97377121811239664, 'architecture': 354, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.97377121811239664, 'architecture': 354, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.97377121811239664, 'architecture': 354, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.84897873012610625, 'architecture': 639, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.84897873012610625, 'architecture': 639, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.84897873012610625, 'architecture': 639, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.51165693995601802, 'architecture': 674, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.51165693995601802, 'architecture': 674, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.51165693995601802, 'architecture': 674, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.9356923945816451, 'architecture': 638, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.9356923945816451, 'architecture': 638, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.9356923945816451, 'architecture': 638, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.84597600001412832, 'architecture': 421, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.84597600001412832, 'architecture': 421, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.84597600001412832, 'architecture': 421, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.81524407002326038, 'architecture': 719, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.81524407002326038, 'architecture': 719, 'input_size': 300}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_size': 8, 'dropout': 0.81524407002326038, 'architecture': 719, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.62583046866474157, 'architecture': 372, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.62583046866474157, 'architecture': 372, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.62583046866474157, 'architecture': 372, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.81728030455457645, 'architecture': 468, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.81728030455457645, 'architecture': 468, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.81728030455457645, 'architecture': 468, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.86980199583729223, 'architecture': 657, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.86980199583729223, 'architecture': 657, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.86980199583729223, 'architecture': 657, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87132941894390437, 'architecture': 629, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87132941894390437, 'architecture': 629, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87132941894390437, 'architecture': 629, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53363366910928778, 'architecture': 673, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53363366910928778, 'architecture': 673, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53363366910928778, 'architecture': 673, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67311902357875586, 'architecture': 761, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67311902357875586, 'architecture': 761, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67311902357875586, 'architecture': 761, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53108225549188015, 'architecture': 779, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53108225549188015, 'architecture': 779, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53108225549188015, 'architecture': 779, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.59533212591845308, 'architecture': 454, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.59533212591845308, 'architecture': 454, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.59533212591845308, 'architecture': 454, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.64429172559833492, 'architecture': 565, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.64429172559833492, 'architecture': 565, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.64429172559833492, 'architecture': 565, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.80717454355893081, 'architecture': 407, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.80717454355893081, 'architecture': 407, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.80717454355893081, 'architecture': 407, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.50800411602206197, 'architecture': 480, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.50800411602206197, 'architecture': 480, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.50800411602206197, 'architecture': 480, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.59557223001222415, 'architecture': 622, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.59557223001222415, 'architecture': 622, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.59557223001222415, 'architecture': 622, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87710940781322821, 'architecture': 672, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87710940781322821, 'architecture': 672, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87710940781322821, 'architecture': 672, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.50721400768513991, 'architecture': 698, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.50721400768513991, 'architecture': 698, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.50721400768513991, 'architecture': 698, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.69600231436954041, 'architecture': 323, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.69600231436954041, 'architecture': 323, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.69600231436954041, 'architecture': 323, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.54713460791918966, 'architecture': 506, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.54713460791918966, 'architecture': 506, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.54713460791918966, 'architecture': 506, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.79045950452998182, 'architecture': 311, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.79045950452998182, 'architecture': 311, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.79045950452998182, 'architecture': 311, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.84500835951857289, 'architecture': 745, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.84500835951857289, 'architecture': 745, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.84500835951857289, 'architecture': 745, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.74098198909644797, 'architecture': 641, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.74098198909644797, 'architecture': 641, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.74098198909644797, 'architecture': 641, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.60425482583387891, 'architecture': 423, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.60425482583387891, 'architecture': 423, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.60425482583387891, 'architecture': 423, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.90043436958751921, 'architecture': 541, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.90043436958751921, 'architecture': 541, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.90043436958751921, 'architecture': 541, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67197187168460604, 'architecture': 419, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67197187168460604, 'architecture': 419, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67197187168460604, 'architecture': 419, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.97905647089546266, 'architecture': 644, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.97905647089546266, 'architecture': 644, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.97905647089546266, 'architecture': 644, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.50888765761962151, 'architecture': 532, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.50888765761962151, 'architecture': 532, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.50888765761962151, 'architecture': 532, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.95008672442945707, 'architecture': 535, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.95008672442945707, 'architecture': 535, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.95008672442945707, 'architecture': 535, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67826325238359342, 'architecture': 522, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67826325238359342, 'architecture': 522, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67826325238359342, 'architecture': 522, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53970848728773579, 'architecture': 776, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53970848728773579, 'architecture': 776, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.53970848728773579, 'architecture': 776, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.94624557623818428, 'architecture': 366, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.94624557623818428, 'architecture': 366, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.94624557623818428, 'architecture': 366, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.59842012456801541, 'architecture': 720, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.59842012456801541, 'architecture': 720, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.59842012456801541, 'architecture': 720, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67213579505081067, 'architecture': 489, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67213579505081067, 'architecture': 489, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.67213579505081067, 'architecture': 489, 'input_size': 300}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_size': 8, 'dropout': 0.63544704367169169, 'architecture': 631, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.63544704367169169, 'architecture': 631, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.63544704367169169, 'architecture': 631, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.74336379025020771, 'architecture': 562, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.74336379025020771, 'architecture': 562, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.74336379025020771, 'architecture': 562, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87714869173967669, 'architecture': 650, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87714869173967669, 'architecture': 650, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87714869173967669, 'architecture': 650, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.75900236189447423, 'architecture': 463, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.75900236189447423, 'architecture': 463, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.75900236189447423, 'architecture': 463, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.99508772592845984, 'architecture': 667, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.99508772592845984, 'architecture': 667, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.99508772592845984, 'architecture': 667, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.8153098372399139, 'architecture': 638, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.8153098372399139, 'architecture': 638, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.8153098372399139, 'architecture': 638, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87330792135917179, 'architecture': 575, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87330792135917179, 'architecture': 575, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.87330792135917179, 'architecture': 575, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.93352997535691573, 'architecture': 756, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.93352997535691573, 'architecture': 756, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.93352997535691573, 'architecture': 756, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.7219539867782111, 'architecture': 574, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.7219539867782111, 'architecture': 574, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.7219539867782111, 'architecture': 574, 'input_size': 300}\n",
      "{'output_size': 8, 'dropout': 0.69600231436954041, 'architecture': 323, 'input_size': 300}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=<models.Model object at 0x7f3b752896d8>, fit_params={},\n",
       "          iid=True, n_iter=100, n_jobs=1,\n",
       "          param_distributions={'batch': [128, 256, 512], 'dropout': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f3b75289c50>, 'iters': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f3b75289d30>, 'architecture': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f3b75289fd0>, 'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f3b75289e10>, 'lr': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f3b752896a0>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nn = models.Model('mlp', lr=1e-3, class_balance=False, batch=256, iters=300, alpha=1e-3, \n",
    "                  architecture=[500], dropout=1)\n",
    "\n",
    "\n",
    "searcher = RandomizedSearchCV(nn, n_iter=100, param_distributions={'lr':uniform(1e-5, 1e-1), 'dropout':uniform(loc=.5, scale=.5),\n",
    "                                             'alpha':uniform(1e-4, 1e-2), 'batch':[128, 256, 512], \n",
    "                                               'architecture':randint(300, 800), 'iters': randint(50, 300)\n",
    "                                                                })\n",
    "\n",
    "searcher.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61534749034749037"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "nn = models.Model('mlp', lr=1e-3, class_balance=False, batch=256, iters=300, alpha=1e-3, \n",
    "                  architecture=[500], dropout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<models.Model at 0x7f895ced52b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.set_params(**{'alpha': 0.00023090522206274048,\n",
    " 'architecture': 396,\n",
    " 'batch': 512,\n",
    " 'dropout': 0.89291615635753208,\n",
    " 'iters': 210,\n",
    " 'lr': 0.059455630570591084})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx, dy = docv.fit_transform(x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_size': 8, 'dropout': 0.8929161563575321, 'architecture': 396, 'input_size': 300}\n",
      "start training 210 left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 left, train nan, test nan\n",
      "200 left, train nan, test nan\n",
      "190 left, train nan, test nan\n",
      "180 left, train nan, test nan\n",
      "170 left, train nan, test nan\n",
      "160 left, train nan, test nan\n",
      "150 left, train nan, test nan\n",
      "140 left, train nan, test nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-903d9e17acec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miters\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/models.py\u001b[0m in \u001b[0;36mstep_fit\u001b[0;34m(self, X, y, weights)\u001b[0m\n\u001b[1;32m    126\u001b[0m                          self.placeholders['training']:True})\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn.fit(dx, dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = list(zip(*dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.asarray(list(zip(*y))).astype(int).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.69935807136775685, 'log loss': 1.9924949948223531, 'recall': 0.72645062686876638, 'accuracy': 0.7360153256704981}\n",
      "{'precision': 0.65557981259919096, 'log loss': 1.5137354187718741, 'recall': 0.71904177628274468, 'accuracy': 0.76743295019157087}\n",
      "{'precision': 0.57043700914307127, 'log loss': 6.0160787917706982, 'recall': 0.63021773377410972, 'accuracy': 0.71149425287356327}\n"
     ]
    }
   ],
   "source": [
    "pips = []\n",
    "\n",
    "for c in range(3):\n",
    "    \n",
    "    score, pip = utils.train_test_pipeline(BinaryVectorizer, \n",
    "                                           model=BernoulliNB, data=(X, y[:, c]), \n",
    "                                           vocabulary=at_least_threshold)\n",
    "    \n",
    "    pips.append(pip)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/utils.py'>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.42892720306513415,\n",
       " 'log loss': 3.0851288051313102,\n",
       " 'partial accuracy': 0.73844189016602813,\n",
       " 'precision': 0.37914609243088526,\n",
       " 'recall': 0.6194880638351401}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.train_mlc(BinaryVectorizer, BernoulliNB, (X, y), vocabulary = at_least_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = [pips[i].predict(X) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = np.asarray(preds).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45467625899280578"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(y == preds, axis=1).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
