{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import utils, imp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use any sentiment training, it might be worth exploring, which words are in any way determining labels. There are more than 70k words, so learning matrices capable of processing vectors that huge is going to take forever. Most of them is going be not so informative - for instance, words like 'I', 'the', 'will', 'be', 'want' are most likely going to occur in every label with roughly the same probability. \n",
    "\n",
    "What I will want to find, will be how distributions of joint probability $P( W, L )$ diverges from independence assumptions $P( W, L ) = P(W)P(L)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What models am I going to build? First one will be simple Naive Bayes. I will test for occurence of given word, its count and Tf-Idf score. I will use CountVectorizer and TfidfVectorizer from sci-kit learn package. Moreover, using vectors given by these models as inputs, I will build simple logistic regression and neural network with one hidden layer. Another model I'm curious to check out would be average over word embeddings in sentence. At last, I will reach recurrent neural networks, which I expect to explore more deeply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to desire to keep this notebook somewhat clean and readable, I'm storing both all of my helper functions and models in separate files. I will try to explain what is going on, but they are easily checkable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset, test = utils.load_and_train_test_split(keywords=['technology', 'design', 'entertainment'], train_size=.7)\n",
    "\n",
    "#it loads and shuffles my training data from TED dataset. Here used with default parameters. Under the hood, it also\n",
    "#does some basic preprocessing - turns to lowercase, deletes numbers and diactric signs\n",
    "\n",
    "x_train, y_train = list(zip(*dataset))\n",
    "y_train, labels_readable = utils.transform_labels_usable(y_train)\n",
    "\n",
    "x_test, y_test = list(zip(*test))\n",
    "y_test = utils.transform_labels_usable(y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7]),\n",
       " array([796, 111, 116,  19, 271,  23, 100,  23]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes are highly imbalanced. This is going to be a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to need some plotting device. Matplotlib is indispensable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine most useful words, I will need some metric of difference between two distributions of probability - first one being proportional to labels' frequency in dataset and other one conditioned by word. There are two common ways to do this - first one is called mutual information score, second is Chi-Squared test. \n",
    "\n",
    "$$ MI = \\sum_{w_i \\in W} \\sum_{l_j \\in L} P( w = w_i, l = l_j ) \\log \\frac{P( w = w_i, l = l_j )}{P( w = w_i) P(l = l_j)} $$\n",
    "\n",
    "Those of you familiar with statistics can recognize this as cross entropy - basically we are testing how different our joint distribution is from distributions that holds independence assumption.\n",
    "\n",
    "Chi-Squared test also tests this difference, but with more straightforward way.\n",
    "\n",
    "$$ \\tilde{\\chi}^2 = \\sum_{w_i \\in W} \\sum_{l_j \\in L} \\frac{\\left( N_{ w_i, l_j} - E_{  w_i, l_j } \\right)^2}{E_{ w_i, l_j }}$$\n",
    "\n",
    "where $N_{ w = w_i, l = l_j}$ is number of real occurences of both word and label and $E_{ w = w_i, l = l_j }$ is number of occurence should these two factors were independent. $\\tilde{\\chi}^2$ is probability distribution - if it is in \n",
    "\n",
    "Fortunately, I don't have to write this pretty straightforward functions myself - sci-kit learn package is going to do all tedious processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, I can't really use all the words. Many of them occurs only once, so it would be basically relying on chance. I have to assert that every $P( w = w_i, l = l_j )$ is greater than zero, at the very least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counts = utils.count_words(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proportions_dict = utils.calculate_probs_occurence(word_counts.keys(), x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check number of words fulfilling the condition of having at least 20 occurences in every class. Apart from that, I will test for showing up in at least ten percent of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perc_threshold = int(len(x_train)/10)\n",
    "occ_threshold = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "at_least_occ = list(filter(lambda x: np.all(proportions_dict[x] > occ_threshold), proportions_dict.keys()))\n",
    "at_least_threshold = list(filter(lambda x: np.sum(proportions_dict[x])>perc_threshold, proportions_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(at_least_occ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that was unexpected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1118"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(at_least_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "at_least_5 = list(filter(lambda x: np.all(proportions_dict[x]>5), proportions_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(at_least_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, everything will be determined be final score of the estimator - maybe someone more skilled in statistics would be able to predict, which approach is going to yield better accuracy of predictions? Before I get around to testing predictors, it's time to check how these sets encapsulate each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "818"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(at_least_threshold) - set(at_least_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I do any feature engineering, let's check how simple models are going to perform on last two sets of words. I will use three vectorizers and three different models, respectively. Binary count vectorizer will select features for Bernoulli Naive Bayes ( further NB ), ordinary count vectorizer will produce inputs for Multinomial NB and tf-idf vectorizer will fabricate samples for Gaussian NB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do I mean by text vectorizer? Well, it is simply function that takes some given sequence of words as input and outputs some vector of numbers - be it integers or reals. For instance, for dictionary of words of size $N$, vectorizer will output vector of size $N$. Number on $i$-th position will be representing frequency, occurence (or lack thereof) of $i$-th word. In binary vectorizer, it will be 1 if word was found in given text and zero otherwise. In count vectorizer, it is going be number of times word was found in text. Misterious tf-idf vectorizer will return number produced by equation: $\\frac{\\#w_{ji}}{\\#w_j} \\cdot \\frac{N}{\\log 1 + D_{w_i} }$, where $w_j$ denotes number of words in document, $w_{ji}$ number of times word $w_i$ can be found in $D_j$ and $D_{w_i}$ is number of documents which one can find $w_i$ in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've decided to import accuracy_score only for brevity - displaying confusion matrix, while useful, is going to take up a lot of place in this notebook. It would be reasonable for one classifier, but not for six of them (two vocab sets, three models ). Since this is multiclass problem, I can't really use other metrics such as precision and recall out of the box - I would have to turn this into multiple binary classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BinaryVectorizer = partial(CountVectorizer, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/utils.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overall_scores = []\n",
    "pips = []\n",
    "vect_model = list(zip([BinaryVectorizer, CountVectorizer, TfidfVectorizer],[BernoulliNB, MultinomialNB, GaussianNB]))\n",
    "for vocab in [at_least_5, at_least_threshold]:\n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        vectorizer, model = vect_model[i]\n",
    "        params = {\n",
    "            'vectorizer':vectorizer,\n",
    "            'model':model,\n",
    "            'vocabulary':vocab,\n",
    "            'data':data\n",
    "        }\n",
    "        score, pip = utils.train_test_pipeline(**params)\n",
    "        overall_scores.append(score)\n",
    "        pips.append(pip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'test': 0.40894568690095845, 'train': 0.46196024674434544},\n",
       " {'test': 0.42971246006389774, 'train': 0.48320767649074708},\n",
       " {'test': 0.40734824281150162, 'train': 0.5476353666895134},\n",
       " {'test': 0.46325878594249204, 'train': 0.60795065113091162},\n",
       " {'test': 0.51118210862619806, 'train': 0.62919808087731321},\n",
       " {'test': 0.52396166134185307, 'train': 0.78272789581905411}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score, pip = utils.train_test_pipeline(vectorizer=BinaryVectorizer, model=MultinomialNB, vocabulary=at_least_threshold, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'test': 0.52715654952076674, 'train': 0.70185058259081567},\n",
       " Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "    ...     validate=True)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overall_scores.append(score)\n",
    "pips.append(pip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unexpected winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pips[-1].predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': [0.6, 0.58, 0.37, 0.0, 0.53, 0.14, 0.26, 0.0], 'precision': [0.75, 0.26, 0.45, 0.0, 0.44, 0.17, 0.25, 0.0]}\n",
      "{'recall': [0.63, 0.4, 0.41, 0.0, 0.51, 0.0, 0.26, 0.0], 'precision': [0.74, 0.39, 0.28, 0.0, 0.39, 0.0, 0.22, 0.0]}\n",
      "{'recall': [0.54, 0.66, 0.48, 0.0, 0.55, 0.0, 0.31, 0.12], 'precision': [0.78, 0.32, 0.46, 0.0, 0.4, 0.0, 0.26, 0.11]}\n",
      "{'recall': [0.52, 0.44, 0.28, 0.0, 0.58, 0.0, 0.13, 0.0], 'precision': [0.74, 0.16, 0.39, 0.0, 0.38, 0.0, 0.28, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    \n",
    "    predictions = pips[-i].predict(x_test)\n",
    "    print({n:np.round(utils.test_score_one_vs_all(predictions, y_test, func), 2).tolist()\n",
    "           for n, func in zip(['precision', 'recall'], [precision_score, recall_score])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very impressive - we see that rare classes were rarely ( mostly not at all ) correctly labeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Finally, it's time to select best features, so I can be honest while comparing scores of different classifiers. It would not be very wise to give verdict \"Naive Bayes is crap\" while not taking elementary steps to make it a little bit better.\n",
    "\n",
    "I'll start off with MIS. Also, since this is neither production-level analysis nor Kaggle contest, I will use only two best-performing models from previous pipeline - which means Multinomial Naive Bayes on top of Binary Vectorizer and Gaussian NB on top of Tf-idf. It does not mean, of course, that some other model would not outperform this one with less number of irrelevant words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstraction of an abstraction ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/utils.py'>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer, Normalizer, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "            'vocabulary':vocab,\n",
    "            'data':data\n",
    "        }\n",
    "\n",
    "gparams = {\n",
    "    'model':GaussianNB,\n",
    "    'vectorizer':TfidfVectorizer\n",
    "}\n",
    "\n",
    "gparams.update(params)\n",
    "\n",
    "bparams = {\n",
    "    'model':MultinomialNB,\n",
    "    'vectorizer':BinaryVectorizer\n",
    "}\n",
    "\n",
    "bparams.update(params)\n",
    "\n",
    "binary = []\n",
    "gauss = []\n",
    "\n",
    "for k in range(100, 1200, 100):\n",
    "    \n",
    "    mic = {'selection_func':mutual_info_classif, 'k':k}\n",
    "    bparams.update(mic)\n",
    "    bscore, pip = utils.feature_selection_pipeline(**bparams)\n",
    "    \n",
    "    gparams.update(mic)\n",
    "    gscore, pip = utils.feature_selection_pipeline(**gparams)\n",
    "    \n",
    "    bparams.update({'selection_func':chi2})\n",
    "    bscore_2, pip = utils.feature_selection_pipeline(**bparams)\n",
    "    \n",
    "    gparams.update({'selection_func':chi2})\n",
    "    gscore_2, pip = utils.feature_selection_pipeline(**gparams)\n",
    "    \n",
    "    binary.append(( bscore['test'], bscore_2['test'] ))\n",
    "    gauss.append((gscore['test'], gscore_2['test']))\n",
    "    \n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd4VFX6wPHvmUkPEEihpDGB0EsgBEILVRQbooILWAAV\nGy4qsivqz3Wtq6669q7YQUBURFCREpqU0HsIEEgoaZRAQvr5/XEHDBDIJJlkJpP38zx5zNz6Xie8\nc+ecc9+jtNYIIYSoG0yODkAIIUTNkaQvhBB1iCR9IYSoQyTpCyFEHSJJXwgh6hBJ+kIIUYdI0hdC\niDpEkr4QQtQhkvSFEKIOcXN0ABcKDAzUFovF0WEIIUStsn79+kytdVB52zld0rdYLCQkJDg6DCGE\nqFWUUgds2U6ad4QQog6RpC+EEHWIJH0hhKhDnK5NXwghLqewsJDU1FTy8vIcHYpDeHl5ERoairu7\ne6X2l6QvhKhVUlNTqV+/PhaLBaWUo8OpUVprsrKySE1NJSIiolLHkOYdIUStkpeXR0BAQJ1L+ABK\nKQICAqr0LUeSvhCi1qmLCf+sql676yT93GOw9GU4stnRkQghhNNynaRvMkP8S7DrF0dHIoRwcUop\nbrvttnOvi4qKCAoK4rrrrgPg888/58EHH3RUeJflOknfyw+aRUHyCkdHIoRwcb6+vmzbto0zZ84A\nsHDhQkJCQhwclW1cJ+kDWPpC6jooPOPoSIQQLu6aa67hl1+MloXp06czevRoB0dkG9casmnpB6ve\nhpS10KK/o6MRQlSzZ37ezo7D2XY9ZvvgBjx9fYdytxs1ahTPPvss1113HVu2bOHOO+9k+fLldo2l\nOrjWnX54T1AmaeIRQlS7zp07k5yczPTp07nmmmscHY7NXOtO36sBNOsiSV+IOsKWO/LqNGzYMKZM\nmcLSpUvJyspyaCy2cq2kDxARB3++BwW54OHj6GiEEC7szjvvpGHDhnTq1ImlS5c6OhybuFbzDoAl\nDkoKIXWtoyMRQri40NBQJk2a5OgwKsT1kn54T1BmaeIRQlSb06dPX7RswIABzJs3D4Bx48bxzjvv\n1HRYNnG9pO9ZH4K7wn7n70UXQoia5npJH4zx+ofWQ0GOoyMRQgin4qJJ39qunyLt+kIIUZprJv1z\n7frSxCOEEKW5ZtL3rAch0dKZK4QQF3DNpA/Sri+EEGVw4aQfByVFcHC1oyMRQri4cePGMXv27IuW\nHz58mBEjRpy37MiRI0RGRhIdHc2pU6fOLc/NzeXaa6+lbdu2dOjQgalTp1ZLrK6b9MNiweQmTTxC\nCIcJDg4+78Pg1KlTDB8+nJdffpmxY8cyYsQICgsLz62fMmUKu3btYuPGjaxcuZIFCxbYPSabkr5S\naqhSardSKkkpddHHj1JqnFIqQym1yfpzt3X5wFLLNiml8pRSw+19EWXyrAfB0q4vhLC/L7/8ks6d\nOxMVFcXtt98OwLJly+jduzctWrQ4l+iTk5Pp2LEjAIWFhYwePZrHHnuMm2++mYceeohhw4YxYcIE\nAHx8fBg4cCAAHh4eREdHk5qaavfYy629o5QyA+8CQ4BUYJ1Saq7WescFm36ntT5vqhit9RKgi/U4\n/kAS8Ls9ArdJRBysfBPyTxsfAkII17JgKhzdat9jNu0EV790ydXbt2/n+eefZ9WqVQQGBnLs2DEm\nT57MkSNHWLFiBbt27WLYsGEXNeu4u7ufe2L3rIkTJ5Z5jhMnTvDzzz/z0EMPVf16LmDLnX4PIElr\nvU9rXQDMAG6oxLlGAAu01rmV2LdyLH2Ndv0UadcXQtjH4sWLGTlyJIGBgQD4+/sDMHz4cEwmE+3b\ntyctLa3Sxy8qKmL06NFMmjSJFi1a2CXm0mypshkCpJR6nQrElrHdzUqpfkAi8IjWOuWC9aOA1ysV\nZWWVbtePvKJGTy2EqAGXuSOvaZ6enud+11pX+jj33HMPrVq14uGHH7ZHWBexV0fuz4BFa90ZWAh8\nUXqlUqoZ0An4raydlVL3KKUSlFIJGRkZdgoJ8PCFkG7Sri+EsJtBgwYxa9asc/Xzjx07Zrdj/9//\n/R8nT57kjTfesNsxL2RL0j8EhJV6HWpddo7WOktrnW99+QnQ7YJj3AL8oLUupAxa64+01jFa65ig\noCDbIreVJQ4ObYD8U+VvK4QQ5ejQoQNPPvkk/fv3JyoqismTJ9vluKmpqbzwwgvs2LGD6OhounTp\nwieffGKXY5dmS/POOqCVUioCI9mPAsaU3kAp1UxrfcT6chiw84JjjAYer2KslWPpC8tfhYNroJU0\n8Qghqm7s2LGMHTv2kuvPll62WCxs27bNpmOGhoZWqVnIVuXe6Wuti4AHMZpmdgIztdbblVLPKqWG\nWTebpJTarpTaDEwCxp3dXyllwfimEG/f0G0UFgsmd6nDI4QQ2DhdotZ6PjD/gmX/KvX741ziTl5r\nnYzRGewYHj4QGiNJXwghcOUnckuz9IXDmyAv29GRCCHsoCaaQZxVVa+97iR9XQwpaxwdiRCiiry8\nvMjKyqqTiV9rTVZWFl5eXpU+hk3NO7VeaA8we8D+ZdBqiKOjEUJUQWhoKKmpqdh1eHct4uXlRWho\naKX3rxtJ38MHQmJkvL4QLsDd3Z2IiAhHh1Fr1Y3mHTCaeI5Iu74Qom5zmaSffiqPyTM3sSX1RNkb\nRMSBLoGDf9ZsYEII4URcJul7u5tZuCONd5cklb1BaHejXV+Gbgoh6jCXSfr1vdwZ19vCb9vT2JNW\nRskFd28j8Uu7vhCiDnOZpA8wvk8E3u5m3l+6t+wNLHFwZDPknazZwIQQwkm4VNL39/VgTGw4P20+\nTMqxMsr2W/oa7foHpF1fCFE3uVTSB5gQ1wKTgg+XlXG3H9odzJ7Sri+EqLNcLuk39fNiRLdQZiak\nkp6dd/5Kdy8I6yHt+kKIOsvlkj7Avf1aUlRcwicr9l+80tIXjm6BM5cY2imEEC7MJZO+JdCX66OC\n+Xr1AU7kFlywsq+M1xdC1FkumfQB7h/QktyCYj5flXz+ipAYa7u+NPEIIeoel036bZs24Ip2TZi2\nMpnT+UV/rTjbrr9/meOCE0IIB3HZpA/wwMCWnDxTyLdrDpy/whIHR7fCmeOOCUwIIRzEpZN+dHgj\nercM4OPl+8krLP5rhaUvoGW8vhCiznHppA/w4MBIMk7lM3t96l8LQ2PAzUvG6wsh6hyXT/q9WgbQ\nJawhH8Tvpai4xFjo5mkdry9JXwhRt7h80ldKMXFgJKnHz/DzlsN/rbDEwdFtkHvMccEJIUQNc/mk\nDzC4bWPaNKnPe0v2UlJinVfTEofRrr/KobEJIURNqhNJ32RSPDCwJXvST/P7jjRjYUg0uHnLeH0h\nRJ1SJ5I+wLWdmtE8wIf3liahtS7Vri9JXwhRd9SZpO9mNnFf/5ZsST3JiqRMY2FEHKRtlXZ9IUSd\nUWeSPsBN0SE0aeD515SKljjjvwdWOi4oIYSoQXUq6Xu6mZkQ14LV+46x/sAxCI4Gdx9p4hFC1Bl1\nKukDjIkNp5GPO+8u2QtuHhAWC/tlvL4Qom6oc0nfx8ONO/tEsHhXOtsPnzRKMqRvh5wsR4cmhBDV\nrs4lfYA7elmo5+lmTKAu7fpCiDqkTiZ9Px93buvZnF+2HmGfR2tp1xdC1Bk2JX2l1FCl1G6lVJJS\namoZ68cppTKUUpusP3eXWheulPpdKbVTKbVDKWWxX/iVd1ffCDzMJj5ckQLhPaUOjxCiTig36Sul\nzMC7wNVAe2C0Uqp9GZt+p7XuYv35pNTyL4H/aq3bAT2AdDvEXWVB9T35W/cw5mxMJbtJT0jfATmZ\njg5LCCGqlS13+j2AJK31Pq11ATADuMGWg1s/HNy01gsBtNantda5lY7Wzu7p1wKtYWZmc2OBtOsL\nIVycLUk/BEgp9TrVuuxCNyultiilZiulwqzLWgMnlFJzlFIblVL/tX5zOI9S6h6lVIJSKiEjI6PC\nF1FZoY18GN41hDd2+qLdfWTophDC5dmrI/dnwKK17gwsBL6wLncD4oApQHegBTDuwp211h9prWO0\n1jFBQUF2Csk29/VvSU6RiWSfztKZK4RwebYk/UNAWKnXodZl52its7TW+daXnwDdrL+nApusTUNF\nwI9AdNVCtq/IxvW4umNTfjrRAjJ2wuma+6YhhBA1zZakvw5opZSKUEp5AKOAuaU3UEo1K/VyGLCz\n1L4NlVJnb98HATuqFrL9PTAgkqUFbY0XB+Ru3xZf/pnM9LUHHR2GEKKC3MrbQGtdpJR6EPgNMAOf\naa23K6WeBRK01nOBSUqpYUARcAxrE47WulgpNQVYpJRSwHrg4+q5lMrrGOJHQKvu5Bz0wnPvctw6\n3OjokJxaUXEJr/62m4LiEq5s34SAep6ODkkIYaNykz6A1no+MP+CZf8q9fvjwOOX2Hch0LkKMdaI\n+wa1Zd2nbYjavYRGjg7GyW1OPUl2XhEA01YmM+WqNg6OSAhhqzr5RG5Zulv8SfWLoVHOPgpOHHV0\nOE4tPjEDk4K+kYF88Wcy2XmFjg5JCGEjSfqltOt9NQAJ8T87OBLnFp+YQZewhky9ui2n8or46s8D\njg5JCGEjSfqlRMcOIFd5k7F1EcVnJ1AX5zmWU8CW1BP0b92YjiF+DGgTxGcr9nOmoNjRoQkhbCBJ\nvxRldud0kx50KNjM/K1HHB2OU1q+JwOtoV/rQAAmDowkK6eA79bJSB4hagNJ+hcI7DiYSNNhvl20\nzphAXZwnPjGDhj7udA5tCBh9IT0s/ny0bB8FRSUOjk4IUR5J+hcwRfQFICBzHUt2O0VtOKdRUqJZ\nlphJXKsgzCZ1bvkDA1ty+GQeP246dJm9hRDOQJL+hZpGoT3rc4X3bt5ZnCR3+6XsOJJN5ul8+rc+\nv1RG/9ZBdAxpwPtL90pfiBBOTpL+hcxuqPDeDPRKZMPBE6zZf8zRETmNZXuMEhX9WgWet1wpxcQB\nkezPzGHBNukLEcKZSdIvi6UvfjnJtPHN5d0lSY6OxmnE786gfbMGNG7gddG6qzo0pWWQL+8u2Svf\njoRwYpL0yxJhzJs7pU0Gy/dksjnlhIMDcrxTeYWsP3Cc/m3KroJqMinuHxDJziPZLN0tReuEcFaS\n9MvStDN4NqC/x04aeLnx3lInvds/tAHe6Azb5lT7qVbtzaKoRF/Unl/aDV2CCWnozTtLpC9ECGcl\nSb8sJjM0741HyirG9bbw2/Y09qSdcnRU5ys8Az/cCycOwJwJsHtBtZ4uPjGDep5uRIdfujKRu9nE\nvf1bsP7AcekLEcJJSdK/FEtfyEpifJQ33u5m3l+619ERnW/Rc5CZCH/72vhmMvMO2LukWk6ltSZ+\ndwa9Wgbg4Xb5P5lbYsIIrOcpfSFCOClJ+pdiMdr1G6Wt4dbYcH7afJiDWU4yvW/yClj9HnSfAO2u\nh9u+h8DWMGMMHPjT7qfbm5HDoRNnLtu0c5aXu5m74yJYvieTLanSFyKEs5GkfylNO4GnHyQv5+64\nFpiV4sNlTnC3n38Kfrwf/CNgyDPGMh9/uP0HaBAC395itPXbUXyi0TFrS9IHuDU23OgLWeIE/7+E\nEOeRpH8p1nZ9klfQ1M+Lm7uFMishlfTsPMfG9duTcDIVhn8AHr5/La/XGO74Cbwbwtc3Qdp2u51y\nWWIGLYJ8CfP3sWn7+l7ujOtt4dftR52vL0SIOk6S/uVExMGxvZB9mPv6t6CopIRPVux3XDx7FsKG\nL6D3JAiPvXi9XwjcMRfcvOHL4ZBZ9Xb1vMJiVu/Lsvku/6xxfSKcsy9EiDpOkv7lWIw6PCSvoHmA\nL9dHBfP16gOcyC2o+Vhyj8FPD0Lj9jDwiUtv5x9h3PHrEvhyGByvWq37NfuPkV9UUuGk7+/rwRhr\nX0jKMSfpCxFCSNK/rCYdwcto1wdjAvXcgmKmrUyu+VgW/BNyM+HGD8CtnDlpg1rDHT9CQY6R+LMr\nXxohfncGnm4merYIqPC+E5ypL0QIAUjSvzyTGZr3hf1G0m/TtD5D2jfh81XJnM4vqrk4tv8IW2dB\n/8egWZRt+zTtBLfNgZxM+PIG47+VEJ+YTmyLALzczRXe92xfyExn6AsRQgCS9Mtn6QvH9xudp8AD\nA1py8kwh366poSkCT6fDvEcgOBr6Tq7YvqHdYMxMOHEQvhoOZ45XaPeUY7nszci5qMBaRdzXvwVF\nxSV86si+ECHEOZL0y3OuXX8lAF3DG9EnMoCPl+8nr7CapwjUGn5+yGimufEDMLtV/BiWPjDqa8jY\nDd+MNIZ82uhsVc0Bl6i3YwuH94UIIc4jSb88TTqCV0NIXnZu0cQBkWScymf2+tTqPffm6bB7Plzx\nNAS1qfxxIq+AEdOM8fvTRxslHGwQvzuDkIbetAyqV/lzY/SF5BQU8/mq5CodRwhRdZL0y2MyGXf7\nySvOLerVMoCu4Q35IH4vRcXVNEXgiRRY8Bg07wOx91f9eO2ug5s+Mq7ju9ugKP+ymxcWl7Bqbxb9\nWgehlLrstuU52xcybWUN94UIIS4iSd8Wlr5wPNlIxPw1aUjq8TPM3XzY/ucrKYGfJhrDLoe/Z3zw\n2EOnETDsLUj6A76/C4ovnYA3HDjO6fyiCg/VvJSzfSHT18gE6kI4kiR9W1jr8JS+2x/UtjFtm9bn\nvaV7KbH3FIEJn8L+eLjqBWhkse+xo++AoS/Bzp+Ncg4lZX9TiU/MwM2k6B1Z8aGaZfmrL2Rf9feF\nCCEuSZK+LRq3B+9G5yV9Y9KQliSln+b3HWn2O1fWXvj9KYgcAtFj7Xfc0nreD4Oegq0z4ZdHjA7j\nC8QnZhDdvBENvNztdtqJAyJJr4m+ECHEJUnSt4XJZLStWx/SOuu6zsFYAnx4b6mdJg0pKYYf7jMe\nvhr2NlSxLf2y+k2BuEdh/efw2xPnJf70U3lsP5xtt6ads3q1DKBLWDX3hQghLkuSvq0i+hkTlpz4\nq03abFLc178lW1JPsiKpcg8/nWfVW5C6Fq55FRo0q/rxyjPoKYi9zyjTvOTFc4uXJxrXYu+kr5Ti\nwYFGX8jPW6qhL0QIUS5J+rYqVYentBujQ2jawKvqZYTTthuJt/0NRodrTVAKrvoPdL0dlr0CK/4H\nGE07gfU8aN+sgd1Pea4vZEk19IUIIcolSd9WQe3A2/+ipO/pZmZsbwt/7ssiKf105Y5dVGBMfejl\nB9e+Xr3NOhcymeD6N6HjCPjj35Ss/pDlezLo1yoIk8n+cZztC9lj774QIYRNbEr6SqmhSqndSqkk\npdTUMtaPU0plKKU2WX/uLrWuuNTyufYMvkaZTMbTrRe06wOMjAnF3ayYsbaSwxGX/ReOboXr3wLf\nypc8qDST2Xjit821mH79J1fkL6R/FZ7CLc+1nZrR3J59IUIIm5Wb9JVSZuBd4GqgPTBaKdW+jE2/\n01p3sf58Umr5mVLLh9knbAex9DPa9C8oVxxYz5Mh7Zvw/YbUig9HPLQelr8GXW6FttfYMdgKMrvD\nyGkcaNiTl90+ZlDRxR9u9uJmNtm3L0QIYTNb7vR7AEla631a6wJgBnBD9YblpC7Rrg8wukc4x3ML\n+W37UduPV3jGGK1TvxkM/Y+dgqwCN0+mejzGTvf21J8/EXbNr7ZT3WTtC5EJ1IWoWbYk/RAgpdTr\nVOuyC92slNqilJqtlAortdxLKZWglFqtlBpe1gmUUvdYt0nIyMiwPfqaFtQWfALKTPp9WgYS5u/N\n9Io08Sx6DjIT4YZ3jPZ8BzuZW8ialDMsiX7bKOE8ayzsXVwt5/J0MzOhXwtW7zvG+gPHquUcQoiL\n2asj92fAorXuDCwEvii1rrnWOgYYA7yhlGp54c5a64+01jFa65igoOprS66yc3V4ll/0QJPJpBjV\nPZzV+46xL8OGDt3kFcZQye4ToOXAagq4YlYkZVKioVeHCLh1NgS2hulj4MCqajnf6B5hNPJx512Z\nQF2IGmNL0j8ElL5zD7UuO0drnaW1PlvB6xOgW6l1h6z/3QcsBbpWIV7Hs8TByRRjzP4FRsaE4mZS\nfLcupYwdS8k/ZZRA8I+AIc9UU6AVF5+YTgMvN6JCG4KPP9z+I/iFwje3GH0Pdubj4cadfSJYvCud\n7YdP2v34QoiL2ZL01wGtlFIRSikPYBRw3igcpVTpJ4mGATutyxsppTytvwcCfYAd9gjcYS7Trt+4\nvhdXtGvCrPWp5BddpkP3tyeNSVmGfwAevtUUaMVorYlPzKBvq0DczNY/i3pBMHau8QHw1U1wdJvd\nz3tHLwv1PN1kAnUhaki5SV9rXQQ8CPyGkcxnaq23K6WeVUqdHY0zSSm1XSm1GZgEjLMubwckWJcv\nAV7SWtfupB/UFnwCz02heKFRPcI4llPAwkuNQd+zEDZ8Ab0nQXhsNQZaMYlpp0nLzr/4KdwGwUbi\nd/cxZt/K3GPX8/r5uHNbz+b8svWIbc1iQogqsalNX2s9X2vdWmvdUmv9gnXZv7TWc62/P6617qC1\njtJaD9Ra77IuX6W17mRd3klr/Wn1XUoNUeqv+vpljDGPaxVESMNLdOjmHoOfHjQKuA18ogaCtV18\nYjoA/coqvdDIAnf8ZFzvF8OMMtN2dFffCDzMJj6M32fX4wohLiZP5FaGpS9kp5aZ/MwmxajuYaxM\nyuJAVs75Kxf8E3IzjQeh3DxrJlYbxSdm0KZJfZr5eZe9QVBrI/EX5hqJP9t+tXOC6nsyqnsYczam\ncviEbbN6CSEqR5J+ZUT0M/5bxtO5ACNjwjCbFDNKd+hu/xG2zoL+U43hkE4kJ7+IdfuPl/8UbtOO\ncNscyM2CL2+A0/YbXjuhXwu0ho+Wyd2+ENVJkn5lBLYG36AyO3MBmvp5MahtY2YlpFBQVAKn0mDe\nIxAcDX0fqeFgy7d6XxYFxSW2VdUM7QZjZhqziM0YY5SDtoPQRj4M7xrCjHUHyTx9+akchRCVJ0m/\nMspp1wcY0yOczNMFLNpxFOY9bDSL3PghmN1qONjyxSdm4O1uJsbSyLYdLH2Mev+pa2Hlm3aL4/4B\nLckvKmHayv12O6YQ4nyS9CvLEgfZh+BY2c0R/VoHEeznRcrST2H3fBj8L6Nd3AnFJ2bQu2UAnm5m\n23fqNMIoA73kRaMstB20DKrHNR2b8eWqA2TnFdrlmEKI80nSr6wy5s0tzWxS3NXJnVFZ75IX0gti\n76/B4GyXnJnDgazcilfVVMooA+3dEObca5SHtoP7B7TkVH4RX/158cNvQoiqk6RfWYGtoF6TSyZ9\nSkq4Le0VTGi+avxPo4SDE1q2x+iM7deqEuUvfAONctBpW41JWOygY4gfA9oE8emK/ZwpkAnUhbA3\n58xEtUF57foJn+KZspzvA+/n420lFDrpnLDxuzNoHuCDJbCSTwa3vQaixsDy1yHVPqUaJg6M5FhO\nATPWVXJ+AiHEJUnSrwpLXzh1+OJ2/ay98PtTEDmEkEH3kX4qn8W70h0T42XkFxWzam9W1efCvfol\nozz0D/ca5aKrqLvFnx4Wfz5ats8Y/SSEsBtJ+lVxrl2/1Hj9kmKjRr6bJwx7mwFtG9OkgWfFSi7X\nkITk45wpLK560vfyM8pDZ+2BRc/aJbaJgyI5cjKPHzceKn9jIYTNJOlXRUDkxe36q94yhjJe+xo0\naIab2cTfYsKIT8wg9Xiu42ItQ3xiBh5mEz1bBFT9YC0HGmWiV793ybpEFdGvVSAdQxrwfvxeimUC\ndSHsRpJ+VShl3O3vt9bXT9tuDGFsfwN0vPncZrd0NypTz0xIdVSkZYrfnUH3iEb4etrp2YEhz4B/\nC/jxAaN8dBUopZg4IJL9mTnM33rEPvEJISTpV5mlL5w+Cuk7jTZtLz+49n/GB4JVaCMf+rcOYua6\nFIqcpEP3yMkz7E47VfWmndI8fI1y0dmp8FvVC8pd1aEpLYN8eXeJTKAuhL1I0q+qs+36s8bB0a3G\nEEbfi5tLRvcI52h2Hkt3O8d0kMsSjTj6t25s3wOHxxplozd8CYm/V+lQJpPi/gGR7Dp6iiW7na8j\nXIjaSJJ+VQW0NEauZO6GLrcaQxjLMKhtYxrXd54O3WWJmTRt4EXrJvXsf/CBTxjlo+f+3SgnXQU3\ndAkmpKE37yyWu/26ZH9mjsymVk0k6VeVUtDqSmgYDkP/c8nN3M0mRsaEsmR3usPLBxcVl7B8Twb9\nWgeiSjVD2Y2bp1E+OjcT5v+jSodyN5u4r38LNhw8wep9MoG6Kysu0Szckcbtn65h4KtLufHdVSSm\nVa1vSFxMkr49XPsaPLDaaM+/jFHdwynRMDOhnDl0q9nm1BNk5xXZv2mntGZR0P8x2DYbtv9QpUON\njAkjsJ4n7y1NslNwwpkcyyng/aV76ffKEiZ8mcCetNNMGtyKel5uTJ65yWkfbKytJOnbg9ndprlu\nw/x9iGsVyMx1KQ4dhhi/OwOTgr6RgdV7or6TjXLS8yYb5aUrycvdzN1xESzfk8nmlBN2DFA40uaU\nE0yeuYme/1nEy7/uIszfm/dvjWb5YwOZPKQ1L97YkW2Hsnl3iXzY25Mk/Ro2pkc4h0/mnetIdYT4\nxAy6hjfCz8e9ek9kdjOaeQpy4OdJlyxDbYtbY8Np4OUmd/u1XF5hMbPXp3LDOyu44d2V/LbtKH+L\nCeP3R/ox455eXN2pGe5mIy0N7diM4V2CeWdxEltTpX3fXiTp17Ar2jchsJ4n3zqoQzfrdD5bDp20\n71DNywlqA1c8DYm/wqZvKn2Y+l7ujOtt4bftaeyRdt5aJ+VYLi8t2EWv/yxiyqzNnM4v4plhHVj9\nxGCeG96R1k3ql7nfM8M6EljPk8kzN5FXKAX47EGSfg1zN5sY0S2UxbvSOXoyr8bPvyIpE62puaQP\nRlnp5n1hwVQ4UfkPu/F9IvDxMPPe0r12DE5Ul5ISzbLEDO7+Yh39/ruEj5btJTYigG/vjuWPyf0Z\n29tCfa/Lf9v083Hn5RGd2ZN+mtcXJtZQ5K5Nkr4DjOoeRnGJZpYDOnTjd2fg7+tBp5DLdzrblckE\nw98FNPw0EUoq1zHXyNeDMT3Cmbv5MCnHnKukhfjLyTOFfLpiP4Nfj+eOz9ayKeUEEwdEsuKxQXxw\nezd6R1bvbcvAAAAgAElEQVRs1Fj/1kGMiQ3n4+X7WLtfRnBVlSR9B7AE+tInMoAZ61IoqcEO3ZIS\nzbI9mcS1CsRkqoahmpfTyAJXvQD7l8G6Typ9mLviIgD48s9ku4Ql7GfnkWwen7OVni8u4rl5O2jk\n486bo7qwcuogplzVhuCG3pU+9pPXtCO0kTdTZm0mJ7/IjlHXPZL0HWR0j3AOnTjD8qTMGjvnjiPZ\nZJ7Or9yEKfYQPRYih8DCf0Fm5Tpkm/l5M7RjU2asS5F//E6goKiEuZsPM/KDVVz95nJ+2JjKsKhg\n5v29L3Me6MMNXUIqNg3nJfh6uvHayC6kHM/lxfk77RB53SVJ30GubN+UAF8Ppq+puQ7deOuIobjW\n1TxU81KUMiZUd/OEH+8zylBXwp19LJzKK2LOBucqYFeXHD2Zx+sLE+nz8mImTd9IWnY+T17TjtWP\nD+blEZ3pWA3Nhz0i/Lm7bwTfrDl47m9ZVJwkfQfxcDM6dP/YmUZ6ds106MYnZtAhuAGN63vVyPnK\n1KAZXPMqpK6DlW9W6hDR4Y3oHOrHtFXJNdo8VtdprVm9L4sHvllPn5cX8/biPXQK8WPa+O4snTKA\nCf1a0NDHo1pjePTKNkQ2rsdjs7dwMrewWs/lqiTpO9DfuodRVKKZtb7671iz8wrZcOB4zY7auZRO\nI4zy00tehKPbKry7UorxfSzsy8g5N8evqD45+UV8tfoAV72xjFEfrWZlUhZ39Y0gfspAPhvXnYFt\nGtdYH5GXu5nXb4ki43Q+//55e42c09VI0negFkH16NnCnxnrDlb7HeuqpCyKSrRzJH2ljPLT3g2N\nWcaKCip8iGs7BRNU35NpK5PtH58AjI7/lxbsoueLi3jqx214uJl4ZURn1jwxmCeuaUd4gI9D4uoc\n2pAHB0byw8ZD/LrNTnMtFBcZNyAbvoTf/69KT5A7OzvNniEqa3SPcB6asYlVe7Po26r62trjEzOo\n5+lGdPNG1XaOCvENMMpQzxgN8S/D4KcqtLuHm4nbezbn9YWJJKWfJrJxNVQLreO++DOZD+L3cm2n\nZtwVF0HXsIbVU6CvEh4cFMmiXWk8+cM2Yiz+BNbztH1nreF4MhzeAIesP0c2QWGpYcA5mcbT5C5I\n7vQd7KoOTWnk416tJZe1Nh6S6RMZcO4Rd6fQ9hqjHPWK1yE1ocK7j4kNx8Ns4vNV+6shuLptb8Zp\nXlqwiwFtgnhnTFeiwxs5TcIH4yHH12/pwqm8Ip6Ys/XyZbdPZ0Dib0Zz4tcj4JUW8FYXmH2nMXy4\npMgYWXbTx/D3DdDrQdg8A9J21NwF1SC503cwL3czN0eH8vmqZDJO5RNUvwJ3LDbam5HDoRNnmDgw\n0u7HrrKh/4F98UYzz33Lwd32sdyB9TwZ1iWY79cf4h9Xtq3+WkJ1RFFxCY/O3IyXu5mXb+7sVMm+\ntNZN6vPola35z4Jd/LDxEDdFh0L+aeOu/dD6v+7iT1pvqJQJgtpB22shJBpCuhnzPpgv+LuJe9Ro\n5ln8PIz+tuYvrJrZdNunlBqqlNqtlEpSSk0tY/04pVSGUmqT9efuC9Y3UEqlKqXesVfgrmRUj3CK\nSjTfV9MQxLPD2/o5aqjm5Xj5wQ3vQNYeWPRshXcf38fCmcJivktwjslpXMGHy/axKeUEz97QgSYN\nHDjSqzxFBdzdMpsnglah5k6k8O0e8FIYfH6t8SzI4Y0Q2g2ufB7GL4CpKfDAKuPvLeZOo/z3hQkf\nwMcf+kyC3b9Aytqav65qVu6dvlLKDLwLDAFSgXVKqbla6wu/+3yntX7wEod5DlhWpUhdWGTjevSw\n+DNj7UHuiWth95EQ8YkZtAzyJbSRYzreytVyIHSfAKvfgzbXQESczbt2CPajR4Q/X6w6wJ19InBz\npuarWmjH4Wze+CORazo1ZVhUsKPD+UtJCRzba717X2+0xx/Zgrk4n3uAY7o+23PaEdXvn6jQGAju\nCr5VuMmJvR/WfAR/PAPj5p0353VtZ0vzTg8gSWu9D0ApNQO4AbCpwUsp1Q1oAvwKxFQyTpc3OjaM\nR77bzOp9WfS2Y537vMJi1uzL4tbY5nY7ZrUY8gzsXQQ/PmDcjXmWXXWxLHf2sXDf1xv4Y2caQzs2\nq8YgXVt+UTGTZ27Cz9uD54d3QpUUQcbu8zs4a9Lp9L8S/KGNkG8tr+zuC8FdIPYeY76GkG78skvz\n1E/bec67I7e3ssPfumc96PcPWPAP4+8y8oqqH9NJ2JL0Q4DSlcFSgdgytrtZKdUPSAQe0VqnKKVM\nwGvAbcAl/68ppe4B7gEIDw+3MXTXcnXHZvx77g6mr0uxa9JfvS+L/KIS+rdxgqGal+PhC8M/gGlD\n4bcnjCd3bTSkfVNCGnrz2cpkSfqVVVLCV/MW0SZ9CR91OI3/9Jfg6FYoqvlKsOcxuUGTDtDxJqMN\nPqSbUa7bdH5ph9t6an7fkcaLv+ykX6tAmgeUP6lRubqNgz/fNu72WwwyCge6AHt15P4MTNda5yul\n7gW+AAYBDwDztdapl+sM0lp/BHwEEBMTUycfsfRyN3NTdAjfrD5I1ul8AioyBO0y4hMz8HQzERvh\nb5fjVavwWOg9CVa+AW2vg9ZX2bSb2aQY27s5L87fxfbDJ+kQXIMVRGurU0etnZ1Gh2dR6nruLsgG\nDyDZB5p1ge53G80k3g0dE6OnHzTtaFPnvlKKV0Z05sr/LePRmZv57t5emKvaTOrmAQP/D364B3b8\nAB1vrtrxnIQtSf8QEFbqdah12Tla66xSLz8BXrH+3guIU0o9ANQDPJRSp7XWF3UGC2PM/rSVyczZ\ncIgJ/VrY5ZjxiRn0bBGAl3vVi17ViIFPwJ7fYe7fjXmHfWz7sPpbTDj/W7iHaSuTeXVkVDUHWcvk\nnTQ6NUuPaDl12FinzJQ07sCCkl5sdWvJpDtGUS+kgzHrWS3TzM+bZ4Z1YPLMzXyyfB/39m9Z9YN2\nGmGUC1n8PLQbVnbHby1jyzu7DmillIrASPajgDGlN1BKNdNan300bhiwE0BrfWupbcYBMZLwL611\nk/p0a96I6WsPcndcRJWHyqUcy2VfRg63OXt7fmlunsZDMR8PgvlTYMRnNu3m5+POzd1CmLkulalX\nt63YwzqupDAP0rb91eF5aL0xMuos/xZg6WM0kwRHQ7POPLtgH58fSOabu2OpF+6EI7wq4MauIfy6\n7Siv/Z7IwLaNLzkjl81MZuPBwemjYONXxqifWq7cpK+1LlJKPQj8BpiBz7TW25VSzwIJWuu5wCSl\n1DCgCDgGjKvGmF3a6B7hTJm1mTX7j9GzRUCVjnW2Lo3Tt+dfqFkU9J8KS543mnk63mTTbuN6R/D1\n6oN8u+Ygkwa3quYgnUBJMWTu+Su5H95glBIosRYiq9fESO5RfzMSfHDXi745rdqbyeerkhnbqzl9\n7NiX5ChKKV68qRNX/W8Zk2du4ocH+lT9gcTWQyEsFuJfgc6jwMNJR8HZSF32STYHiImJ0QkJFX86\n01WcKSimx4t/MLhtY94Y1bVKx7rnywS2H85mxWMDnfYBm0sqLoJPhxiPyz+wGuo3sWm3Oz5by84j\n2ax8bBAebq7R8QYYpQNOppYazbLBaLIpOG2s96gPIV3PjWYhpBs0CL7sUMNTeYUMfWM57mbF/Ifi\n8PGofU06l/LrtiPc9/UGHhrcikeGtK76AQ+sgmlXwxXPQN+Hq368aqCUWq+1LneEpOu8yy7C28PM\nTV1DmL4uhadzCmjkW7lStQVFJazam8WwLsG1L+GD0aZ844fwYRz8PAlGz7BprPT4PhbGT1vH/K1H\nGN41pAYCrWbpO2Htx7DzZ8hJN5aZPaBJR4gabU3w0RDQqsKjS56ft5MjJ88w677eLpXwAYZ2bMaN\nXUN4Z0kSg9s1pnNoFTujm/eGVlcaJUO6jQVvJ6lhVQkudCvkOkbHhlNQVMKcjYfK3/gSNhw8zun8\nIueoqllZQa1h8L8g8VfY9I1Nu/RvFUSLIF8+W7n/8vVYnFlxIWz/EaZdC+/1hI1fg6WvMQ/BhMXw\neCrcswSufRW6jLYOYazYP+XFu9L4LiGFe/u3pJuzFOGzs39f34Ggep5MnrmZvMLKTdhznkFPGZ3i\nK9+q+rEcSJK+E2rbtAFdwxsyfe3BSieu+MQM3EyK3i2r1i/gcLH3Q/O+sGAqnCi/1ILJpBjf28KW\n1JNsOHi8BgK0o1NpRrvxG51g1ljjeq/4N0zeCSOnQY8Jxp29W9U6qY/nFPDY91tp27Q+D1/hun0f\nfj7uvDyiM0npp3nt991VP2CzztBxBKz5wBjyWktJ0ndSo7uHk5R+moQDlUtc8bsz6Na8EfW9avkQ\nM5MJhr8LaPhpovE4fjluig6lvpcbn9WGWvtaw4E/jYqP/+sAS16Axu1g1HR4aBP0fcQoQ21HT/20\njeM5Bbx2S5Rd5q91Zv1bB3FrbDifrNjPmn1Z5e9QnoFPQHEBLPtv1Y/lIJL0ndR1Uc2o5+lWqTl0\n07Pz2HEku/aN2rmURha46gXYvwzWfVzu5r6ebozqHsav245y+MSZ6o+vMgpyYP3n8EGc8RTynj+M\nh6EeXA+3/2CUnTbZPyH/vPkw87Yc4aHBrerMQ2xPXNOOsEY+TJm9mZz8oqodLKClUYZ5/edwbJ9d\n4qtpkvSdlI+HG8O7BvPL1iMVngt02Z5MgNrdnn+h6LEQOQQWPg2ZSeVufkcvC1prvlp9oAaCq4Cs\nvfDrE/BaO/j5IUDDdW/Aozvh6pcgsPrKX6dn5/HUT9uICvXj/gF2eHCplvD1dOPVkVGkHj/DC/N3\nVv2A/f8JJnejPn8tJEnfiY3uEU5+UQk/bKxYyeVliRkE1fekfbMG1RSZAyhl1ONx84Q5E4wa/Hkn\nL7l5mL8PQ9o3Yfrag5wpsEMnXlWUFMPuBfDVTfB2NKz9ECIHG+V+71sBMeON2kPVSGvN1DlbOVNQ\nzGu3dKlz1Uh7RPgzIa4F3645yNLd6VU7WP2m0PM+2DrLqE9Uy9Std76W6RDsR1SoH9PXptjcoVtc\nolm+J4N+rYJq51DNy2nQDK5/A45shi+HwUvh8E53mHOvUQY3dT0U5Z/bfHyfCE7kFvLjpsqPgqqS\n3GOw4g1jlqbpoyBtOwx4Ah7ZbnTMNu9dYyV7ZyWksnhXOv8c2rbOTi05eUhrWjWux2Pfb6nwt+eL\n9HnImAti0XP2Ca4GudbgXBc0ukc4U+dsZcPBEzYNrdt66CTHcwudc8IUe+hwI0T0t9aS2WA8qLR3\nMWyZYaw3uRtFukK6ERvclasaK75YkcSo7mE19yF4aIMxtn7b91Ccb4w+GvKs8XSxA2q3pBzL5dl5\nO4iN8Gd8b0uNn99ZeLmbef2WLgx/byVPz91WtYcfvRsZnex//Nt4cKt5b7vFWd0k6Tu566OCeW7e\nDqavPWhT0o/fnYFSENfKhdrzL+TjbzSPRA42XmsN2YfOn2Bj83eodZ/wIXBae5H9QRR+kT3/emLV\nL9S+d9mFebD9B6Oj+dB6o+Z711uNyWGatLffeSqopETzz9lb0Frz6sgou0/QU9t0CvXjwYGRvLlo\nD1d1aMrVnapQirvHvbD6A6P08p2/1pqJViTpOzlfTzeGdQnhh42p/Ov69jQoZwhmfGI6nUMb4l/J\nJ3lrJaWMJO4XCu2HGctKSiBrDwUHE/hl3lx6HN+P3+r3jeF2AL6N/5onNSTa+DCwsaLneU4chITP\njDlVc7OMJ2OvfgWiRhlf/x3siz+T+XNfFi/d1Ikw/9pdM8ZeHhwUyaJdaTz54zZiLP6Vn5faw8fo\n1P1lsjHxepuh9g20mkjSrwXG9Ahn+tqD/LTxELf3slxyuxO5BWxKOcGDg1z3gRubmUwQ1AaPoDak\nZsUwdUkSSx7uhaVo/1/lhQ+tN/6xYu0vaRRR6oOgGzTtXHZxrZIS2LcE1n1iPC0MxjSPPSYYTU9O\ncse3N+M0Ly3YxYA2Qfyte1j5O9QR7mYTr9/SheveXsGTP2zlw9u7Vb7pL/oOWPW2Mb9zqytrxUQr\nkvRrgU6hfnQMacA3aw5yW8/ml/wDXZGUSYl2saGadnBbz+a8v3Qvn685wr+HWRP6WXnZcGTTX7Xm\nD64x2uIBlBkatzcKmZ39EEhZYyT7rCTwCTTadbuNh4bOlVSLikt4dOZmvNzNvHxzZ9fr1K+i1k3q\nM+XK1rw4fxdzNhzi5m6hlTuQ2R0G/R98fxdsmw2db7FvoNVAkn4tMbpHOE/+sI3NqSfpElZ28aj4\n3Rn4ebsTFer4ZgVn0qSBF9d1bsbs9ak8emXr859S9moAEf2Mn7NOpVkrWVo/CHbMNZpvzgrtDjd+\nBB2GV7kkQnX5cNk+NqWc4M1RXWjSwMvR4Tilu/q2YOGONP49dzu9WgYQ3LD8GbrK1OEmY7a3xc9D\n++HGjFtOzPm/iwgAhkUF4+1uvuQTulprlu3JoG+rwDo3BtsW4/tEcDq/iFkJNjzzUL8JtLnauIO7\nfQ48lgx/3wAjpsE98XD3H0aNeidN+DsOZ/PGH4lc26kZw6KCHR2O0zKbFK+OjKJY/9XZXSkmEwx+\nGk4cgA1f2DfIaiDZoZao7+XOsKhg5m4+zKm8i8cY7047RVp2vjTtXEJUWEOiwxvyxZ/JFJdU8B+3\nUsbj9x1vguAu1RKfveQXFTN55ib8vD14bnhHadYpR/MAX564ph0rkjL5uipPb0deAc37GAXzCnLs\nF2A1kKRfi4yODedMYTFzNx++aF38bmOWrH6uPFSzisb3ieBAVi5LdlXxiUwn9taiPew6eoqXbupU\nt0ZwVcGtseHEtQrkxfm7SM6sZMJWyrjbz0mH1e/bN0A7k6Rfi0SF+tGuWQOmr724iSc+MYO2TevT\n1E/aby9laMemNG3gxbRV+x0dSrXYcPA47y/dy8huoVzR3raZxoQxxeIrIzrjZlZMmbW54t8EzwqP\nNUZxrXzTeBrbSUnSr0WUUozpEca2Q9lsTf2r7kxOfhHrko9J00453M0mbu/VnJVJWew+esrR4djV\nmYJipszcTDM/b5663nEPg9VWzfy8efaGDiQcOM7Hy6tQPXPQU5B/Clb8z37B2Zkk/Vrmhq4heLmb\n+LbU3f6fe7MoLNaS9G0wpkc4nm4mPnexu/2Xf93FvswcXhnRudwH+ETZhncJ4aoOTXj990QW7Uyr\n3EGatIfOf4O1H0H2xc2wzkCSfi3TwMud6zoHM3fToXO1weMTM/DxMNPN4prT3tlTI18PbuwawpwN\nhzieU+DocOxi1d5MPl+VzNhezekT6aI1l2qAUooXbuxE8wAf7voigYnfbiD9VF7FDzTwcaOyavzL\n9g/SDiTp10Kje4STU1DMz9YO3fjEDHq3DHD5WZDsZVwfC/lFJUxfV/EJapzNqbxC/jFrCxGBvky9\nup2jw6n1Aut5Mm9SXyYPac3C7WkMfi2eb9YcoKQi7fyNLBBzJ2z4yqa5H2qaJP1aKDq8IW2a1Gf6\n2oMkZ+Zw8FiuNO1UQNumDejdMoCv/jxAYXH50y86s+fm7eDIyTO8OjIKbw/50LcHTzczkwa34teH\n4+gQ3IAnf9jGyA//JDGtAv1A/aaAmxcseb76Aq0kSfq1kFKK0T3C2Jx6kveWGncS/Vs3dnBUtcv4\nPhEcOZnHb9tr7wTXi3amMTMhlXv7t7SpAquomBZB9Zg+oSf/HdGZvRmnufat5bz6227yCm2YlKde\nY+j1gFF59fDG6g+2AiTp11I3dg3F083EzIRUIgJ9CQ+QCooVMahtY8L9ffhsRe3s0D2eU8DUOVtp\n27Q+D18hBfaqi1KKkTFhLJrcn+s7B/POkiSGvrGMlUmZ5e/c++9G3f1Fz1Z/oBUgSb+W8vNx51pr\nLfB+raTzrqLMJsW43hY2HDzB5pQTjg6nwp76aRsncgt47ZYo6cupAQH1PHn9b134+q5YNHDrJ2uY\n/N0msk7nX3onLz+Ie9SY5Gf/shqLtTyS9Gux23o1x6Tgqg5NHR1KrTQyJpR6nm5MW1m77vZ/3nyY\neVuO8NDgVnQIluJ6Nalvq0B+e7gfDw6MZO7mw1zxejyzEi4znWn3u6FBiDHRSmVr+9iZJP1aLDq8\nERueGkJvGaZXKfW93BnRLZRfth4hPbsSQ/McID07j6d+2kZUWEPu69/S0eHUSV7uZqZc1Yb5D8XR\nIqge/5i9hTEfr2FfxumLN3b3hv6PwaEE2PVLzQdbBkn6tVxDH6mvUhXjelsoKtFVK7ZVQ7TWTJ2z\nlTMFxbw2MkqqqTpY6yb1mXVvL164sSPbDp9k6JvLeWvRHvKLLujo7XIrBETC4ueM8fsOJn81ok6z\nBPoyqE1jvllz0LZRGQ40KyGVxbvS+efQtkQ2rufocARgMilujW3Oosn9GdK+Ca8vTOTat1awdn+p\n2jtmN6M8Q8Yu2PKd44K1kqQv6rzxfSLIyik497CbM0o5lsuz83bQs4U/43tbHB2OuEDjBl68Oyaa\naeO6c6agmFs+/JPH52zhZK61DHr7G6BZF1jyIhRdpvO3BtiU9JVSQ5VSu5VSSUqpqWWsH6eUylBK\nbbL+3G1d3lwptcG6bLtS6j57X4AQVdUnMoDWTeoxbWVy5SfSqEYlJZp/zN6M1pr/jojCZJIa+c5q\nYNvGLJzcjwlxEcxMSGXw60v5adMhYxbmK56GkymQ8JlDYyw36SulzMC7wNVAe2C0UqqsMn7faa27\nWH8+sS47AvTSWncBYoGpSimZykc4FaUU43pHsONI9vlfy53AidwCpszezOp9x3jquvaE+cvzGM7O\nx8ONJ69tz08T+xDc0JuHZmxi7LR1pDSMNablXPZfoxKng9hyp98DSNJa79NaFwAzgBtsObjWukBr\nffa7jKeN5xOixt3YNYSGPu5MW5ns6FAAo9P2x42HGPxaPD9tOszEgS35W3fnmnxdXF7HED9+eKAP\nT1/fnvXJxxjyxjLm+N8NuVnw57sOi8uWJBwCpJR6nWpddqGblVJblFKzlVLn/jqVUmFKqS3WY7ys\ntb6o4VQpdY9SKkEplZCRkVHBSxCi6rw9zIzqHs7vO46ScizXobEcyMrhjs/W8vB3mwj19+HnB/vy\nj6vaytSHtZDZpBjfJ4KFk/sT1yqIySvdWOHei+KVb0OODU/1VgN73Xn/DFi01p2BhcC52YG11inW\n5ZHAWKXURVP6aK0/0lrHaK1jgoKkcJhwjDt6NUcpxZd/Jjvk/IXFJby3NIkr/7eMjQdP8MywDsy5\nvzftgxs4JB5hP8ENvfn4jhg+uK0bbzMKCnJY9fkTZc53Xd1sSfqHgNLfK0Oty87RWmeVasb5BOh2\n4UGsd/jbgLjKhSpE9Qpu6M3QDk2ZsS7l3FwFNWXDweNc//YKXvl1NwPaBPHH5P6M7W3BLJ22LmVo\nx6Z88uitbA64hm7p33Pra7P5dVvNFv2zJemvA1oppSKUUh7AKGBu6Q2UUs1KvRwG7LQuD1VKeVt/\nbwT0BXbbI3AhqsP4PhZO5RUxZ0NqjZwvO6+Qp37cxs3vr+LkmUI+ur0bH94eI3Mdu7D6Xu5E3/Ey\n7mYTE9Vs7vt6PRO+TODwiTM1cv5yk77Wugh4EPgNI5nP1FpvV0o9q5QaZt1sknVI5mZgEjDOurwd\nsMa6PB54VWu91d4XIYS9dGveiM6hfkxblVyxiTMqSGvNgq1HuOK1eL5ec4CxvSwsnNyfK6WOUt3Q\nMAxTjwlcWbiYl/p5sHxPBkNej+ezFfur9e8OQDnbuOSYmBidkJDg6DBEHfbDxlQe+W4zn4/vzoA2\n9p+n4NCJMzz90zb+2JlO+2YN+M9NnYgKa2j38wgnl5MJb3aBlgNIGfIRT/64DbOCz8Z1r1SnvVJq\nvdY6przt3CoVrBAu7NpOwbw4fxfTVibbNekXFZfwxZ8HeO333WgNT17TjvF9LFJDp67yDYTeD8LS\n/xDWZydfjO9ObkFxtY/Skr82IS7g4WbittjmxCdmkJReRuXESth26CTD31vJc/N2EBvhz++P9GNC\nvxaS8Ou6XhPBJwD+eBoF+HpW/324/MUJUYYxseF4mE18sSq5SsfJyS/iuXk7GPbOCtKy83lnTFc+\nG9ddnqwVBs/60O8fkLwc9i2pkVNK0heiDEH1Pbk+KpjvN6Ry8kzlxlIv2pnGlf9bxqcr9jOqRzh/\nTO7PdZ2D5SErcb6YO8EvrMYmWpGkL8QljO9jIbegmJnrUsrfuJS07Dwe+GY9d32RgI+Hmdn39eLF\nGzvh5+1eTZGKWs3NEwY8Dkc2wY6fqv10kvSFuISOIX70sPjzxZ/JFNswjK6kRPPV6gNc8Vo8f+xM\nZ8qVrfllUhwxFv/qD1bUblGjIKgtLP1Ptd/ty+gdIS5jfB8L93+zgYU70hja8dJj6HcfPcXjc7aw\n4eAJ+kQG8MLwTlgCfWswUlGrmcww7B1jMvVqbv6TpC/EZQxp34SQht58tnJ/mUk/r7CYtxbt4aNl\n+2jg7c7rt0RxY9cQabcXFRfWvUZOI0lfiMtwM5u4o1dz/rNgF9sPn6RDsN+5dcv3ZPDkD9s4eCyX\nEd1CeeKadvj7ypzFwrlJm74Q5RjVPRxvd/O5WvuZp/N5eMZGbv90LWaT4tsJsbw6MkoSvqgV5E5f\niHL4+bhzc7cQZq5LpX2zBry1eA85+UVMGhTJAwMj8XI3OzpEIWwmd/pC2GBc7wgKikt4dt4OWjWu\nx/xJcUy+so0kfFHryJ2+EDaIbFyPp65rT30vN0ZEh8rk5KLWkqQvhI3u6hvh6BCEqDJp3hFCiDpE\nkr4QQtQhkvSFEKIOkaQvhBB1iCR9IYSoQyTpCyFEHSJJXwgh6hBJ+kIIUYcoXQPTc1WEUioDOODo\nOCohEMh0dBA1TK65bpBrrh2aa62DytvI6ZJ+baWUStBaxzg6jpok11w3yDW7FmneEUKIOkSSvhBC\n1CGS9O3nI0cH4AByzXWDXLMLkTZ9IYSoQ+ROXwgh6hBJ+jZQSoUppZYopXYopbYrpR6yLvdXSi1U\nShXcAocAAAOoSURBVO2x/reRdblSSr2llEpSSm1RSkU79goqTyllVkptVErNs76OUEqtsV7bd0op\nD+tyT+vrJOt6iyPjriylVEOl1Gyl1C6l1E6lVC9Xf5+VUo9Y/663KaWmK6W8XO19Vkp9ppRKV0pt\nK7Wswu+rUmqsdfs9SqmxjriWqpKkb5si4FGtdXugJzBRKdUemAos0lq3AhZZXwNcDbSy/twDvF/z\nIdvNQ8DOUq9fBv6ntY4EjgN3WZffBRy3Lv+fdbva6E3gV611WyAK49pd9n1WSoUAk4AYrXVHwAyM\nwvXe58+BoRcsq9D7qpTyB54GYoEewNNnPyhqFa21/FTwB/gJGALsBppZlzUDdlt//xAYXWr7c9vV\nph8gFOMfwyBgHqAwHlhxs67vBfxm/f03oJf1dzfrdsrR11DB6/UD9l8Ytyu/z0AIkAL4W9+3ecBV\nrvg+AxZgW2XfV2A08GGp5edtV1t+5E6/gqxfZ7sCa4AmWusj1lVHgSbW38/+Qzor1bqstnkD+CdQ\nYn0dAJzQWhdZX5e+rnPXbF1/0rp9bRIBZADTrE1anyilfHHh91lrfQh4FTgIHMF439bj2u/zWRV9\nX2v9+w3SvFMhSql6wPfAw1rr7NLrtPHR7zJDoZRS1wHpWuv1jo6lBrkB0cD7WuuuQA5/feUHXPJ9\nbgTcgPGBFwz4cnEziMtztff1ciTp20gp5Y6R8L/RWs+xLk5TSjWzrm8GpFuXHwLCSu0eal1Wm/QB\nhimlkoEZGE08bwINlVJu1m1KX9e5a7au9wOyajJgO0gFUrXWa6yvZ2N8CLjy+3wFsF9rnaG1LgTm\nYLz3rvw+n1XR99UV3m9J+rZQSingU2Cn1vr1UqvmAmd78MditPWfXX6HdRRAT+Bkqa+RtYLW+nGt\ndajW2oLRsbdYa30rsAQYYd3swms++/9ihHX7WnXnpLU+CqQopdpYFw0GduDC7zNGs05PpZSP9e/8\n7DW77PtcSkXf19+AK5VSjazfkK60LqtdHN2pUBt+gL4YX/22AJusP9dgtGUuAvYAfwD+1u0V8C6w\nF9iKMTLC4ddRhesfAMyz/t4CWAskAbMAT+tyL+vrJOv6Fo6Ou5LX2gVIsL7XPwKNXP19Bp4BdgHb\ngK8AT1d7n4HpGH0WhRjf6O6qzPsK3Gm99iT4//btmAYAGASAYK3i30Q9sDD8XYIAlh9IeHO912Z8\n5AKEOO8AhIg+QIjoA4SIPkCI6AOEiD5AiOgDhIg+QMgHXevxej2wcOUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6eac9e1828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m, c = list(zip(*binary))\n",
    "r = range(100, 1200, 100)\n",
    "plt.plot(r, m, label='MI')\n",
    "plt.plot(r, c, label=r'chi^2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VNXdx/HPyb5CyMKWhQQS9t2wuiAoCoqAgi1YK2Cr\ntY8UrLV1rT5urVpLa5/axVpBWwUVVFZF3BVQCIuEJUgCgWyQkI2ErJM5zx93AkMMySSZzPp7v155\nZebOuZPfzcB3Ts6ce4/SWiOEEMI7+Di7ACGEEI4joS+EEF5EQl8IIbyIhL4QQngRCX0hhPAiEvpC\nCOFFJPSFEMKLSOgLIYQXkdAXQggv4ufsApqKjo7WiYmJzi5DCCHcyq5du05rrWNaa+dyoZ+YmEha\nWpqzyxBCCLeilDpuSzsZ3hFCCC8ioS+EEF5EQl8IIbyIy43pN6e+vp7c3FxqamqcXYrTBAUFERcX\nh7+/v7NLEUK4MbcI/dzcXMLDw0lMTEQp5exyHE5rTXFxMbm5uSQlJTm7HCGEG3OL4Z2amhqioqK8\nMvABlFJERUV59V86Qgj7cIvQB7w28Bt5+/ELIezDLYZ3hBDCo53Jh4yNEBoDQ2Z36o9ym56+syml\nuPXWW8/dN5lMxMTEMGPGDABWrFjB4sWLnVWeEMLdFGfBV3+Gf10FywbBpvso3b2m03+s9PRtFBoa\nyv79+6muriY4OJgtW7YQGxvr7LKEEO5CaziZDhkb4NB6KDwIQHGXwWwMvo1Xy4YRbxrJik4uQ0K/\nDa677jo2btzI3LlzWblyJfPnz+fLL790dllCCFdlNkPuDiPkD62HsuOgfKjsMYZPey/hhdz+ZBZG\nMqBHOLfdkMDskZ3fkXS70H98/QEO5p+x63MO7t2Fx24Y0mq7efPm8cQTTzBjxgz27dvH7bffLqEv\nhLiQqQ6yvzR69BkbofIU+PhjSppEWuxC/pKXwrZsH4L8fbhheG+eG5fAqPgIh03WcLvQd6bhw4eT\nnZ3NypUrue6665xdjhDCVdRVQdbHRm/+uw+gphz8Q9EpUznefQrLT6Xw1v4zVNc3MLBnOE/OSmDm\nyFi6Bjv+ZEu3C31beuSdaebMmdx333189tlnFBcXO7UWIYQTVZfBd5vh0DrI/BhM1RDcDQbOoKrf\ndN4rT+E/u4o4tPsMwf5nuGFEL+aPTWCkA3v1zXG70He222+/nYiICIYNG8Znn33m7HKEEI5Uccoy\nbLMBjn0BZhOE94ZRt6IHzWCPzxBW7sxnw1sFVNdnMbhXF56cPZRZI3vTJcg1LqEiod9GcXFxLFmy\nxNllCOHRtNaAi5yUWHLMMuNmA+R8A2iI7AsTFsOgGyiPHMZ7ewtYue4EGSd3EBLgy6yRvZk/NoHh\ncV1d4xisqMZfrqtITU3VTRdROXToEIMGDXJSRa5Dfg/C05gazJwoqSKzsJKsorNkFlaSWVTJ0cJK\nGrSmX0wYyd2NL+N2KH2iQvH37cRTjLSGwkPnZ9ycSje29xwGg2bCwBnomIHszinjjW9y2JieT029\nmaGxXZg/NoGZI3oT7oRevVJql9Y6tbV20tMXQnS66roGsooqySqqtAS88T37dBV1DeZz7Xp0CaRf\nTBg3jo7FRymyiir5+mgx7+7JO9fGz0fRJyrE6o3g/JtCaGA7I63sBBzfDie2GcM2JUcBBfHj4Jqn\nYdAM6JZIeVU97+zJZeUbX/LdqUpCA3y5cVQct4xNYFhc1w7+lhxDQl8IYTelZ+vItAR641dWUSV5\nZdU0Dir4KOgTFUq/mDCmDOxBv5hQI7S7h1103Luy1sTRJs+bWVjJx4cKMZnPj1b07hpEvyZvBsnd\nw4gKDTg/zKI1FB02Av74djixHcpzjMcCu0DCeJj4CxhwPYT3QGtN2vFSVn64l43pBdSazAyP68rv\nbxrGDSN6E9beNxonca9qhRBOZzZr8surzw/HFFaSZRmWKTlbd65dkL8PfaPDGJ3QjR+kxp/rjSdG\nhxDo59umnxkW6MfwuAiGx0VcsL3OZOZEiVUdlpreSsuhqq4BAF8aGBeUyzVhR0lVGSTXpBNUXwaA\nDuuBSphghHzCBOgxBHyM2sqq6ljz1TFW7jhBZmElYYF+zL0kjvljExga6x69+uZI6AshmlVnMnO8\n+Oy5oZjG8faswrNU1zecaxcR4k9yTBjXDO5xrseeHBNGbEQwPj6d+yFmgJ8Pyd3DSe4efn5jfTXm\nnJ1UHvmShmNbCSvajX9DNVRCDj1ZbxrODj2QHeaBnDT1oq9/OMkNYfSrCCK56BRhgX68tyePTftP\nUmcyMyI+gmfnDGPG8N7tHz5yIe5/BEKIDqmsNRk9daux9syiSk4UV10wdBIbEUy/7mGMGRtpDJtY\nhlCiwgKdWD3GfPmcb+D4VmO4Jn8PPuZ6uqCMnvvoW6HPREiYQHyXXoSdrSOpqJJLrN7I9pwoZcO+\n/HNDUOGBfvwwNZ55Y+MZ0tt9e/XNkdAXwgtorTldWWfVWz8f8AXl5xfn8fNRJEaH0r97ONcN7UW/\n7qEkx4TTNybUdXq5ZwouHI8/dQDQ4OMPvUfBhLuNkI8fa5ws1US30ABSQyNJTYy8YHt1XQNHT1dS\nWFHLuKRIQgJc5HjtzDOPykEWLlzIjBkzmDt37gXb8/PzWbJkCatXrz63raCggMsvv5wuXbrw+eef\nEx5u/DlaVVXFzTffTFZWFr6+vtxwww0888wzDj0O4TkazJq80moyiyqafJh6lvLq+nPtQgN86dc9\njAl9o4zhGMt4e5+okM6dDtlWWhszaY5vMwL++FYozTYe8w81gn3yQ8Z4fOwlEBDS7h8VHODLkN5d\nce45/53PptBXSk0DXgB8gZe11s80eXwh8AegcV7VX7XWL1seWwA8Ytn+lNb6VTvU7dJ69+59QeBX\nVFQwe/Zsnn32WXJzc5k7dy4bNmw4t8j5fffdx+TJk6mrq+Oqq67i/fffZ/r06c4qX7iBmvoGjp1u\nMt5eWMmx02epNZ2fAhkdFkC/mDBmDO91wWyWnl2CXO6kIcwNRqCfPgKnD0PebiPoK08ZjwdHGj34\nMXdAnwnQcwT4Sr+1rVr9jSmlfIEXgalALrBTKbVOa32wSdM3tdaLm+wbCTwGpAIa2GXZt9Qu1TvY\na6+9xvPPP49SiuHDh+Pr68sXX3zBsmXLOHnyJM899xxz584lOzubGTNmsH//furr65k/fz73338/\nN910EwB+fn7ccccdrFixgpCQECZPngxAQEAAo0ePJjc315mHKVxMUUUtn2YUXjDenlNSReNwu1IQ\n3y2EfjGhXJ4SfcG89YiQAOcW35z6aijONKZNNgZ80XfGtoba8+26xkPSJCPgEyZCzADjYEWH2PI2\nORbI1FofBVBKrQJmAU1DvznXAlu01iWWfbcA04CV7SsXeP8BYyECe+o5DKa3PKRy4MABnnrqKbZt\n20Z0dDQlJSXce++9FBQU8NVXX5GRkcHMmTO/N9Tj7+/Phg0bLth29913N/szysrKWL9+PUuXLu3Y\n8QiPseXgKX779g5qqyup9utCYnQ4Q3t3ZdbI2HMfpvaNCSXIv21TIB2iutQI89OHLwz40uMYfUAA\nBd36QPQASJ5ifI8ZANEpzY7Hi46zJfRjgRyr+7nAuGbazVFKXQF8B/xSa51zkX3dcrmpTz75hJtv\nvpno6GgAIiOND4Fmz56Nj48PgwcP5tSpU+1+fpPJxPz581myZAl9+/a1S83CDWgNVSXGyUHlOVCe\nC2U5NJQep+BEJqOq8vlanYEg0ChUbTcoiYLaaCiOguOREBINIVEQavkeYrUtILRze8daG+u7NvbW\nrb+fLTrfzjfQCPLeo2D4PIjpbwR8VDL4B3VefeJ77DUgth5YqbWuVUr9DHgVmGLrzkqpO4E7ARIS\nElpu3EqP3NECA89PV+vIdYzuvPNOUlJSuOeee+xRlnAVDSaoyD8X5pSfsLqdawR9fdUFu5j9gsgz\nR5Nd343wnpOJGDIUv6BwVFUJVBWf/yo5Cjk7jNu6ofmf7xf0/TeC5t4cGrcFRzY/Tt5Qb1x47HST\nYD99BOoqz7cL6mqEef9rIdoS7DH9IaLPuZOehHPZEvp5QLzV/TjOf2ALgNba+sLyLwPPWe17ZZN9\nP2v6A7TWLwEvgXHBNRtqcrgpU6Zw4403cu+99xIVFUVJSYndnvuRRx6hvLycl19+2W7PKRyktvJ8\neJfnWML8fI+dinzQ5gv3CYmGrnFGGCZfZYxdd41Dd43njcOaxz8+SdeQAJbNH8GolJjWa9DaWLSj\n8c3g7GmrN4fTxl8SjdtKs43vtS2sPhcUcf6NIDDcOI6So2A+P/uH8N5G/SN/ZOm1WwI+rLuMu7s4\nW0J/J5CilErCCPF5wC3WDZRSvbTWBZa7M4FDltubgd8ppRoH564BHuxw1U4wZMgQHn74YSZNmoSv\nry+jRo2yy/Pm5uby9NNPM3DgQEaPHg3A4sWL+elPf2qX5xd20mCCb1fCqf1WwZ5jjFtb8/GDLr2h\nawIkXgYRRqAbwW653cy0wqKKWu57+1s+/66Iqwd159k5w20/6UkpCI4wvqL62baPqQ6qrd4MGt8c\nLnjTOG0M0UQlw8Drzvfao1IgqIttP0e4nFZDX2ttUkotxghwX+AVrfUBpdQTQJrWeh2wRCk1EzAB\nJcBCy74lSqknMd44AJ5o/FDXHS1YsIAFCxZc9PHKSuPP3MTERPbv32/Tc8bFxXVoWEg4wOkj8O5d\nkJcGAWFGeEfEQ1yq5XbC+WAP79nmYYxPMwr59epvqagx8eSsIdw6vk/nT6f0CzBqDe/ZuT9HuByb\nxvS11puATU22PWp1+0Eu0oPXWr8CvNKBGoVwDrMZvvk7fPwE+AfDnH/D0Dl2G76oqW/gmfczWLEt\nm4E9w3njjvH07xHe+o5CdICc2SBEc0qOwdq7jTNA+0+DG16wa6/4u1MVLFm5h4yTFSycmMgD0we6\n5rRL4XHcJvS11q53BqEDyRCQg2gNaa/Ah781hmlm/Q1G3mK33r3Wmv9+fZynNh4iPMiP5QvHMHlg\nd7s8txC2cIvQDwoKori4mKioKK8Mfq01xcXFBAXJfOZOVZ4LaxfD0U+h72SY9VdjrN5OiitruX/N\nPj46VMik/jE8f/MIYsKdfIVK4XXcIvTj4uLIzc2lqKio9cYeKigoiLg4+wWQsKI17H0DPnjAuP7L\n9csg9Xa7Tj388kgR9771LeVV9Tw6YzALJyZ2+rXmhWiOW4S+v78/SUlJzi5DeKKKk7B+KXz3AfS5\nFGa9CJH2+7dWZzLz/IeHeemLo6R0D+PVRWMZ3FumOwrncYvQF8LutIb9a2DTfcYFwK79PYy7C3zs\nd1nhrKJKlqzcw4H8M9w6PoGHrxtMcIB8WCucS0JfeJ+zp2HjvXBwLcSmwo3/MK4LYydaa97cmcPj\n6w8S5O/Dv25LZergHnZ7fiE6QkJfeJdDG2DDPcYSe1c9BhOX2PWa7GVVdTywJp0PDpzksuRo/viD\nEfToIh/AC9choS+8Q3UpvH8/7HsTeg6H29Ya66fa0fasYn755l6Kz9by0HUD+ellfeXDWuFyJPSF\nW6msNbHjWDEJkaG2L+135CNYtxgqC2HSA3DFfeDrb7ea6hvM/GnLd/z98yySokJ5ecGlDI31rMW0\nheeQ0BduQ2vN0pV7+DijEDAW8e4TFXLBMoD9Yoyv0EA/qDkDHz4Mu1+DmIEwf6VxPXc7yj59lqWr\n9vBtbjnzxsTz6A2DPXZBbeEZ5F+ncBv//fo4H2cU8ospySRFh55bF/ZIYSUfHSqkwXz+rOUZ4Ud4\nzPw3ohsKOZi0iMqJv6Fflyii7HRmt9aaNbvzeGztfvx8ffj7j0YzfVivDj+vEJ1NQl+4hcMnK3hq\n4yGuHBDDvVP7fy+460xmjhefJbugkO47nmVE/pvk+/TilobH2X4oGQ7tASAixJ9ky18D1n8hxEYE\n2zz+Xl5dz8PvprNhXwHj+0ay7Acj6R0RbPdjFqIzSOgLl1dT38CSlXsID/LjD3NHNNtTD/DzIaX2\nIClf3GUs+DHuLnpf9Riv+wVTcKbm3F8FmYWVZBVV8tGhU7yZdn4lz0A/H/o2vhFYvvfrHkpSdCiB\nfufn1u/MLuGeVXs5daaGX187gLsm9cNXPqwVbkRCX7i8Z97P4PCpCpYvGtP8tWrqa+DTp2Hb/xnX\ntF+wHpKuAMAHiI0IJjYimEn9L1yFqvRsHZlFljeCwkoyiyrZc6KU9d/mn2vjoyAh0vjcoEuwP+/t\nySM+MoTVP5/IyPiIzjxsITqFhL5waZ9mFLJiWzaLLk1k8oBmrkaZtxve+zkUZcDoBXDt08YSfzbo\nFhrAmNBIxiRGXrC9uq6BrCLjL4LGN4PMwkpySqq5aXQc/ztzCGGB8l9HuCf5lytcVlFFLb9e/S0D\ne4Zz/7SBFz5oqoMv/gBf/hHCesCP1kDK1Xb5ucEBvgyN7fq9aZfefnlv4Rkk9IVLMps1971tLCH4\nxh3jL1xg5OR+eO8uOJkOw+fB9GcguNvFn8xOJPCFJ5DQFy5pxbZsPv+uiCdnDzWWEDQ3QPZXsO8t\n46za4AiY9wYMvN7ZpQrhViT0hcs5mH+GZ97P4OqB3bm1Tzl8+Aikr4GKfAgIN1ayuuoxCI1ydqlC\nuB0JfeFSqusaePKND1kS+Cl3Ve5C/fMQ+PhB8lTjQ9oB041FyoUQ7SKhL1xDdRkcXEvBp8t5vWIv\nPkpD8Di4/o8w+Ebp1QthJxL6wnlMtXBkizFG/91maKhFm3vxZfwdTJrzc4js6+wKhfA4EvrCscxm\nyPnaCPoD70FNGYTGcHb4bdy5ty/l0UN5Z9Fl4Ge/FayEEOdJ6AvHKMyA9Ldg39tQfgL8Q2DgDBj+\nQ8xJk7hzxS52m8rYMH80ARL4QnQaCX3ReSpOQvpqo1d/ch8oH+g3Ba76LQy4DgLDAPjX51lszSzm\nmZuG0S8mzMlFC+HZJPSFfdVWwKH1xnz6Y5+DNhvXsJ/2DAy5CcIvXCs2Pbec5z88zLQhPfnhmHgn\nFS2E95DQFx3XUA9Znxg9+oxNYKqGiD5w+X0w/AcXXXS8qs7E0lV7iAoN5Jk5w+SMVyEcQEJftI/W\nkLfLCPr9a6Cq2LgUwshbYPgPIX4stBLiT6w/yLHis7zx0/FEhAQ4qHAhvJtNoa+Umga8APgCL2ut\nn7lIuznAamCM1jpNKZUIHAIOW5p8rbW+q6NFCyeoLIKCvZC/1/iet9s4Q9Y30DhhavgPIflq8LMt\nvN9PL2DVzhz+58p+TOgnc/CFcJRWQ18p5Qu8CEwFcoGdSql1WuuDTdqFA0uBb5o8RZbWeqSd6hWO\nUFl4Ptwbv5/JO/94VDL0mQh9r4TBMyGobYuA55dV88A76YyI68ovp/a3a+lCiJbZ0tMfC2RqrY8C\nKKVWAbOAg03aPQk8C/zarhWKzlVx6sJwz99r9OABUOcDvtdI6D0Seg6HoC7t/nENZs0v39yLqcHM\nC/NG4e8r0zOFcCRbQj8WyLG6nwuMs26glBoNxGutNyqlmoZ+klJqD3AGeERr/WVHChYdUHHy+z34\nigLLg8r4wDXxMiPce42EnsM6FPDN+cfnWXxzrITnbx5BYnSoXZ9bCNG6Dn+Qq5TyAZYBC5t5uABI\n0FoXK6UuAd5TSg3RWp9p8hx3AncCJCQkdLQkAXCm4Ps9+MqTlgcVRPc3lhQ814MfZvOKU+2150Qp\ny7Z8x4zhvZgzOrZTf5YQonm2hH4eYD2BOs6yrVE4MBT4zDLlriewTik1U2udBtQCaK13KaWygP5A\nmvUP0Fq/BLwEkJqaqtt3KF5Ka6O33rQHX3nKeFz5GAHf98oLe/CBjj0JqrLWxNJVe+nZJYinb5Tp\nmUI4iy2hvxNIUUolYYT9POCWxge11uVAdON9pdRnwH2W2TsxQInWukEp1RdIAY7asX7vlpsGb912\n/kNW5QPRA4yzXq178AHOH0Z5bO0BckurePNnE+ga7O/scoTwWq2GvtbapJRaDGzGmLL5itb6gFLq\nCSBNa72uhd2vAJ5QStUDZuAurXWJPQr3eg31sHaxcXv6c5Ye/FCXCPim1u7NY83uXJZclfK9RciF\nEI5l05i+1noTsKnJtkcv0vZKq9trgDUdqE9czNd/g6JDMH+VMU/eReWUVPHIu/sZnRDBkinJzi5H\nCK8n8+XcUVkOfPYMDLjepQPf1GDml2/uBeCFeaPwk+mZQjidXIbBHX3wgPF9erMnRruMv36aSdrx\nUl6YN5L4yBBnlyOEQHr67ufwB5CxASb9BiJcd3prWnYJf/n4CDeNimXWSJmeKYSrkNB3J3VV8P6v\nIWYgjL/b2dVc1Jmaepau2ktctxAenzXE2eUIIazI8I47+fJ5KDsBCzfafGEzR9Na88i7+zl5poa3\n75pAeJBMzxTClUhP310UHYatf4ER841LJbiod/fkse7bfO65KoXRCd2cXY4QogkJfXegNWz8lTEH\nf+qTzq7moo4Xn+W37+1nbGIk/zNZpmcK4YpkeMcdpL8N2V/CjD9BWIyzq2lWfYOZpav24uuj+NO8\nkfj6yGUWhHBFEvqurroMNj8EsZfA6IXOruaiXvjoCHtzynjxltHERgQ7uxwhxEVI6Lu6T54yliK8\ndQ34uOZo3NdHi3nxs0x+kBrH9cN7ObscIUQLXDNFhCFvN+x8GcbeCb1GOLuaZpVX1fPLN/eSGBXK\nYzfI9EwhXJ309F2VuQE2/BLCusPkh5xdTbO01jz47j6KKmp5538mEhoo/5yEcHXyv9RVpb1iXBd/\nzr/bvAato7ydlsum9JM8MH0gw+MinF2OEMIGMrzjiipOwcdPGgufDJ3j7GqadbSoksfWHWBivyju\nvLyvs8sRQthIevqu6MNHwFQN1/0ROrjClNmsqa5vML7qGqix3K6qM77X1J2/X2NpY93e+nuN1X5F\nFbUE+vuw7Acj8ZHpmUK4DQl9V3P0c0h/C674DUS3fIJTbmkVz31wmNKquu8FdOPtWpO5zSX4+yqC\n/H0J9vclOODC7z27+BMU4MslCb7MG5tAz65B7T1SIYQTSOi7ElOtceZtt0S4/N4Wm2qt+fXb+9ib\nU8bAXuEE+/sSEeJ/0bAODvAlyN+XkMb7/r4EWW43bmu87y/XvRfCY0nou5Jt/wfFR+BHq8G/5ROc\n3tmdx/ajxTx941B+NK6PgwoUQrg76dK5itJs+OIPMGgmpExtsWnJ2Tqe2niQS/p0Y/4Y172mvhDC\n9UjouwKtYdNvwMcPprW+GtbTGw9RUWPidzcOkw9RhRBtIqHvCjI2wpHNcOWD0LXlVaa2ZZ1mze5c\nfjapLwN6hjuoQCGEp5DQd7baSnj/fug+BMb9rMWmNfUNPPzufvpEhfCLKSkOKlAI4Unkg1xn+/xZ\nOJMLc/8Nvi2vMvW3TzM5dvos//3JOIL8fR1UoBDCk0hP35lOHYSv/wajfgwJ41tsmllYwd8/z+LG\nUbFclhLtoAKFEJ5GQt9ZtIaN90JgF5j6RItNzWbNQ+/sJzTQj4evH+SgAoUQnkhC31n2vgEntsPU\nxyEkssWmb6XlsCO7hIemDyI6LNBBBQohPJGEvjNUlcCW30L8OBh5a4tNiypq+d2mQ4xNiuTm1DgH\nFSiE8FQS+s7w0f8ayyBev6zV1bCe2niQmnozv7txGKqDF18TQggJfUfL2Qm7X4XxP4eeQ1ts+sV3\nRazdm8/Pr+xHcvcwBxUohPBkNoW+UmqaUuqwUipTKfVAC+3mKKW0UirVatuDlv0OK6WutUfRbqvB\nZKyGFd4brrzorxGA6roGHnlvP32jQ/n5lf0cVKAQwtO1Ok9fKeULvAhMBXKBnUqpdVrrg03ahQNL\ngW+stg0G5gFDgN7AR0qp/lrrBvsdghvZ8RKcSocfvAaBLZ9N+5dPjnCipIqVd4yXOflCCLuxpac/\nFsjUWh/VWtcBq4BZzbR7EngWqLHaNgtYpbWu1VofAzItz+d9zuTDp09D8tXGRdVakHHyDP/64ig3\nXxLHhH5RDipQCOENbAn9WCDH6n6uZds5SqnRQLzWemNb9/Uamx8Cswmu+0OLq2EZc/LT6RLsz0PX\nyZx8IYR9dfiDXKWUD7AM+FUHnuNOpVSaUiqtqKiooyW5nsyP4cC7cPmvILLl9WRf33GC3SfKeOT6\nQXQLDXBQgUIIb2FL6OcB8Vb34yzbGoUDQ4HPlFLZwHhgneXD3Nb2BUBr/ZLWOlVrnRoTE9O2I3B1\n9TWw6T6I7AeXLm2xaeGZGp57P4NLk6O4cZR3/kEkhOhctoT+TiBFKZWklArA+GB2XeODWutyrXW0\n1jpRa50IfA3M1FqnWdrNU0oFKqWSgBRgh92PwpVt/TOUHIXr/wh+LZ9N+/j6g9Q2mHlqtszJF0J0\njlZn72itTUqpxcBmwBd4RWt9QCn1BJCmtV7Xwr4HlFJvAQcBE3C3V83cKc6CL5fB0DnQb3KLTT/J\nOMXG9ALuu6Y/SdGhDipQCOFtlNba2TVcIDU1VaelpTm7jI7TGv57k3Ey1i/SILznRZtW1ZmYuuwL\nQgJ82bjkcgL85Jw5IUTbKKV2aa1TW2sn19PvLAfehaxPYNqzLQY+wJ+2fEdeWTVv3zVBAl8I0akk\nYTpDzRn44EHoORzG/LTFpvvzynllazbzxyYwJrHlq20KIURHSU+/M3z2e6g8BfPeAN+L/4obzJqH\n3k2nW0gAD0wb6MAChRDeSnr69lawD775B6QugrhLWmz62vZs9uWW8+gNg+ka0vJSiUIIYQ8S+vZk\nNhurYQVHwlWPtti0oLya5zcf5or+MdwwvJeDChRCeDsZ3rGnPa9B7k6Y/Q8I7tZi08fWHqBBa56e\nPVTm5AshHEZ6+vZy9jRseQz6XAoj5rXYdPOBk3x48BT3XN2f+MgQBxUohBAS+vaz5VGoqzTOvG2h\n515Za+KxtQcY2DOcn1yW5MAChRBCQt8+jm+Dva/DhMXQveUrYz6/+TCnKmr4/U3D8PeVX78QwrEk\ndTqq7iysWwJd42HSb1ps+m1OGa9uz+bH4/swKqHlMX8hhOgM8kFuR236NRRnwm1rIeDi18wxNZh5\n8J10YsIhDpAwAAAQdElEQVQCue/aAQ4sUAghzpPQ74hv3zSGda74DfSd1GLT5VuzOVhwhr//aDRd\ngmROvhDCOWR4p71OZxqLnCdMhEn3t9g0t7SKZVu+46qB3Zk2tOXr8AghRGeS0G+P+hpYvdC4Pv6c\nl1u81ILWmkfXHkApeELm5AshnExCvz22/BZOpsPsv0PXlle42pR+kk8yCrl3an9iI4IdVKAQQjRP\nQr+tDq2HHS/B+LthwLQWm56pqed/1x9gaGwXFk5MdEx9QgjRAvkgty3KTsDau6HXSLj6sVabP/dB\nBsWVtbyyYAx+MidfCOECJIls1VAPq39iXFTt5uWtrne763gpr39zgoUTkxgW19VBRQohRMukp2+r\nT5+G3B0w598Q2bfFpvUNZh56J52eXYK495r+DipQCCFaJ6Fvi8yP4as/wejbYNjcVpv/68ujHD5V\nwb9uSyUsUH7FQgjXIcM7rak4Be/+DGIGGevdtuJEcRUvfHSEa4f0YOrgHg4oUAghbCfd0JaYG+Cd\nO6C2Ehash4CWL4Ostebh99Lx9/Xh8ZlDHVSkEELYTnr6LflqGRz7HKY/2+rVMwHWfZvPl0dO8+tr\nB9Cza5ADChRCiLaR0L+Y49vh09/B0DnGWH4ryqrqeHLDQUbER3Dr+D4OKFAIIdpOhneaU1UCa34C\nEX1gxp9bXBSl0TPvZ1BaVc9rtw/D10cutSCEcE0S+k1pbZyAVVkIP/kQgrq0usuOYyWs2pnDz67o\ny+DerbcXQghnkdBv6pt/wuFNcO3vIXZ0q8211jyx4QCxEcEsvTrFAQUKIUT7yZi+tfy9xsXU+k+H\n8T+3aZed2aXszzvD3ZOTCQmQ91AhhGuT0G9UWwGrF0FoDMz+m03j+ADLtx4jIsSfG0e1fLVNIYRw\nBTaFvlJqmlLqsFIqUyn1QDOP36WUSldK7VVKfaWUGmzZnqiUqrZs36uU+oe9D8AutDYWRCnNNq6P\nHxJp0255ZdVsPnCSeWMSCA7w7dwahRDCDlodj1BK+QIvAlOBXGCnUmqd1vqgVbM3tNb/sLSfCSwD\nGq87nKW1Hmnfsu1sz38h/W2Y/Aj0mWjzbq9tz0YpxY8nyBRNIYR7sKWnPxbI1Fof1VrXAauAWdYN\ntNZnrO6GAtp+JXaywgxjcfOkK+Dye23erarOxKodOVw7pIcsjiKEcBu2hH4skGN1P9ey7QJKqbuV\nUlnAc8ASq4eSlFJ7lFKfK6Uu71C19lZfbYzjB4TCTf8CH9uHaN7dk0d5dT2LLk3qxAKFEMK+7PZB\nrtb6Ra11P+B+4BHL5gIgQWs9CrgXeEMp9b2J7EqpO5VSaUqptKKiInuV1LoPHoDCg3DTPyHc9gXL\ntdas2JrN0NgupPbp1okFCiGEfdkS+nlAvNX9OMu2i1kFzAbQWtdqrYstt3cBWcD3LjCvtX5Ja52q\ntU6NiYmxtfaO2f8O7FoBl94DyVe3adetmcUcKaxk0cQkWehcCOFWbAn9nUCKUipJKRUAzAPWWTdQ\nSlmflXQ9cMSyPcbyQTBKqb5ACnDUHoV3SMkxWL8U4sbAlEdab9/E8q3HiA4LYMaIXp1QnBBCdJ5W\nZ+9orU1KqcXAZsAXeEVrfUAp9QSQprVeByxWSl0N1AOlwALL7lcATyil6gEzcJfWuqQzDsRmpjpj\nHF8pYxUsX/827Z59+iyfHC7kF1NSCPSTaZpCCPdi0ymkWutNwKYm2x61ur30IvutAdZ0pEC7+/hx\nyN8DP/gPdGv7VMsV27Lx81HcOj6hE4oTQojO5V1n5H63Gbb/Fcb8FAbPbPPuFTX1rN6Vy4zhveke\nLtfLF0K4H+8J/fI8ePcu6DEMrnm6XU+xelculbUmFk5MtG9tQgjhIN4R+g0mY9lDUy3cvBz8295L\nN5s1r27LZnRCBCPiIzqhSCGE6HzeEfpfPAfHt8L1f4To9l3++NPDhWQXV8nJWEIIt+b5oX/sC/j8\nORgxH0bOb/fTLN+aTc8uQUwbavtJXEII4Wo8O/TPnoY1d0BUMlz3fLuf5sipCr7KPM2PJ/TB39ez\nf2VCCM/muat+mM3GB7fVpXDraggMa/dTLd+WTaCfD/PHyjRNIYR789zQ3/5XyNxi9PB7Dmv305RV\n1fHO7lxmj4wlMjTAjgUKIYTjeeZYRW6acRLWoJnGnPwOWLUzh5p6M4suS7RPbUII4USeF/rVZcZl\nFsJ7w8z/s3nZw+aYGsz8Z/txJvSNYmDP710cVAgh3I5nhb7WsH4JnMmHua9AcMfm0285eIq8smoW\nXZpon/qEEMLJPCv0016Bg2thym8hfkyHn2751mziI4O5alAPOxQnhBDO5zmhf3I/fPAg9LsKJi5p\nvX0r9ueVsyO7hAUTEvH1kWvmCyE8g+eEfmgMDJ4FN/4TfDp+WCu2ZRMS4MvNqfGtNxZCCDfhOVM2\nw3vAnH/Z5alOV9aybm8+88bG0zW4bdfbF0IIV+Y5PX07euObE9Q1mFkgV9MUQngYCf0m6kxm/vP1\ncSb1j6FfTPvP4hVCCFckod/EpvQCiipqZZqmEMIjSeg3sXxbNn1jQrkiJcbZpQghhN1J6FvZfaKU\nb3PKWDQxER+ZpimE8EAS+laWb80mPMiPm0bHObsUIYToFBL6FifLa3g/vYAfpsYTGug5M1mFEMKa\nhL7Ff78+jllrmaYphPBoEvpATX0Db+w4wdWDehAfGeLscoQQotNI6APr9uZTcraOhTJNUwjh4bw+\n9LXWvLL1GAN7hjOhb5SzyxFCiE7l9aH/9dESMk5WsOjSRFQHFlwRQgh34PWhv2LbMbqF+DNrZKyz\nSxFCiE7n1aGfU1LFloOnuGVcAkH+vs4uRwghOp1Noa+UmqaUOqyUylRKPdDM43cppdKVUnuVUl8p\npQZbPfagZb/DSqlr7Vl8R722PRulFLeO7+PsUoQQwiFaDX2llC/wIjAdGAzMtw51ize01sO01iOB\n54Blln0HA/OAIcA04G+W53O6s7UmVu3MYfrQnvTqGuzscoQQwiFs6emPBTK11ke11nXAKmCWdQOt\n9Rmru6GAttyeBazSWtdqrY8BmZbnc7p39uRRUWNi0aVJzi5FCCEcxpbrDcQCOVb3c4FxTRsppe4G\n7gUCgClW+37dZN/vfWKqlLoTuBMgISHBlro7xGzWrNh6jBFxXRmdENHpP08IIVyF3T7I1Vq/qLXu\nB9wPPNLGfV/SWqdqrVNjYjr/ksZfZp4mq+gsC2WaphDCy9gS+nmA9ergcZZtF7MKmN3OfR1i+dZj\nxIQHcv2w3s4uRQghHMqW0N8JpCilkpRSARgfzK6zbqCUSrG6ez1wxHJ7HTBPKRWolEoCUoAdHS+7\n/bKKKvnscBG3jutDgJ9Xz1gVQnihVsf0tdYmpdRiYDPgC7yitT6glHoCSNNarwMWK6WuBuqBUmCB\nZd8DSqm3gIOACbhba93QScdik9e2ZRPg68Mt4zr/swMhhHA1Nl04Xmu9CdjUZNujVreXtrDv08DT\n7S3Qns7U1LN6Vy4zRvQiJjzQ2eUIIYTDedX4xls7czhb18DtMk1TCOGlvCb0G8yaV7dnMyaxG0Nj\nuzq7HCGEcAqvCf1PMgrJKamWk7GEEF7Na0J/+dZj9O4axDWDezi7FCGEcBqvCP2Mk2fYllXMjyck\n4ufrFYcshBDN8ooEXLE1myB/H+aPjW+9sRBCeDCPD/3Ss3W8uyePG0fFERES4OxyhBDCqTw+9Ffu\nPEGtycwiWfRcCCE8O/TrG8z8Z/txLk2Oon+PcGeXI4QQTufRob/5wEkKymtYNFGmaQohBHh46C/f\nmk2fqBCmDOzu7FKEEMIleGzo78stY9fxUhZMSMTHR66ZL4QQ4MGhv2JrNqEBvtycGufsUoQQwmV4\nZOgXVtSwfl8+N6fGEx7k7+xyhBDCZXhk6L/+9QlMZs2CiYnOLkUIIVyKx4V+ramB1785weQB3UmK\nDnV2OUII4VI8LvQ37ivgdGWtnIwlhBDN8KjQ11qzfGs2yd3DuCw52tnlCCGEy/Go0N91vJT0vHIW\nTkxEKZmmKYQQTXlU6C/fmk2XID9uGh3r7FKEEMIleUzo55dV88GBk8wfm0BIgE3rvQshhNfxmNCv\nqjNxeUo0P57Qx9mlCCGEy/KYLnFy93BWLBrr7DKEEMKleUxPXwghROsk9IUQwotI6AshhBeR0BdC\nCC8ioS+EEF5EQl8IIbyIhL4QQngRCX0hhPAiSmvt7BouoJQqAo47u452iAZOO7sIB5Nj9g7edszu\nerx9tNYxrTVyudB3V0qpNK11qrPrcCQ5Zu/gbcfs6ccrwztCCOFFJPSFEMKLSOjbz0vOLsAJ5Ji9\ng7cds0cfr4zpCyGEF5GevhBCeBEJfRsopeKVUp8qpQ4qpQ4opZZatkcqpbYopY5YvnezbFdKqb8o\npTKVUvuUUqOdewTtp5TyVUrtUUptsNxPUkp9Yzm2N5VSAZbtgZb7mZbHE51Zd3sppSKUUquVUhlK\nqUNKqQme/jorpX5p+Xe9Xym1UikV5Gmvs1LqFaVUoVJqv9W2Nr+uSqkFlvZHlFILnHEsHSWhbxsT\n8Cut9WBgPHC3Umow8ADwsdY6BfjYch9gOpBi+boT+LvjS7abpcAhq/vPAn/SWicDpcBPLNt/ApRa\ntv/J0s4dvQB8oLUeCIzAOHaPfZ2VUrHAEiBVaz0U8AXm4Xmv8wpgWpNtbXpdlVKRwGPAOGAs8Fjj\nG4Vb0VrLVxu/gLXAVOAw0MuyrRdw2HL7n8B8q/bn2rnTFxCH8Z9hCrABUBgnrfhZHp8AbLbc3gxM\nsNz2s7RTzj6GNh5vV+BY07o9+XUGYoEcINLyum0ArvXE1xlIBPa393UF5gP/tNp+QTt3+ZKefhtZ\n/pwdBXwD9NBaF1geOgn0sNxu/I/UKNeyzd38GfgNYLbcjwLKtNYmy33r4zp3zJbHyy3t3UkSUAQs\ntwxpvayUCsWDX2etdR7wPHACKMB43Xbh2a9zo7a+rm7/eoMM77SJUioMWAPco7U+Y/2YNt76PWYq\nlFJqBlCotd7l7FocyA8YDfxdaz0KOMv5P/kBj3yduwGzMN7wegOhfH8YxON52uvaEgl9Gyml/DEC\n/3Wt9TuWzaeUUr0sj/cCCi3b84B4q93jLNvcyaXATKVUNrAKY4jnBSBCKeVnaWN9XOeO2fJ4V6DY\nkQXbQS6Qq7X+xnJ/NcabgCe/zlcDx7TWRVrreuAdjNfek1/nRm19XT3h9ZbQt4VSSgH/Bg5prZdZ\nPbQOaPwEfwHGWH/j9tssswDGA+VWf0a6Ba31g1rrOK11IsYHe59orX8EfArMtTRresyNv4u5lvZu\n1XPSWp8EcpRSAyybrgIO4sGvM8awznilVIjl33njMXvs62ylra/rZuAapVQ3y19I11i2uRdnf6jg\nDl/AZRh/+u0D9lq+rsMYy/wYOAJ8BERa2ivgRSALSMeYGeH04+jA8V8JbLDc7gvsADKBt4FAy/Yg\ny/1My+N9nV13O491JJBmea3fA7p5+usMPA5kAPuB/wCBnvY6AysxPrOox/iL7ifteV2B2y3Hngks\ncvZxtedLzsgVQggvIsM7QgjhRST0hRDCi0joCyGEF5HQF0IILyKhL4QQXkRCXwghvIiEvhBCeBEJ\nfSGE8CL/D4qQ5+GcxzvMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6eacaa2da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m, c = list(zip(*gauss))\n",
    "r = range(100, 1200, 100)\n",
    "plt.plot(r, m, label='MI')\n",
    "plt.plot(r, c, label=r'chi^2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently Gaussian classifier does better and better with more data, while binary one worsens its performance, needing highly selective features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bparams['k'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bscore, pip = utils.feature_selection_pipeline(**bparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 0.57987220447284349, 'train': 0.56751199451679235}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.58626760563380287, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.test_score_one_vs_all(pip.predict(x_test), y_test, precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.96242774566473988,\n",
       " 0.0,\n",
       " 0.043478260869565216,\n",
       " 0.0,\n",
       " 0.23333333333333334,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.test_score_one_vs_all(pip.predict(x_test), y_test, recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I knew that there is a catch. Turns out that label imbalance is bigger problem than I've thought. While naive bayes has no way of battling this phenomenon, one might introduce sample weights into logistic regression - which is classifier I'm going to turn my attention into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How am I going to weight samples? One method is to use $w_i = \\frac{N}{K*n_i}$, where $N$ is number of samples, $K$ number of classes and $n_i$ number of samples with $i$ class. Another would be to split training in batches, uniformly filled with all of the classes. While the former is straighforward with sklearn - one has to switch one argument while defining estimator, latter will be a bit of a hassle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balance = len(x_train)/np.unique(y_train, return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 0.59287183002056199, 'recall': 0.14684190960877944, 'precision': 0.24206684362934361, 'test': 0.57827476038338654}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores, pip = utils.train_test_pipeline(TfidfVectorizer, LogisticRegression, data, at_least_threshold)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 0.70733379026730636, 'recall': 0.3028464059710918, 'precision': 0.35368114141662343, 'test': 0.60383386581469645}\n"
     ]
    }
   ],
   "source": [
    "scores, pip = utils.train_test_pipeline(TfidfVectorizer, LogisticRegression, data, at_least_threshold, \n",
    "                                        class_weight='balanced')\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 0.77107607950651136, 'recall': 0.32661768354373277, 'precision': 0.35387695505863009, 'test': 0.61661341853035145}\n",
      "{'train': 0.78821110349554491, 'recall': 0.33345959315251222, 'precision': 0.36422372145784043, 'test': 0.62140575079872207}\n",
      "{'train': 0.80123372172721041, 'recall': 0.33132086482881284, 'precision': 0.36155803465906311, 'test': 0.62140575079872207}\n",
      "{'train': 0.81631254283755994, 'recall': 0.33299658946649396, 'precision': 0.36986747229996975, 'test': 0.62140575079872207}\n",
      "{'train': 0.82179575051405074, 'recall': 0.33554536718412686, 'precision': 0.37148034507020555, 'test': 0.62140575079872207}\n",
      "{'train': 0.83755997258396164, 'recall': 0.3357627584884747, 'precision': 0.37161870806251446, 'test': 0.62140575079872207}\n",
      "{'train': 0.84372858122001371, 'recall': 0.3364431534788408, 'precision': 0.36956918951881984, 'test': 0.62140575079872207}\n"
     ]
    }
   ],
   "source": [
    "for c in range(3,10):\n",
    "    scores, pip = utils.train_test_pipeline(TfidfVectorizer, LogisticRegression, data, at_least_threshold, \n",
    "                                        class_weight='balanced', C=c)\n",
    "    \n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it seems that regularization constant around 7-8 is optimal choice. Default model was constrained too strongly. While overfitting is substantial, recall, precision and test accuracy raise along with train accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing worth checking is how logistic regression deals with truncated feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/utils.py'>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 0.65935572309801238, 'recall': 0.32422538381447652, 'precision': 0.32834114750233173, 'test': 0.59105431309904155}\n",
      "{'train': 0.70596298834818372, 'recall': 0.34698737223445064, 'precision': 0.34365979168889021, 'test': 0.597444089456869}\n",
      "{'train': 0.72858122001370806, 'recall': 0.33923583129193835, 'precision': 0.34913776049169309, 'test': 0.61341853035143767}\n",
      "{'train': 0.74640164496230299, 'recall': 0.32990712861110572, 'precision': 0.34045726928463993, 'test': 0.61341853035143767}\n",
      "{'train': 0.76148046607265252, 'recall': 0.33756842413053145, 'precision': 0.36000717662951709, 'test': 0.61661341853035145}\n",
      "{'train': 0.77793008910212469, 'recall': 0.32485766218158152, 'precision': 0.34249070751336425, 'test': 0.61022364217252401}\n",
      "{'train': 0.79369431117203559, 'recall': 0.32637625981917889, 'precision': 0.3563618046088754, 'test': 0.61501597444089462}\n",
      "{'train': 0.81151473612063052, 'recall': 0.33520638802430708, 'precision': 0.37205113621861691, 'test': 0.6230031948881789}\n",
      "{'train': 0.81631254283755994, 'recall': 0.3302924447902772, 'precision': 0.3633406629248116, 'test': 0.61341853035143767}\n",
      "{'train': 0.82590815627141878, 'recall': 0.33273704979991109, 'precision': 0.36582509961306686, 'test': 0.61821086261980829}\n",
      "{'train': 0.8307059629883482, 'recall': 0.33722109182180804, 'precision': 0.37080509252195865, 'test': 0.62140575079872207}\n"
     ]
    }
   ],
   "source": [
    "for k in range(100, 1200, 100):\n",
    "    \n",
    "    scores, pip = utils.feature_selection_pipeline(TfidfVectorizer, \n",
    "                                                   LogisticRegression, \n",
    "                                                   data, \n",
    "                                                   chi2, \n",
    "                                                   k=k, \n",
    "                                                   vocabulary=at_least_threshold, \n",
    "                                                   C=7.5,\n",
    "                                                   class_weight='balanced'\n",
    "                                                  )    \n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing more impressive than learning with all words in vocabulary. However, might be useful in terms of efficiency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't believe that I am capable of squeezing better score from logistic regression on top of tf-idf. Time to change vectorizer to something less obvious - word embeddings. I won't train them myself, however. I'm going to use vectors linked on course page - https://github.com/oxford-cs-deepnlp-2017/practical-2 . There is couple of versions, differing in vector dimension and, most likely, performance and accuracy. Let's start with 50-dimensional vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load_word2vec_format('../embeddings/vecs_50.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec, ind = utils.vectorize_docs(x_train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def take_subset_to_word2vec(data):\n",
    "    vec, ind = utils.vectorize_docs(data[0], model)\n",
    "    new_data = []\n",
    "    N = len(data[0])\n",
    "    for s in data[:2]:\n",
    "        \n",
    "        new_data.append([s[i] for i in range(N) if i in ind])\n",
    "    \n",
    "    vec, ind = utils.vectorize_docs(data[2], model)\n",
    "    N = len(data[2])\n",
    "    for s in data[2:]:\n",
    "        \n",
    "        new_data.append([s[i] for i in range(N) if i in ind])\n",
    "        \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trunc_data = take_subset_to_word2vec(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1455, 1455, 625, 625]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(len, trunc_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_x_train = utils.vectorize_docs(trunc_data[0], model)\n",
    "embed_x_test = utils.vectorize_docs(trunc_data[2], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_data = embed_x_train[0], trunc_data[1], embed_x_test[0], trunc_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/utils.py'>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 0.54089347079037797, 'recall': 0.125, 'precision': 0.069199999999999998, 'test': 0.55359999999999998}\n",
      "{'train': 0.54089347079037797, 'recall': 0.125, 'precision': 0.069199999999999998, 'test': 0.55359999999999998}\n",
      "{'train': 0.54089347079037797, 'recall': 0.125, 'precision': 0.069199999999999998, 'test': 0.55359999999999998}\n",
      "{'train': 0.54089347079037797, 'recall': 0.125, 'precision': 0.069199999999999998, 'test': 0.55359999999999998}\n",
      "{'train': 0.54089347079037797, 'recall': 0.125, 'precision': 0.069199999999999998, 'test': 0.55359999999999998}\n",
      "{'train': 0.55051546391752582, 'recall': 0.16158711316896701, 'precision': 0.25806715806715808, 'test': 0.55840000000000001}\n",
      "{'train': 0.57319587628865976, 'recall': 0.23093825409801247, 'precision': 0.33419951804918624, 'test': 0.58720000000000006}\n",
      "{'train': 0.58969072164948455, 'recall': 0.28978786901115738, 'precision': 0.33003454878454874, 'test': 0.59360000000000002}\n",
      "{'train': 0.59518900343642611, 'recall': 0.29197344922367807, 'precision': 0.31876114411580625, 'test': 0.58399999999999996}\n",
      "{'train': 0.59243986254295533, 'recall': 0.3147618477185759, 'precision': 0.32905021917466953, 'test': 0.58720000000000006}\n"
     ]
    }
   ],
   "source": [
    "for c in [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 4, 6, 8]:\n",
    "    \n",
    "    scores, pip = utils.uninformed_train_pipeline(LogisticRegression, embed_data, Normalizer, \n",
    "                                                  class_weight='balanced', C=c)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores, pip = utils.uninformed_train_pipeline(MLPClassifier, embed_data, Normalizer, hidden_layer_sizes=[500, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.22719599479784694,\n",
       " 'recall': 0.23448419001895052,\n",
       " 'test': 0.5846645367412141,\n",
       " 'train': 0.64305364511691887}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/utils.py'>"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_data = utils.prepare_data_to_rnn(data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-411-d873d14396f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbidirectional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, iters, batch, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstuff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets_ph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/models.py\u001b[0m in \u001b[0;36mbuild_rnn\u001b[0;34m(input_size, output_size, hidden, cell, bidirectional, time_major, max_length)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         )\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\u001b[0m in \u001b[0;36mstatic_rnn\u001b[0;34m(cell, inputs, initial_state, dtype, sequence_length, scope)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mcall_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcall_cell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             state_size=cell.state_size)\n\u001b[0m\u001b[1;32m    196\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_rnn_step\u001b[0;34m(time, sequence_length, min_sequence_length, max_sequence_length, zero_output, state, call_cell, state_size, skip_conditionals)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtime\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mempty_update\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# otherwise calculation is required: copy some or all of it through\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         _maybe_copy_some_through)\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_output_and_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_zero_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, fn1, fn2, name)\u001b[0m\n\u001b[1;32m   1764\u001b[0m     \u001b[0mcontext_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCondContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m     \u001b[0mcontext_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildCondBranch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1767\u001b[0m     \u001b[0mcontext_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExitResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1768\u001b[0m     \u001b[0mcontext_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildCondBranch\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mBuildCondBranch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[0;34m\"\"\"Add the subgraph defined by fn() to the graph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1660\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1661\u001b[0m     \u001b[0moriginal_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_maybe_copy_some_through\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mtime\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mflat_new_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflat_new_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# else copy some of it through\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         lambda: _copy_some_through(flat_new_output, flat_new_state))\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;31m# TODO(ebrevdo): skipping these conditionals may cause a slowdown,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, fn1, fn2, name)\u001b[0m\n\u001b[1;32m   1784\u001b[0m         raise ValueError(\"Outputs of fn1 and fn2 must have the same type: \"\n\u001b[1;32m   1785\u001b[0m                          \"%s, %s\" % (val_x.dtype.name, val_y.dtype.name))\n\u001b[0;32m-> 1786\u001b[0;31m     \u001b[0mmerges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m     \u001b[0mmerges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_flows_to_tensorarrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1784\u001b[0m         raise ValueError(\"Outputs of fn1 and fn2 must have the same type: \"\n\u001b[1;32m   1785\u001b[0m                          \"%s, %s\" % (val_x.dtype.name, val_y.dtype.name))\n\u001b[0;32m-> 1786\u001b[0;31m     \u001b[0mmerges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m     \u001b[0mmerges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_flows_to_tensorarrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(inputs, name)\u001b[0m\n\u001b[1;32m    415\u001b[0m               for inp in inputs]\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_ref_dtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgen_control_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ref_merge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "imp.reload(models)\n",
    "\n",
    "rnn = models.Model(func=models.build_rnn, input_size=50, output_size=8, bidirectional=False, hidden=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mere building computational graph takes far too long. I will ditch concept of determining sentiment with RNN, until I figure out work-around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/models.py'>"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score, pip = utils.train_test_pipeline(TfidfVectorizer, models.Model, data, at_least_threshold,\n",
    "                                      func=models.build_mlp, input_size=len(at_least_threshold), output_size=8, \n",
    "                                      architecture=[2000, 500], dropout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.27050698577258886,\n",
       " 'recall': 0.26882296253064225,\n",
       " 'test': 0.51118210862619806,\n",
       " 'train': 0.97532556545579163}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 {'precision': 0.008386581469648562, 'train': 0.082248115147361203, 'recall': 0.125, 'test': 0.067092651757188496}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.555555555556 {'precision': 0.0027955271565495207, 'train': 0.019191226867717615, 'recall': 0.125, 'test': 0.022364217252396165}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.611111111111 {'precision': 0.19259999999999999, 'train': 0.55243317340644282, 'recall': 0.12701612903225806, 'test': 0.54153354632587858}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666666666667 {'precision': 0.0027955271565495207, 'train': 0.022618231665524333, 'recall': 0.125, 'test': 0.022364217252396165}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.722222222222 {'precision': 0.1278, 'train': 0.025359835503769704, 'recall': 0.12701612903225806, 'test': 0.023961661341853034}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777777777778 {'precision': 0.19259999999999999, 'train': 0.55928718300205615, 'recall': 0.12701612903225806, 'test': 0.54153354632587858}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833333333333 {'precision': 0.102868548905049, 'train': 0.18437285812200138, 'recall': 0.15687405529216944, 'test': 0.11022364217252396}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888888888889 {'precision': 0.14248449797281182, 'train': 0.1501028101439342, 'recall': 0.1315676155936702, 'test': 0.078274760383386585}\n",
      "0.944444444444 {'precision': 0.28083829021329021, 'train': 0.83207676490747084, 'recall': 0.27682370105089538, 'test': 0.44568690095846647}\n",
      "1.0 {'precision': 0.23608955330976766, 'train': 0.99794379712131598, 'recall': 0.23004514577515797, 'test': 0.51437699680511184}\n"
     ]
    }
   ],
   "source": [
    "nn_scores = []\n",
    "for d in np.linspace(.5, 1, num=10):\n",
    "    \n",
    "    score, pip = utils.train_test_pipeline(TfidfVectorizer, models.Model, data, at_least_threshold,\n",
    "                                      func=models.build_mlp, input_size=len(at_least_threshold), output_size=8, \n",
    "                                      architecture=[2000, 500], dropout=d)\n",
    "    \n",
    "    nn_scores.append(score)\n",
    "    \n",
    "    print(d, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are... interesting. Dropout is very powerful regularizer, that's for sure, but I would not expect it to drive network's performance that low. However, not all hope is lost. I can finetune this network using hyperopt package, since doing it by hand would take a lot of time and be rather tedious and not exactly inspiring work. But before I get to automatising everything, I will investigate how loss function changes with succesive iterations. It might be that test and train accuracy diverges after reaching some high level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/utils.py'>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/home/lukasz/Dokumenty/DEEP LEARNING/NLP/oxford/models.py'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, pip = utils.train_with_loss_history(TfidfVectorizer, data, models.Model, at_least_threshold,\n",
    "                                          func=models.build_mlp, input_size=len(at_least_threshold), \n",
    "                                          output_size=8, architecture=[1000, 500], dropout=1, iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
